{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8408039,"sourceType":"datasetVersion","datasetId":4937652}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setups\n## Import Libraries","metadata":{}},{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:25.628882Z","iopub.execute_input":"2024-05-15T14:55:25.629600Z","iopub.status.idle":"2024-05-15T14:55:38.100258Z","shell.execute_reply.started":"2024-05-15T14:55:25.629564Z","shell.execute_reply":"2024-05-15T14:55:38.098972Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (2.7.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nimport os\nimport random\n\n# Deep Learning\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, Subset\nfrom torch.utils.data import random_split, ConcatDataset\nfrom itertools import chain\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nimport gc\n# from torchsummary import summary\n# from torch.nn import functional as F\n\n# torchvision\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torchvision.utils import make_grid\n\n# Image Processing\nfrom PIL import Image\n\n# Encoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.decomposition import PCA\n\n# texual embeddings\nfrom sentence_transformers import SentenceTransformer\n\n# Training\nfrom sklearn.model_selection import train_test_split\n# from skopt import BayesSearchCV\nfrom sklearn.metrics import mean_absolute_error\n# svd\nfrom sklearn.decomposition import TruncatedSVD\n\n# Random Forest\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\n# XGBoost / CatBoost\nimport xgboost as xgb\nimport catboost as ctb\n\n# DataFrame\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom gensim.models import Word2Vec","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:38.102614Z","iopub.execute_input":"2024-05-15T14:55:38.102931Z","iopub.status.idle":"2024-05-15T14:55:38.113036Z","shell.execute_reply.started":"2024-05-15T14:55:38.102903Z","shell.execute_reply":"2024-05-15T14:55:38.112292Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Check GPU","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"No GPU available, using CPU.\")\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:38.114374Z","iopub.execute_input":"2024-05-15T14:55:38.114735Z","iopub.status.idle":"2024-05-15T14:55:38.130533Z","shell.execute_reply.started":"2024-05-15T14:55:38.114706Z","shell.execute_reply":"2024-05-15T14:55:38.129458Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"GPU\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/input/social-media-popularity-with-images/'\n# path = ''\n# read json to dataframe\ntrain_x = pd.read_json('{}data/train_data.json'.format(path))\ntest_x = pd.read_json('{}data/test_data.json'.format(path))\n\n# read labels\ntrain_y = pd.read_csv('{}data/train_label.csv'.format(path))\ntrain_x['img_filepath'] = train_x['img_filepath'].apply(lambda x: '{}data/'.format(path) + x)\ntest_x['img_filepath'] = test_x['img_filepath'].apply(lambda x: '{}data/'.format(path) + x)\nprint(train_x.columns)\nprint(train_x.head()) ","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:38.133157Z","iopub.execute_input":"2024-05-15T14:55:38.133741Z","iopub.status.idle":"2024-05-15T14:55:39.171567Z","shell.execute_reply.started":"2024-05-15T14:55:38.133713Z","shell.execute_reply":"2024-05-15T14:55:39.170619Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Index(['Pid', 'Uid', 'Title', 'Alltags', 'Category', 'Concept', 'Subcategory',\n       'Postdate', 'img_filepath'],\n      dtype='object')\n      Pid        Uid                                              Title  \\\n0  149005  22687@N84                                     having a drink   \n1  149948  17614@N19  Foto Agne Sterberg, Destination Hga Kusten, AG...   \n2  151388  17614@N19  Foto Agne Sterberg, AGMA Forntid & ventyr AB, ...   \n3  151389  17614@N19  Foto Agne Sterberg, AGMA Forntid & ventyr AB, ...   \n4  151390  17614@N19  Foto Agne Sterberg, AGMA Forntid & ventyr AB, ...   \n\n                                             Alltags              Category  \\\n0  life county wild bird water animal closeup fau...                  Food   \n1  hav mitt hga kusten blsippor nordingr klippor ...  Travel&Active&Sports   \n2  is sweden sverige hav soluppgng mitt vr hga ku...  Travel&Active&Sports   \n3  is sweden sverige hav soluppgng mitt vr hga ku...  Travel&Active&Sports   \n4  is sweden sverige hav soluppgng mitt vr hga ku...  Travel&Active&Sports   \n\n   Concept Subcategory    Postdate  \\\n0  thirsty      Drinks  1426216890   \n1     mitt    Baseball  1426557920   \n2     mitt    Baseball  1427232557   \n3     mitt    Baseball  1427192316   \n4     mitt    Baseball  1427234146   \n\n                                        img_filepath  \n0  /kaggle/input/social-media-popularity-with-ima...  \n1  /kaggle/input/social-media-popularity-with-ima...  \n2  /kaggle/input/social-media-popularity-with-ima...  \n3  /kaggle/input/social-media-popularity-with-ima...  \n4  /kaggle/input/social-media-popularity-with-ima...  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Exploration","metadata":{}},{"cell_type":"code","source":"# EDA_df = train_x\n# EDA_test_df = test_x\n\n# EDA_df['Postdate'] = pd.to_datetime(EDA_df['Postdate'], unit='s')\n# EDA_test_df['Postdate'] = pd.to_datetime(EDA_test_df['Postdate'], unit='s')\n\n# # find the time interval of EDA & test\n\n# print(EDA_df['Postdate'].min())\n# print(EDA_df['Postdate'].max())\n# print(EDA_test_df['Postdate'].min())\n# print(EDA_test_df['Postdate'].max())\n\n# print(EDA_df['Postdate'])\n# print(EDA_test_df['Postdate'])\n\n# print(EDA_df['Category'].value_counts())\n# print(EDA_df['Subcategory'].value_counts())\n\n# # plot y distribution with histogram\n# plt.figure()\n# train_y['label'].hist(bins=300)\n# plt.title('Label Distribution')\n# plt.show()\n\n# # plot y distribution depends on time\n# EDA_df['Postdate'] = pd.to_datetime(EDA_df['Postdate'], unit='s')\n# date_distribution = train_y.merge(EDA_df[['Postdate', 'Pid']], on='Pid', how='left')\n# date_distribution = date_distribution.set_index('Postdate')\n# # group by hour & plot hist\n# hour_distribution = date_distribution.resample('H').mean()\n# plt.figure()\n# hour_distribution['label'].hist(bins=1000)\n# plt.title('Label Distribution over Time')\n# plt.show()\n\n# # group by weekday\n# weekday_distribution = date_distribution.resample('D').mean()\n# plt.figure()\n# weekday_distribution['label'].hist(bins=300)\n# plt.title('Label Distribution over Time')\n# plt.show()\n\n\n# # find unique values of Category, Concept, Subcategory\n# print(len(EDA_df['Category'].unique()))\n# print(len(EDA_df['Concept'].unique()))\n# print(len(EDA_df['Subcategory'].unique()))\n# print(len(EDA_df['Uid'].unique()))\n\n# # check if there is any missing value\n# print(EDA_df.isnull().sum())\n\n# # check if Uid appears in test but not in train\n# train_uid = set(EDA_df['Uid'].unique())\n# test_uid = set(test_x['Uid'].unique())\n# print(len(test_uid - train_uid))\n\n# # check if Concept appears in test but not in train\n# train_concept = set(EDA_df['Concept'].unique())\n# test_concept = set(test_x['Concept'].unique())\n# print(len(test_concept - train_concept))\n\n# # check if Category appears in test but not in train\n# train_category = set(EDA_df['Category'].unique())\n# test_category = set(test_x['Category'].unique())\n# print(len(test_category - train_category))\n\n# # check if Subcategory appears in test but not in train\n# train_subcategory = set(EDA_df['Subcategory'].unique())\n# test_subcategory = set(test_x['Subcategory'].unique())\n# print(len(test_subcategory - train_subcategory))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:39.172850Z","iopub.execute_input":"2024-05-15T14:55:39.173203Z","iopub.status.idle":"2024-05-15T14:55:39.180328Z","shell.execute_reply.started":"2024-05-15T14:55:39.173170Z","shell.execute_reply":"2024-05-15T14:55:39.179294Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering\n## Time Feature","metadata":{}},{"cell_type":"code","source":"def time_feature_engineering(df, start_t):\n    df['Postdate'] = pd.to_datetime(df['Postdate'], unit='s')\n\n    # groupby weekday and encode in 7 dimension\n    df['weekday'] = df['Postdate'].dt.weekday\n    weekday_df = pd.get_dummies(df['weekday']).astype(int)\n    df = pd.concat([df, weekday_df], axis=1)\n\n    combined_categories = [i for i in range(1, 13)]\n    encoder = OneHotEncoder(categories=[combined_categories], sparse=False)\n    encoder.fit([[cat] for cat in combined_categories]) \n    df['month'] = df['Postdate'].dt.month\n    train_encoded = pd.DataFrame(encoder.transform(df[['month']]), columns=encoder.get_feature_names_out(['month'])).astype(int)\n    df = pd.concat([df, train_encoded], axis=1)\n\n    # transform hour to morning (06:00 to 11:59), afternoon (12:00 to 17:59), evening (18:00 to 23:59), or night (00:00 to 05:59).\n    df['hour'] = df['Postdate'].dt.hour\n    df['morning'] = df['hour'].apply(lambda x: 1 if 6 <= x < 12 else 0)\n    df['afternoon'] = df['hour'].apply(lambda x: 1 if 12 <= x < 18 else 0)\n    df['evening'] = df['hour'].apply(lambda x: 1 if 18 <= x < 24 else 0)\n    df['night'] = df['hour'].apply(lambda x: 1 if 0 <= x < 6 else 0)\n\n    # get post duration\n    if start_t is None:\n        start_t = df['Postdate'].min()\n    df['Postduration'] = df['Postdate'] - start_t\n    df['Postduration'] = df['Postduration'].dt.total_seconds()\n    df = df.drop(columns=['weekday', 'month', 'hour', 'Postdate'])\n    \n    return df, start_t","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:39.181729Z","iopub.execute_input":"2024-05-15T14:55:39.182082Z","iopub.status.idle":"2024-05-15T14:55:39.196694Z","shell.execute_reply.started":"2024-05-15T14:55:39.182032Z","shell.execute_reply":"2024-05-15T14:55:39.195812Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Texual Embedding","metadata":{}},{"cell_type":"code","source":"def get_textual_embeddings(data):\n    model = SentenceTransformer('paraphrase-MiniLM-L6-v2', device = 'cuda')\n#     model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n    embeddings = model.encode(data['all_text'].tolist())\n\n    # reduce embedding dimension\n#     svd = TruncatedSVD(n_components=80, n_iter=2, random_state=42)\n#     embeddings = svd.fit_transform(embeddings)\n    columns = ['text_embedding_' + str(i) for i in range(384)]\n    embeddings = pd.DataFrame(embeddings, columns=columns)\n    data[columns] = embeddings\n\n    # add tf-idf\n    from sklearn.feature_extraction.text import TfidfVectorizer\n    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n    tfidf = vectorizer.fit_transform(data['all_text'].tolist())\n    tfidf = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n    data = pd.concat([data, tfidf], axis=1)\n\n    data['Concept_words'] = data['Concept'].apply(lambda x: x.split())\n\n    model = Word2Vec(sentences=data['Concept_words'], vector_size=100, window=5, min_count=1)\n    model.train(data['Concept_words'], total_examples=len(data['Concept_words']), epochs=10)\n    embeddings = model.wv.vectors\n    c_columns = ['concept_embedding_' + str(i) for i in range(100)]\n    embeddings = pd.DataFrame(embeddings, columns=c_columns)\n    data[c_columns] = embeddings\n    data.drop(['Concept_words'], axis=1, inplace=True)\n\n    c_columns.extend(columns)\n    return data, c_columns","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:39.198017Z","iopub.execute_input":"2024-05-15T14:55:39.198365Z","iopub.status.idle":"2024-05-15T14:55:39.212635Z","shell.execute_reply.started":"2024-05-15T14:55:39.198334Z","shell.execute_reply":"2024-05-15T14:55:39.211772Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"## Categorial Embedding","metadata":{}},{"cell_type":"code","source":"# get categorical embedding by PCA\n\ndef PCA_embedding(data, columns, n_components = 10, pca_model=None, encoder=None):\n    # One-hot encode the categories that appear in both training and test datasets\n    if encoder:\n        encoded_data = encoder.transform(data[[columns]])\n    else:\n        encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n        encoded_data = encoder.fit_transform(data[[columns]])\n    \n    if pca_model == None:\n        pca_model = PCA(n_components=n_components)\n        pca_result = pca_model.fit_transform(encoded_data)\n    else:\n        # Apply PCA model trained on training data to test data\n        pca_result = pca_model.transform(encoded_data)\n    \n    columns = ['{}_Embedding_'.format(columns) + str(i) for i in range(n_components)]\n    pca_result = pd.DataFrame(pca_result, columns=columns)\n    data[columns] = pca_result\n\n    return data, pca_model, encoder","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:39.213838Z","iopub.execute_input":"2024-05-15T14:55:39.214096Z","iopub.status.idle":"2024-05-15T14:55:39.225955Z","shell.execute_reply.started":"2024-05-15T14:55:39.214074Z","shell.execute_reply":"2024-05-15T14:55:39.225164Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Normalization","metadata":{}},{"cell_type":"code","source":"def numerical_feature_normalization(df, columns, mean=None, std=None):\n    if mean is None:\n        mean = df[columns].mean()\n        std = df[columns].std()\n        df[columns] = (df[columns] - mean) / std\n        return df, mean, std\n    df[columns] = (df[columns] - mean) / std\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:39.227026Z","iopub.execute_input":"2024-05-15T14:55:39.227320Z","iopub.status.idle":"2024-05-15T14:55:39.240169Z","shell.execute_reply.started":"2024-05-15T14:55:39.227297Z","shell.execute_reply":"2024-05-15T14:55:39.239444Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def feature_engineering(df, label_encoder=None, embeddings=None, train_cat_df=None, start_time=None):\n    \n    df['tags_count'] = df['Alltags'].apply(lambda x: len(x.split(' ')))\n    df['title_len'] = df['Title'].apply(lambda x: len(x))\n    df['all_text'] = df['Title'] + ' ' + df['Alltags']\n\n#     get textual embeddings\n    df, text_embedding_columns = get_textual_embeddings(df)\n    # time feature engineering\n    df, start_time = time_feature_engineering(df, start_time)\n\n    n_comp = {'Concept':30, 'Subcategory':30, 'Uid':20}\n    embeddings = []\n    label_encoder = {}\n    # encoding_col = ['Concept']\n    encoding_col = []\n#     get Category embeddings\n    if len(embeddings) > 0:\n        for i, col in enumerate(encoding_col):\n            df, _, _ = PCA_embedding(df, col, n_components=n_comp[col], pca_model=embeddings[i], encoder=label_encoder[col])\n    else:\n        for i, col in enumerate(encoding_col):\n            df, concept_embeddings, concept_encoder = PCA_embedding(df, col, n_components=n_comp[col])\n            embeddings.append(concept_embeddings)\n            label_encoder[col] = concept_encoder\n\n    # split dataset by category into different dataframes\n    category_df = {}\n    for cat in df['Category'].unique():\n        category_df[cat] = {'df': df[df['Category'] == cat]}\n        category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n        # one hot encoder ignore unknown categories\n        if train_cat_df is not None:\n            encoder = train_cat_df[cat]['encoder']\n        else:\n            encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n            encoder.fit([[subcat] for subcat in category_df[cat]['df']['Subcategory']])\n        encoded_data = encoder.transform(category_df[cat]['df'][['Subcategory']])\n        category_df[cat]['encoder'] = encoder\n        # concat the encoded data with the original data\n        columns = ['Subcategory_' + str(i) for i in range(encoded_data.shape[1])]\n        encoded_data = pd.DataFrame(encoded_data, columns=columns)\n        encoded_data.set_index(category_df[cat]['df'].index, inplace=True)\n        category_df[cat]['df'] = pd.concat([category_df[cat]['df'], encoded_data], axis=1)\n        category_df[cat]['df'].drop('Subcategory', axis=1, inplace=True)\n        category_df[cat]['df'].drop([ 'Pid', 'Title', 'Alltags', 'Uid', 'Concept', 'all_text'], axis=1, inplace=True)\n        \n\n    concept_embedding_columns = ['Concept_Embedding_{}'.format(i) for i in range(n_comp['Concept'])]\n\n    numeric_feature = ['tags_count', 'title_len', 'Uid_freq', 'Postduration']\n#     numeric_feature.extend(text_embedding_columns)\n    for i in [text_embedding_columns]:\n#     for i in [concept_embedding_columns]:\n        numeric_feature.extend(i)\n    # categorial_feature = ['Category_Animal', 'Category_Electronics', 'Category_Entertainment', 'Category_Family', 'Category_Fashion', 'Category_Food', 'Category_Holiday&Celebrations', 'Category_Social&People', 'Category_Travel&Active&Sports', 'Category_Urban', 'Category_Whether&Season', 'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12', 'morning', 'afternoon', 'evening', 'night']\n\n    for cat in category_df.keys():\n        if train_cat_df is None:\n            category_df[cat]['df'], train_mean, train_std = numerical_feature_normalization(category_df[cat]['df'], numeric_feature)\n            category_df[cat]['mean'] = train_mean\n            category_df[cat]['std'] = train_std\n        else:\n            category_df[cat]['df'] = numerical_feature_normalization(category_df[cat]['df'], numeric_feature, train_cat_df[cat]['mean'], train_cat_df[cat]['std'])\n    \n    if train_cat_df is None:\n        return category_df, label_encoder, embeddings, start_time\n    return category_df","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:39.244524Z","iopub.execute_input":"2024-05-15T14:55:39.244806Z","iopub.status.idle":"2024-05-15T14:55:39.263076Z","shell.execute_reply.started":"2024-05-15T14:55:39.244783Z","shell.execute_reply":"2024-05-15T14:55:39.262288Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Models\n## MultiModal (CNN + Feature)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Images","metadata":{}},{"cell_type":"code","source":"class MultimodalDataset(Dataset):\n    def __init__(self, x, image_filepath, y=None, transform=None):\n        self.image_paths = image_filepath  # Adjust this to match the column name containing image paths\n        self.dataframe = x\n        self.transform = transform\n        self.y = y\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        # Extract information for the current row\n        image_path = self.image_paths[int(idx)]\n        \n        # Load the image\n        image = Image.open(image_path)  # Ensure RGB mode\n        # Apply transformations if specified\n        if self.transform:\n            image = self.transform(image)\n        if(image.shape[0]):\n            image = image.expand(3, -1, -1)\n        # print(image)\n        # Extract other relevant data from the row if needed\n        # For example: label = row['label']\n        \n        # Return image and other data\n        if self.y is None:\n            return self.dataframe[int(idx)], image\n        else:\n            return self.dataframe[int(idx)], image, self.y[int(idx)]","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:39.264270Z","iopub.execute_input":"2024-05-15T14:55:39.264593Z","iopub.status.idle":"2024-05-15T14:55:39.279020Z","shell.execute_reply.started":"2024-05-15T14:55:39.264563Z","shell.execute_reply":"2024-05-15T14:55:39.278143Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### def load_data","metadata":{}},{"cell_type":"code","source":"# Load torchvision datasets like CIFAR10 and MNIST\ndef load_data(data,\n              img_filepath_index,\n              y=None,\n              augs=None,\n              resize=(128,128),\n              channel_mean=None,\n              channel_stdd=None):\n    # Normalization step in image processing for neural networks is\n    # usually performed after an image has been converted into a tensor\n    # using transforms.ToTensor(). This converts the image from a PIL Image or\n    # numpy array with dimensions (Height, Width, Channels) and pixel\n    # range [0, 255] to a float tensor with dimensions (Channels, Height, Width)\n    # and pixel values scaled down to the range [0.0, 1.0].\n    if channel_mean and channel_stdd:\n      base_transform = transforms.Compose([\n          torchvision.transforms.Resize(resize),\n          # Convert to tensor\n          transforms.ToTensor(),  # data scaled to 0 to 1\n          # Normalize (example values for normalization, should be adjusted based on dataset)\n          transforms.Normalize(channel_mean, channel_stdd) # rescaled to -1 to 1\n        ])\n    else:\n      base_transform = transforms.Compose([\n         torchvision.transforms.Resize(resize),\n          transforms.ToTensor(),\n      ])\n\n    if augs:\n      transform = transforms.Compose([\n          # Augmentations\n          *augs.transforms,\n          # Preprocessing\n          *base_transform.transforms,\n        ])\n    else:\n      transform = base_transform\n    image_path = data[:, 0]\n        \n    data = torch.tensor(data[:, 1:].astype(np.float32), dtype=torch.float32)\n\n    if y is not None:\n      y = torch.tensor(y, dtype=torch.float32)\n      trainset = MultimodalDataset(data, image_path, y, transform=transform)\n      return trainset\n    trainset = trainset = MultimodalDataset(data, image_path, transform=transform)\n    return trainset\n\n# For visualizing images\ndef unnormalize(img):\n    img = img / 2 + 0.5     # unnormalize\n    return img","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:39.280194Z","iopub.execute_input":"2024-05-15T14:55:39.280534Z","iopub.status.idle":"2024-05-15T14:55:39.294595Z","shell.execute_reply.started":"2024-05-15T14:55:39.280504Z","shell.execute_reply":"2024-05-15T14:55:39.293872Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### Visualization","metadata":{}},{"cell_type":"code","source":"## Let's see some images\ndef imshow(img):\n    npimg = img.numpy()  # convert PyTorch tensor to numpy\n    if len(npimg.shape) == 3:  # RGB image\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))  # transpose (C, H, W) to (H, W, C)\n    else:  # Grayscale image\n        plt.imshow(npimg[0], cmap='gray')  # display the first channel\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:39.295593Z","iopub.execute_input":"2024-05-15T14:55:39.295863Z","iopub.status.idle":"2024-05-15T14:55:39.310701Z","shell.execute_reply.started":"2024-05-15T14:55:39.295839Z","shell.execute_reply":"2024-05-15T14:55:39.309826Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"### Check pictures","metadata":{}},{"cell_type":"code","source":"# Define transformations to preprocess the images\n\n# Randomly select a few images from the training set\n\n# trainset = load_data(train_x.values,\n#                     train_y,\n#                     resize=(256, 256),\n#                     channel_mean=(0.5,0.5,0.5),\n#                     channel_stdd=(0.5,0.5,0.5))\n\n# indices = torch.randperm(len(trainset))[:4]\n\n# # Prepare images and labels\n# images = torch.stack([trainset[i][1] for i in indices])\n\n# # Show images and labels\n# # create grid of images\n# img_grid = torchvision.utils.make_grid(images)\n# # print(img_grid)\n# img_grid.unnorm = unnormalize(img_grid)\n# imshow(img_grid.unnorm)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:39.311768Z","iopub.execute_input":"2024-05-15T14:55:39.312027Z","iopub.status.idle":"2024-05-15T14:55:39.342505Z","shell.execute_reply.started":"2024-05-15T14:55:39.312004Z","shell.execute_reply":"2024-05-15T14:55:39.341481Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"markdown","source":"## Preprocess","metadata":{}},{"cell_type":"code","source":"random_seed = 42\ntest_Pid = test_x['Pid']\n# count Uid frequency concatenate with train_x and test_x\nconcat_df = pd.concat([train_x, test_x])\nUid_freq = concat_df['Uid'].value_counts()\ntrain_x['Uid_freq'] = train_x['Uid'].map(Uid_freq)\ntest_x['Uid_freq'] = test_x['Uid'].map(Uid_freq)\n\ntrain_x, label_encoder, embeddings, start_t = feature_engineering(train_x)\ntest_x = feature_engineering(test_x, label_encoder, embeddings, train_x, start_t)\nimg_filepath_index = train_x['Urban']['df'].columns.get_loc('img_filepath')\n\ny_train = train_y['label']\ny_train_cat = {}\nfor cat in train_x.keys():\n    # Split y_train according to the category\n    y_train_cat[cat] = y_train[train_x[cat]['df'].index].values.reshape(-1)\n    train_x[cat]['df'] = train_x[cat]['df'].values\n    test_x[cat]['df'] = test_x[cat]['df'].values\n    \n# train_x.to_csv('/kaggle/working/train_x.csv',index=False)\n# test_x.to_csv('/kaggle/working/test_x.csv',index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:55:39.343677Z","iopub.execute_input":"2024-05-15T14:55:39.343983Z","iopub.status.idle":"2024-05-15T14:56:04.291057Z","shell.execute_reply.started":"2024-05-15T14:55:39.343958Z","shell.execute_reply":"2024-05-15T14:56:04.290054Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ed0a7b0099447b5a6780d8cb93c31d1"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[c_columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[c_columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[c_columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[c_columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[c_columns] = embeddings\n/tmp/ipykernel_445/1243536838.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df['weekday'] = df['Postdate'].dt.weekday\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"261c8fad1ffa4eaaba6e4f43ed73a45d"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[c_columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[c_columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[c_columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[c_columns] = embeddings\n/tmp/ipykernel_445/1971763274.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[c_columns] = embeddings\n/tmp/ipykernel_445/1243536838.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df['weekday'] = df['Postdate'].dt.weekday\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n/tmp/ipykernel_445/399664418.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  category_df[cat]['df'].drop('Category', axis=1, inplace=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"for cat in train_x.keys():\n    print(cat)\n    print(train_x[cat]['df'].shape)\n    print(test_x[cat]['df'].shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:56:04.292437Z","iopub.execute_input":"2024-05-15T14:56:04.292747Z","iopub.status.idle":"2024-05-15T14:56:04.298101Z","shell.execute_reply.started":"2024-05-15T14:56:04.292722Z","shell.execute_reply":"2024-05-15T14:56:04.297269Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Food\n(901, 1514)\n(283, 1514)\nTravel&Active&Sports\n(3513, 1530)\n(1619, 1530)\nWhether&Season\n(958, 1517)\n(317, 1517)\nAnimal\n(914, 1514)\n(622, 1514)\nEntertainment\n(1319, 1513)\n(448, 1513)\nFamily\n(196, 1511)\n(34, 1511)\nSocial&People\n(1100, 1516)\n(477, 1516)\nHoliday&Celebrations\n(2752, 1517)\n(367, 1517)\nElectronics\n(239, 1510)\n(119, 1510)\nFashion\n(2262, 1523)\n(348, 1523)\nUrban\n(846, 1511)\n(366, 1511)\n","output_type":"stream"}]},{"cell_type":"code","source":"# torch.cuda.empty_cache()\n# torch.cuda.memory_summary(device=None, abbreviated=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:56:04.299222Z","iopub.execute_input":"2024-05-15T14:56:04.299511Z","iopub.status.idle":"2024-05-15T14:56:04.313191Z","shell.execute_reply.started":"2024-05-15T14:56:04.299488Z","shell.execute_reply":"2024-05-15T14:56:04.312473Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## Tuning","metadata":{}},{"cell_type":"code","source":"resize=(128,128)\n\nfor cat in train_x.keys():\n    train_x[cat]['dataset'] = load_data(train_x[cat]['df'],\n              img_filepath_index,\n              y_train_cat[cat],\n              augs=None,\n              resize=resize,\n              channel_mean=None,\n              channel_stdd=None)\n    \n    test_x[cat]['dataset'] = load_data(test_x[cat]['df'],\n                img_filepath_index,\n                augs=None,\n                resize=resize,\n                channel_mean=None,\n                channel_stdd=None)\n\ndef data_loader(train_dataset, image_model, sk_svd=TruncatedSVD(n_components=30, n_iter=2, random_state=42), test=False):\n    total_feature = []\n    target = []\n    image_model.eval()\n    num=train_dataset.__len__()\n    factors=[]\n    print(num)\n\n    if num>=1000:\n        batch_size = num//(4*(num//1000))\n    elif num//4 < 30:\n        batch_size = 30\n    else:\n        batch_size = num//4\n    while((num % batch_size < 30 and num% batch_size != 0)):\n        batch_size += 1\n#     if test:\n#         batch_size = factors[-1]\n#     else:\n#         if num>=1000:\n#             batch_size = num//(4*(num//1000))\n#         else:\n#             batch_size = num//4\n    \n\n    train_dataset = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n\n    for i, val in enumerate(train_dataset):\n        image_input = val[1].to(device)\n        image_features = image_model(image_input)\n        # image_features = torch.tensor(sk_svd.fit_transform(image_features.cpu().detach().numpy()))\n        # image_features = torch.tensor(sk_svd.fit_transform(image_features.detach().numpy()))\n        # Keep only the top 30 singular values and corresponding vectors\n        # print(val[0])\n        total_feature.append(torch.cat((val[0], torch.tensor(image_features.cpu().detach().numpy())), dim=1))\n        del image_features, image_input\n        gc.collect()\n        if not test:\n            target.append(val[2])\n    total_feature = torch.cat(total_feature, dim=0)\n    print('total.shape:', total_feature.shape)\n    if not test:\n        target = torch.cat(target, dim=0)\n        print('target.shape:', target.shape)\n        return total_feature, target  \n    return total_feature\n\nresnet_ = models.resnet50(pretrained=True).to(device)\nfor cat in train_x.keys():\n    train_dataset = train_x[cat]['dataset']\n    total_feature, target = data_loader(train_dataset, resnet_)\n    train_x[cat]['total_feature'] = total_feature\n    train_x[cat]['target'] = target.detach().numpy()\n    del train_dataset\n    print('{} finished'.format(cat))\nprint('train_finished')\n\nfor cat in test_x.keys():\n    test_dataset = test_x[cat]['dataset']\n    total_feature_test = data_loader(test_dataset, resnet_, test=True)\n    test_x[cat]['total_feature'] = total_feature_test\n    del test_dataset\n    print('{} finished'.format(cat))\nprint('test_finished')","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:56:04.314487Z","iopub.execute_input":"2024-05-15T14:56:04.314754Z","iopub.status.idle":"2024-05-15T14:58:32.564123Z","shell.execute_reply.started":"2024-05-15T14:56:04.314731Z","shell.execute_reply":"2024-05-15T14:58:32.563081Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"901\ntotal.shape: torch.Size([901, 2513])\ntarget.shape: torch.Size([901])\nFood finished\n3513\ntotal.shape: torch.Size([3513, 2529])\ntarget.shape: torch.Size([3513])\nTravel&Active&Sports finished\n958\ntotal.shape: torch.Size([958, 2516])\ntarget.shape: torch.Size([958])\nWhether&Season finished\n914\ntotal.shape: torch.Size([914, 2513])\ntarget.shape: torch.Size([914])\nAnimal finished\n1319\ntotal.shape: torch.Size([1319, 2512])\ntarget.shape: torch.Size([1319])\nEntertainment finished\n196\ntotal.shape: torch.Size([196, 2510])\ntarget.shape: torch.Size([196])\nFamily finished\n1100\ntotal.shape: torch.Size([1100, 2515])\ntarget.shape: torch.Size([1100])\nSocial&People finished\n2752\ntotal.shape: torch.Size([2752, 2516])\ntarget.shape: torch.Size([2752])\nHoliday&Celebrations finished\n239\ntotal.shape: torch.Size([239, 2509])\ntarget.shape: torch.Size([239])\nElectronics finished\n2262\ntotal.shape: torch.Size([2262, 2522])\ntarget.shape: torch.Size([2262])\nFashion finished\n846\ntotal.shape: torch.Size([846, 2510])\ntarget.shape: torch.Size([846])\nUrban finished\ntrain_finished\n317\ntotal.shape: torch.Size([317, 2516])\nWhether&Season finished\n348\ntotal.shape: torch.Size([348, 2522])\nFashion finished\n1619\ntotal.shape: torch.Size([1619, 2529])\nTravel&Active&Sports finished\n448\ntotal.shape: torch.Size([448, 2512])\nEntertainment finished\n283\ntotal.shape: torch.Size([283, 2513])\nFood finished\n622\ntotal.shape: torch.Size([622, 2513])\nAnimal finished\n477\ntotal.shape: torch.Size([477, 2515])\nSocial&People finished\n119\ntotal.shape: torch.Size([119, 2509])\nElectronics finished\n367\ntotal.shape: torch.Size([367, 2516])\nHoliday&Celebrations finished\n34\ntotal.shape: torch.Size([34, 2510])\nFamily finished\n366\ntotal.shape: torch.Size([366, 2510])\nUrban finished\ntest_finished\n","output_type":"stream"}]},{"cell_type":"code","source":"# pd.DataFrame(total_feature).to_csv('/kaggle/working/total_feature.csv',index=False)\n# pd.DataFrame(target).to_csv('/kaggle/working/target.csv',index=False)\n# pd.DataFrame(total_feature_val).to_csv('/kaggle/working/total_feature_val.csv',index=False)\n# pd.DataFrame(target_val).to_csv('/kaggle/working/target_val.csv',index=False)\n# pd.DataFrame(total_feature_test).to_csv('/kaggle/working/total_feature_test.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:58:32.565548Z","iopub.execute_input":"2024-05-15T14:58:32.565936Z","iopub.status.idle":"2024-05-15T14:58:32.570672Z","shell.execute_reply.started":"2024-05-15T14:58:32.565898Z","shell.execute_reply":"2024-05-15T14:58:32.569607Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"# for cat in train_x.keys():\n#     model_RF = RandomForestRegressor(n_estimators=400, max_depth=5, random_state=42)\n#     print('model_ready')\n#     model_RF.fit(train_x[cat]['total_feature'].cpu(), train_x[cat]['target'])\n#     print('RF_fit_done')\n#     train_x[cat]['model'] = model_RF","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:58:32.571780Z","iopub.execute_input":"2024-05-15T14:58:32.572095Z","iopub.status.idle":"2024-05-15T14:58:32.583315Z","shell.execute_reply.started":"2024-05-15T14:58:32.572070Z","shell.execute_reply":"2024-05-15T14:58:32.582269Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# for cat in train_x.keys():\n#     model_xgb = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1)\n#     print('model_ready')\n#     model_xgb.fit(train_x[cat]['total_feature'].cpu(), train_x[cat]['target'])\n#     print('RF_fit_done')\n#     train_x[cat]['model'] = model_xgb","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:58:32.584832Z","iopub.execute_input":"2024-05-15T14:58:32.586685Z","iopub.status.idle":"2024-05-15T14:58:32.595086Z","shell.execute_reply.started":"2024-05-15T14:58:32.586659Z","shell.execute_reply":"2024-05-15T14:58:32.594283Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T14:58:32.596195Z","iopub.execute_input":"2024-05-15T14:58:32.596546Z","iopub.status.idle":"2024-05-15T14:58:32.916980Z","shell.execute_reply.started":"2024-05-15T14:58:32.596512Z","shell.execute_reply":"2024-05-15T14:58:32.915874Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"\nfor cat in train_x.keys():\n    model_ctb = ctb.CatBoostRegressor(iterations=600,\n                          learning_rate=0.1,\n                          depth=10,\n                        task_type=\"GPU\",\n                          loss_function='RMSE',\n                        l2_leaf_reg = 3, \n                          verbose=True)\n    print('model_ready')\n    model_ctb.fit(train_x[cat]['total_feature'].cpu().detach().numpy(), train_x[cat]['target'])\n    print('cat_fit_done')\n    train_x[cat]['model'] = model_ctb","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:01:50.610370Z","iopub.execute_input":"2024-05-15T15:01:50.611297Z","iopub.status.idle":"2024-05-15T15:41:29.284141Z","shell.execute_reply.started":"2024-05-15T15:01:50.611259Z","shell.execute_reply":"2024-05-15T15:41:29.283174Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"model_ready\n0:\tlearn: 2.2284332\ttotal: 443ms\tremaining: 4m 25s\n1:\tlearn: 2.1719372\ttotal: 781ms\tremaining: 3m 53s\n2:\tlearn: 2.1121955\ttotal: 1.11s\tremaining: 3m 41s\n3:\tlearn: 2.0589225\ttotal: 1.45s\tremaining: 3m 36s\n4:\tlearn: 2.0192958\ttotal: 1.79s\tremaining: 3m 33s\n5:\tlearn: 1.9705164\ttotal: 2.13s\tremaining: 3m 30s\n6:\tlearn: 1.9301658\ttotal: 2.47s\tremaining: 3m 29s\n7:\tlearn: 1.9008756\ttotal: 2.81s\tremaining: 3m 27s\n8:\tlearn: 1.8520995\ttotal: 3.15s\tremaining: 3m 26s\n9:\tlearn: 1.8151515\ttotal: 3.49s\tremaining: 3m 26s\n10:\tlearn: 1.7960367\ttotal: 3.83s\tremaining: 3m 24s\n11:\tlearn: 1.7654231\ttotal: 4.16s\tremaining: 3m 24s\n12:\tlearn: 1.7405393\ttotal: 4.5s\tremaining: 3m 23s\n13:\tlearn: 1.7168810\ttotal: 4.83s\tremaining: 3m 22s\n14:\tlearn: 1.7016071\ttotal: 5.16s\tremaining: 3m 21s\n15:\tlearn: 1.6829603\ttotal: 5.49s\tremaining: 3m 20s\n16:\tlearn: 1.6611273\ttotal: 5.82s\tremaining: 3m 19s\n17:\tlearn: 1.6417123\ttotal: 6.16s\tremaining: 3m 19s\n18:\tlearn: 1.6180612\ttotal: 6.49s\tremaining: 3m 18s\n19:\tlearn: 1.6004653\ttotal: 6.82s\tremaining: 3m 17s\n20:\tlearn: 1.5868266\ttotal: 7.15s\tremaining: 3m 17s\n21:\tlearn: 1.5705158\ttotal: 7.49s\tremaining: 3m 16s\n22:\tlearn: 1.5593363\ttotal: 7.82s\tremaining: 3m 16s\n23:\tlearn: 1.5441527\ttotal: 8.15s\tremaining: 3m 15s\n24:\tlearn: 1.5227276\ttotal: 8.49s\tremaining: 3m 15s\n25:\tlearn: 1.5076700\ttotal: 8.83s\tremaining: 3m 14s\n26:\tlearn: 1.4968218\ttotal: 9.16s\tremaining: 3m 14s\n27:\tlearn: 1.4728201\ttotal: 9.51s\tremaining: 3m 14s\n28:\tlearn: 1.4493238\ttotal: 9.86s\tremaining: 3m 14s\n29:\tlearn: 1.4265146\ttotal: 10.2s\tremaining: 3m 13s\n30:\tlearn: 1.4181793\ttotal: 10.5s\tremaining: 3m 13s\n31:\tlearn: 1.3952974\ttotal: 10.9s\tremaining: 3m 13s\n32:\tlearn: 1.3784234\ttotal: 11.2s\tremaining: 3m 12s\n33:\tlearn: 1.3690655\ttotal: 11.6s\tremaining: 3m 12s\n34:\tlearn: 1.3543270\ttotal: 11.9s\tremaining: 3m 12s\n35:\tlearn: 1.3457234\ttotal: 12.2s\tremaining: 3m 11s\n36:\tlearn: 1.3398347\ttotal: 12.6s\tremaining: 3m 11s\n37:\tlearn: 1.3248669\ttotal: 12.9s\tremaining: 3m 11s\n38:\tlearn: 1.3145323\ttotal: 13.3s\tremaining: 3m 10s\n39:\tlearn: 1.3051211\ttotal: 13.6s\tremaining: 3m 10s\n40:\tlearn: 1.2967493\ttotal: 13.9s\tremaining: 3m 10s\n41:\tlearn: 1.2850317\ttotal: 14.3s\tremaining: 3m 9s\n42:\tlearn: 1.2726314\ttotal: 14.6s\tremaining: 3m 9s\n43:\tlearn: 1.2621930\ttotal: 15s\tremaining: 3m 9s\n44:\tlearn: 1.2547415\ttotal: 15.3s\tremaining: 3m 8s\n45:\tlearn: 1.2518568\ttotal: 15.6s\tremaining: 3m 8s\n46:\tlearn: 1.2404143\ttotal: 16s\tremaining: 3m 7s\n47:\tlearn: 1.2326848\ttotal: 16.3s\tremaining: 3m 7s\n48:\tlearn: 1.2236478\ttotal: 16.6s\tremaining: 3m 7s\n49:\tlearn: 1.2074914\ttotal: 17s\tremaining: 3m 6s\n50:\tlearn: 1.2011174\ttotal: 17.3s\tremaining: 3m 6s\n51:\tlearn: 1.1928786\ttotal: 17.6s\tremaining: 3m 5s\n52:\tlearn: 1.1779542\ttotal: 18s\tremaining: 3m 5s\n53:\tlearn: 1.1730968\ttotal: 18.2s\tremaining: 3m 3s\n54:\tlearn: 1.1697447\ttotal: 18.5s\tremaining: 3m 3s\n55:\tlearn: 1.1607710\ttotal: 18.9s\tremaining: 3m 3s\n56:\tlearn: 1.1556886\ttotal: 19.2s\tremaining: 3m 2s\n57:\tlearn: 1.1495351\ttotal: 19.5s\tremaining: 3m 2s\n58:\tlearn: 1.1455880\ttotal: 19.9s\tremaining: 3m 2s\n59:\tlearn: 1.1372501\ttotal: 20.2s\tremaining: 3m 1s\n60:\tlearn: 1.1324566\ttotal: 20.5s\tremaining: 3m 1s\n61:\tlearn: 1.1230902\ttotal: 20.9s\tremaining: 3m 1s\n62:\tlearn: 1.1137697\ttotal: 21.2s\tremaining: 3m\n63:\tlearn: 1.1065989\ttotal: 21.5s\tremaining: 3m\n64:\tlearn: 1.0985000\ttotal: 21.9s\tremaining: 3m\n65:\tlearn: 1.0874563\ttotal: 22.2s\tremaining: 2m 59s\n66:\tlearn: 1.0813642\ttotal: 22.6s\tremaining: 2m 59s\n67:\tlearn: 1.0765608\ttotal: 22.9s\tremaining: 2m 59s\n68:\tlearn: 1.0714483\ttotal: 23.2s\tremaining: 2m 58s\n69:\tlearn: 1.0635737\ttotal: 23.6s\tremaining: 2m 58s\n70:\tlearn: 1.0524267\ttotal: 23.9s\tremaining: 2m 58s\n71:\tlearn: 1.0481034\ttotal: 24.3s\tremaining: 2m 57s\n72:\tlearn: 1.0435212\ttotal: 24.6s\tremaining: 2m 57s\n73:\tlearn: 1.0380356\ttotal: 24.9s\tremaining: 2m 57s\n74:\tlearn: 1.0330084\ttotal: 25.3s\tremaining: 2m 56s\n75:\tlearn: 1.0207659\ttotal: 25.6s\tremaining: 2m 56s\n76:\tlearn: 1.0188987\ttotal: 26s\tremaining: 2m 56s\n77:\tlearn: 1.0047859\ttotal: 26.3s\tremaining: 2m 56s\n78:\tlearn: 1.0019411\ttotal: 26.6s\tremaining: 2m 55s\n79:\tlearn: 0.9907382\ttotal: 27s\tremaining: 2m 55s\n80:\tlearn: 0.9780939\ttotal: 27.3s\tremaining: 2m 55s\n81:\tlearn: 0.9736971\ttotal: 27.7s\tremaining: 2m 54s\n82:\tlearn: 0.9653289\ttotal: 28s\tremaining: 2m 54s\n83:\tlearn: 0.9607788\ttotal: 28.3s\tremaining: 2m 54s\n84:\tlearn: 0.9510945\ttotal: 28.7s\tremaining: 2m 53s\n85:\tlearn: 0.9417887\ttotal: 29s\tremaining: 2m 53s\n86:\tlearn: 0.9281670\ttotal: 29.4s\tremaining: 2m 53s\n87:\tlearn: 0.9215627\ttotal: 29.7s\tremaining: 2m 52s\n88:\tlearn: 0.9183652\ttotal: 30.1s\tremaining: 2m 52s\n89:\tlearn: 0.9062274\ttotal: 30.4s\tremaining: 2m 52s\n90:\tlearn: 0.9027659\ttotal: 30.8s\tremaining: 2m 52s\n91:\tlearn: 0.8903085\ttotal: 31.1s\tremaining: 2m 51s\n92:\tlearn: 0.8822795\ttotal: 31.5s\tremaining: 2m 51s\n93:\tlearn: 0.8782217\ttotal: 31.8s\tremaining: 2m 51s\n94:\tlearn: 0.8764070\ttotal: 32.1s\tremaining: 2m 50s\n95:\tlearn: 0.8710925\ttotal: 32.5s\tremaining: 2m 50s\n96:\tlearn: 0.8628993\ttotal: 32.8s\tremaining: 2m 50s\n97:\tlearn: 0.8557253\ttotal: 33.1s\tremaining: 2m 49s\n98:\tlearn: 0.8411477\ttotal: 33.5s\tremaining: 2m 49s\n99:\tlearn: 0.8339705\ttotal: 33.8s\tremaining: 2m 49s\n100:\tlearn: 0.8311212\ttotal: 34.2s\tremaining: 2m 48s\n101:\tlearn: 0.8207163\ttotal: 34.5s\tremaining: 2m 48s\n102:\tlearn: 0.8164171\ttotal: 34.9s\tremaining: 2m 48s\n103:\tlearn: 0.8106368\ttotal: 35.2s\tremaining: 2m 47s\n104:\tlearn: 0.8080067\ttotal: 35.5s\tremaining: 2m 47s\n105:\tlearn: 0.8037163\ttotal: 35.9s\tremaining: 2m 47s\n106:\tlearn: 0.8014385\ttotal: 36.2s\tremaining: 2m 46s\n107:\tlearn: 0.7990290\ttotal: 36.5s\tremaining: 2m 46s\n108:\tlearn: 0.7875742\ttotal: 36.9s\tremaining: 2m 46s\n109:\tlearn: 0.7824321\ttotal: 37.2s\tremaining: 2m 45s\n110:\tlearn: 0.7789719\ttotal: 37.5s\tremaining: 2m 45s\n111:\tlearn: 0.7712759\ttotal: 37.9s\tremaining: 2m 45s\n112:\tlearn: 0.7667881\ttotal: 38.2s\tremaining: 2m 44s\n113:\tlearn: 0.7628573\ttotal: 38.6s\tremaining: 2m 44s\n114:\tlearn: 0.7557210\ttotal: 38.9s\tremaining: 2m 44s\n115:\tlearn: 0.7533214\ttotal: 39.3s\tremaining: 2m 43s\n116:\tlearn: 0.7458886\ttotal: 39.6s\tremaining: 2m 43s\n117:\tlearn: 0.7397699\ttotal: 39.9s\tremaining: 2m 43s\n118:\tlearn: 0.7319974\ttotal: 40.3s\tremaining: 2m 42s\n119:\tlearn: 0.7268490\ttotal: 40.6s\tremaining: 2m 42s\n120:\tlearn: 0.7203276\ttotal: 41s\tremaining: 2m 42s\n121:\tlearn: 0.7146552\ttotal: 41.3s\tremaining: 2m 41s\n122:\tlearn: 0.7139991\ttotal: 41.6s\tremaining: 2m 41s\n123:\tlearn: 0.7030421\ttotal: 42s\tremaining: 2m 41s\n124:\tlearn: 0.6963667\ttotal: 42.3s\tremaining: 2m 40s\n125:\tlearn: 0.6945616\ttotal: 42.7s\tremaining: 2m 40s\n126:\tlearn: 0.6892052\ttotal: 43s\tremaining: 2m 40s\n127:\tlearn: 0.6873434\ttotal: 43.3s\tremaining: 2m 39s\n128:\tlearn: 0.6821707\ttotal: 43.7s\tremaining: 2m 39s\n129:\tlearn: 0.6787655\ttotal: 44s\tremaining: 2m 39s\n130:\tlearn: 0.6744182\ttotal: 44.4s\tremaining: 2m 38s\n131:\tlearn: 0.6719399\ttotal: 44.7s\tremaining: 2m 38s\n132:\tlearn: 0.6660333\ttotal: 45s\tremaining: 2m 38s\n133:\tlearn: 0.6596658\ttotal: 45.4s\tremaining: 2m 37s\n134:\tlearn: 0.6577989\ttotal: 45.7s\tremaining: 2m 37s\n135:\tlearn: 0.6510612\ttotal: 46.1s\tremaining: 2m 37s\n136:\tlearn: 0.6465207\ttotal: 46.4s\tremaining: 2m 36s\n137:\tlearn: 0.6430623\ttotal: 46.8s\tremaining: 2m 36s\n138:\tlearn: 0.6402839\ttotal: 47.1s\tremaining: 2m 36s\n139:\tlearn: 0.6338929\ttotal: 47.4s\tremaining: 2m 35s\n140:\tlearn: 0.6277032\ttotal: 47.8s\tremaining: 2m 35s\n141:\tlearn: 0.6259752\ttotal: 48.1s\tremaining: 2m 35s\n142:\tlearn: 0.6253057\ttotal: 48.4s\tremaining: 2m 34s\n143:\tlearn: 0.6145984\ttotal: 48.8s\tremaining: 2m 34s\n144:\tlearn: 0.6107642\ttotal: 49.1s\tremaining: 2m 34s\n145:\tlearn: 0.6026995\ttotal: 49.5s\tremaining: 2m 33s\n146:\tlearn: 0.6000077\ttotal: 49.8s\tremaining: 2m 33s\n147:\tlearn: 0.5977235\ttotal: 50.2s\tremaining: 2m 33s\n148:\tlearn: 0.5967260\ttotal: 50.5s\tremaining: 2m 32s\n149:\tlearn: 0.5877043\ttotal: 50.8s\tremaining: 2m 32s\n150:\tlearn: 0.5858816\ttotal: 51.2s\tremaining: 2m 32s\n151:\tlearn: 0.5831798\ttotal: 51.5s\tremaining: 2m 31s\n152:\tlearn: 0.5764951\ttotal: 51.9s\tremaining: 2m 31s\n153:\tlearn: 0.5756162\ttotal: 52.2s\tremaining: 2m 31s\n154:\tlearn: 0.5716291\ttotal: 52.5s\tremaining: 2m 30s\n155:\tlearn: 0.5690064\ttotal: 52.9s\tremaining: 2m 30s\n156:\tlearn: 0.5666360\ttotal: 53.2s\tremaining: 2m 30s\n157:\tlearn: 0.5650761\ttotal: 53.6s\tremaining: 2m 29s\n158:\tlearn: 0.5640277\ttotal: 53.9s\tremaining: 2m 29s\n159:\tlearn: 0.5625439\ttotal: 54.2s\tremaining: 2m 29s\n160:\tlearn: 0.5615940\ttotal: 54.5s\tremaining: 2m 28s\n161:\tlearn: 0.5597045\ttotal: 54.9s\tremaining: 2m 28s\n162:\tlearn: 0.5582081\ttotal: 55.2s\tremaining: 2m 28s\n163:\tlearn: 0.5537967\ttotal: 55.6s\tremaining: 2m 27s\n164:\tlearn: 0.5512528\ttotal: 55.9s\tremaining: 2m 27s\n165:\tlearn: 0.5444898\ttotal: 56.2s\tremaining: 2m 27s\n166:\tlearn: 0.5392227\ttotal: 56.6s\tremaining: 2m 26s\n167:\tlearn: 0.5306632\ttotal: 56.9s\tremaining: 2m 26s\n168:\tlearn: 0.5263080\ttotal: 57.3s\tremaining: 2m 26s\n169:\tlearn: 0.5236961\ttotal: 57.6s\tremaining: 2m 25s\n170:\tlearn: 0.5205841\ttotal: 58s\tremaining: 2m 25s\n171:\tlearn: 0.5194326\ttotal: 58.3s\tremaining: 2m 25s\n172:\tlearn: 0.5184855\ttotal: 58.6s\tremaining: 2m 24s\n173:\tlearn: 0.5146557\ttotal: 59s\tremaining: 2m 24s\n174:\tlearn: 0.5131057\ttotal: 59.3s\tremaining: 2m 24s\n175:\tlearn: 0.5096528\ttotal: 59.7s\tremaining: 2m 23s\n176:\tlearn: 0.5062741\ttotal: 1m\tremaining: 2m 23s\n177:\tlearn: 0.5033802\ttotal: 1m\tremaining: 2m 23s\n178:\tlearn: 0.4975651\ttotal: 1m\tremaining: 2m 22s\n179:\tlearn: 0.4950048\ttotal: 1m 1s\tremaining: 2m 22s\n180:\tlearn: 0.4937722\ttotal: 1m 1s\tremaining: 2m 22s\n181:\tlearn: 0.4915776\ttotal: 1m 1s\tremaining: 2m 21s\n182:\tlearn: 0.4904891\ttotal: 1m 2s\tremaining: 2m 21s\n183:\tlearn: 0.4881826\ttotal: 1m 2s\tremaining: 2m 21s\n184:\tlearn: 0.4867005\ttotal: 1m 2s\tremaining: 2m 20s\n185:\tlearn: 0.4852344\ttotal: 1m 3s\tremaining: 2m 20s\n186:\tlearn: 0.4837422\ttotal: 1m 3s\tremaining: 2m 19s\n187:\tlearn: 0.4825049\ttotal: 1m 3s\tremaining: 2m 19s\n188:\tlearn: 0.4807668\ttotal: 1m 4s\tremaining: 2m 19s\n189:\tlearn: 0.4797088\ttotal: 1m 4s\tremaining: 2m 18s\n190:\tlearn: 0.4767565\ttotal: 1m 4s\tremaining: 2m 18s\n191:\tlearn: 0.4741544\ttotal: 1m 5s\tremaining: 2m 18s\n192:\tlearn: 0.4726208\ttotal: 1m 5s\tremaining: 2m 17s\n193:\tlearn: 0.4706342\ttotal: 1m 5s\tremaining: 2m 17s\n194:\tlearn: 0.4660941\ttotal: 1m 6s\tremaining: 2m 17s\n195:\tlearn: 0.4635114\ttotal: 1m 6s\tremaining: 2m 16s\n196:\tlearn: 0.4596367\ttotal: 1m 6s\tremaining: 2m 16s\n197:\tlearn: 0.4586538\ttotal: 1m 7s\tremaining: 2m 16s\n198:\tlearn: 0.4580653\ttotal: 1m 7s\tremaining: 2m 15s\n199:\tlearn: 0.4561997\ttotal: 1m 7s\tremaining: 2m 15s\n200:\tlearn: 0.4549413\ttotal: 1m 8s\tremaining: 2m 15s\n201:\tlearn: 0.4499254\ttotal: 1m 8s\tremaining: 2m 14s\n202:\tlearn: 0.4488550\ttotal: 1m 8s\tremaining: 2m 14s\n203:\tlearn: 0.4481240\ttotal: 1m 9s\tremaining: 2m 14s\n204:\tlearn: 0.4470704\ttotal: 1m 9s\tremaining: 2m 13s\n205:\tlearn: 0.4444892\ttotal: 1m 9s\tremaining: 2m 13s\n206:\tlearn: 0.4438744\ttotal: 1m 10s\tremaining: 2m 13s\n207:\tlearn: 0.4404871\ttotal: 1m 10s\tremaining: 2m 12s\n208:\tlearn: 0.4396541\ttotal: 1m 10s\tremaining: 2m 12s\n209:\tlearn: 0.4390733\ttotal: 1m 11s\tremaining: 2m 12s\n210:\tlearn: 0.4381724\ttotal: 1m 11s\tremaining: 2m 11s\n211:\tlearn: 0.4371259\ttotal: 1m 11s\tremaining: 2m 11s\n212:\tlearn: 0.4363241\ttotal: 1m 12s\tremaining: 2m 10s\n213:\tlearn: 0.4359096\ttotal: 1m 12s\tremaining: 2m 10s\n214:\tlearn: 0.4351638\ttotal: 1m 12s\tremaining: 2m 10s\n215:\tlearn: 0.4336504\ttotal: 1m 13s\tremaining: 2m 9s\n216:\tlearn: 0.4322765\ttotal: 1m 13s\tremaining: 2m 9s\n217:\tlearn: 0.4315205\ttotal: 1m 13s\tremaining: 2m 9s\n218:\tlearn: 0.4308979\ttotal: 1m 14s\tremaining: 2m 8s\n219:\tlearn: 0.4284132\ttotal: 1m 14s\tremaining: 2m 8s\n220:\tlearn: 0.4273236\ttotal: 1m 14s\tremaining: 2m 8s\n221:\tlearn: 0.4262821\ttotal: 1m 15s\tremaining: 2m 7s\n222:\tlearn: 0.4256139\ttotal: 1m 15s\tremaining: 2m 7s\n223:\tlearn: 0.4251555\ttotal: 1m 15s\tremaining: 2m 7s\n224:\tlearn: 0.4233107\ttotal: 1m 16s\tremaining: 2m 6s\n225:\tlearn: 0.4203650\ttotal: 1m 16s\tremaining: 2m 6s\n226:\tlearn: 0.4185369\ttotal: 1m 16s\tremaining: 2m 6s\n227:\tlearn: 0.4149661\ttotal: 1m 17s\tremaining: 2m 5s\n228:\tlearn: 0.4115864\ttotal: 1m 17s\tremaining: 2m 5s\n229:\tlearn: 0.4110134\ttotal: 1m 17s\tremaining: 2m 5s\n230:\tlearn: 0.4088184\ttotal: 1m 18s\tremaining: 2m 4s\n231:\tlearn: 0.4060964\ttotal: 1m 18s\tremaining: 2m 4s\n232:\tlearn: 0.4036479\ttotal: 1m 18s\tremaining: 2m 4s\n233:\tlearn: 0.4007746\ttotal: 1m 19s\tremaining: 2m 3s\n234:\tlearn: 0.4005492\ttotal: 1m 19s\tremaining: 2m 3s\n235:\tlearn: 0.3969850\ttotal: 1m 19s\tremaining: 2m 3s\n236:\tlearn: 0.3965832\ttotal: 1m 20s\tremaining: 2m 2s\n237:\tlearn: 0.3934758\ttotal: 1m 20s\tremaining: 2m 2s\n238:\tlearn: 0.3928985\ttotal: 1m 20s\tremaining: 2m 2s\n239:\tlearn: 0.3893837\ttotal: 1m 21s\tremaining: 2m 1s\n240:\tlearn: 0.3883319\ttotal: 1m 21s\tremaining: 2m 1s\n241:\tlearn: 0.3872762\ttotal: 1m 21s\tremaining: 2m 1s\n242:\tlearn: 0.3858681\ttotal: 1m 22s\tremaining: 2m\n243:\tlearn: 0.3838358\ttotal: 1m 22s\tremaining: 2m\n244:\tlearn: 0.3818118\ttotal: 1m 22s\tremaining: 2m\n245:\tlearn: 0.3800226\ttotal: 1m 23s\tremaining: 1m 59s\n246:\tlearn: 0.3789805\ttotal: 1m 23s\tremaining: 1m 59s\n247:\tlearn: 0.3785278\ttotal: 1m 23s\tremaining: 1m 59s\n248:\tlearn: 0.3774901\ttotal: 1m 24s\tremaining: 1m 58s\n249:\tlearn: 0.3771549\ttotal: 1m 24s\tremaining: 1m 58s\n250:\tlearn: 0.3764401\ttotal: 1m 24s\tremaining: 1m 58s\n251:\tlearn: 0.3754841\ttotal: 1m 25s\tremaining: 1m 57s\n252:\tlearn: 0.3752421\ttotal: 1m 25s\tremaining: 1m 57s\n253:\tlearn: 0.3728502\ttotal: 1m 25s\tremaining: 1m 57s\n254:\tlearn: 0.3721328\ttotal: 1m 26s\tremaining: 1m 56s\n255:\tlearn: 0.3710225\ttotal: 1m 26s\tremaining: 1m 56s\n256:\tlearn: 0.3700326\ttotal: 1m 26s\tremaining: 1m 56s\n257:\tlearn: 0.3673168\ttotal: 1m 27s\tremaining: 1m 55s\n258:\tlearn: 0.3668649\ttotal: 1m 27s\tremaining: 1m 55s\n259:\tlearn: 0.3663392\ttotal: 1m 27s\tremaining: 1m 54s\n260:\tlearn: 0.3657379\ttotal: 1m 28s\tremaining: 1m 54s\n261:\tlearn: 0.3646013\ttotal: 1m 28s\tremaining: 1m 54s\n262:\tlearn: 0.3638934\ttotal: 1m 28s\tremaining: 1m 53s\n263:\tlearn: 0.3636246\ttotal: 1m 29s\tremaining: 1m 53s\n264:\tlearn: 0.3633950\ttotal: 1m 29s\tremaining: 1m 53s\n265:\tlearn: 0.3628802\ttotal: 1m 29s\tremaining: 1m 52s\n266:\tlearn: 0.3603177\ttotal: 1m 30s\tremaining: 1m 52s\n267:\tlearn: 0.3597353\ttotal: 1m 30s\tremaining: 1m 52s\n268:\tlearn: 0.3591559\ttotal: 1m 30s\tremaining: 1m 51s\n269:\tlearn: 0.3582300\ttotal: 1m 31s\tremaining: 1m 51s\n270:\tlearn: 0.3578814\ttotal: 1m 31s\tremaining: 1m 51s\n271:\tlearn: 0.3564968\ttotal: 1m 31s\tremaining: 1m 50s\n272:\tlearn: 0.3560032\ttotal: 1m 32s\tremaining: 1m 50s\n273:\tlearn: 0.3556332\ttotal: 1m 32s\tremaining: 1m 50s\n274:\tlearn: 0.3541845\ttotal: 1m 32s\tremaining: 1m 49s\n275:\tlearn: 0.3532218\ttotal: 1m 33s\tremaining: 1m 49s\n276:\tlearn: 0.3530442\ttotal: 1m 33s\tremaining: 1m 49s\n277:\tlearn: 0.3527255\ttotal: 1m 33s\tremaining: 1m 48s\n278:\tlearn: 0.3522181\ttotal: 1m 34s\tremaining: 1m 48s\n279:\tlearn: 0.3512086\ttotal: 1m 34s\tremaining: 1m 48s\n280:\tlearn: 0.3502090\ttotal: 1m 34s\tremaining: 1m 47s\n281:\tlearn: 0.3495459\ttotal: 1m 35s\tremaining: 1m 47s\n282:\tlearn: 0.3487392\ttotal: 1m 35s\tremaining: 1m 47s\n283:\tlearn: 0.3483478\ttotal: 1m 35s\tremaining: 1m 46s\n284:\tlearn: 0.3480267\ttotal: 1m 36s\tremaining: 1m 46s\n285:\tlearn: 0.3473100\ttotal: 1m 36s\tremaining: 1m 46s\n286:\tlearn: 0.3470247\ttotal: 1m 36s\tremaining: 1m 45s\n287:\tlearn: 0.3466974\ttotal: 1m 37s\tremaining: 1m 45s\n288:\tlearn: 0.3458295\ttotal: 1m 37s\tremaining: 1m 45s\n289:\tlearn: 0.3456479\ttotal: 1m 37s\tremaining: 1m 44s\n290:\tlearn: 0.3451747\ttotal: 1m 38s\tremaining: 1m 44s\n291:\tlearn: 0.3448692\ttotal: 1m 38s\tremaining: 1m 44s\n292:\tlearn: 0.3447314\ttotal: 1m 38s\tremaining: 1m 43s\n293:\tlearn: 0.3445672\ttotal: 1m 39s\tremaining: 1m 43s\n294:\tlearn: 0.3438815\ttotal: 1m 39s\tremaining: 1m 43s\n295:\tlearn: 0.3424689\ttotal: 1m 39s\tremaining: 1m 42s\n296:\tlearn: 0.3422029\ttotal: 1m 40s\tremaining: 1m 42s\n297:\tlearn: 0.3415694\ttotal: 1m 40s\tremaining: 1m 41s\n298:\tlearn: 0.3410059\ttotal: 1m 40s\tremaining: 1m 41s\n299:\tlearn: 0.3405902\ttotal: 1m 41s\tremaining: 1m 41s\n300:\tlearn: 0.3400923\ttotal: 1m 41s\tremaining: 1m 40s\n301:\tlearn: 0.3399240\ttotal: 1m 41s\tremaining: 1m 40s\n302:\tlearn: 0.3390442\ttotal: 1m 42s\tremaining: 1m 40s\n303:\tlearn: 0.3388532\ttotal: 1m 42s\tremaining: 1m 39s\n304:\tlearn: 0.3384231\ttotal: 1m 42s\tremaining: 1m 39s\n305:\tlearn: 0.3379906\ttotal: 1m 43s\tremaining: 1m 39s\n306:\tlearn: 0.3374798\ttotal: 1m 43s\tremaining: 1m 38s\n307:\tlearn: 0.3358281\ttotal: 1m 43s\tremaining: 1m 38s\n308:\tlearn: 0.3350127\ttotal: 1m 44s\tremaining: 1m 38s\n309:\tlearn: 0.3347106\ttotal: 1m 44s\tremaining: 1m 37s\n310:\tlearn: 0.3338804\ttotal: 1m 44s\tremaining: 1m 37s\n311:\tlearn: 0.3321004\ttotal: 1m 45s\tremaining: 1m 37s\n312:\tlearn: 0.3306499\ttotal: 1m 45s\tremaining: 1m 36s\n313:\tlearn: 0.3299540\ttotal: 1m 45s\tremaining: 1m 36s\n314:\tlearn: 0.3296556\ttotal: 1m 46s\tremaining: 1m 36s\n315:\tlearn: 0.3291286\ttotal: 1m 46s\tremaining: 1m 35s\n316:\tlearn: 0.3285026\ttotal: 1m 47s\tremaining: 1m 35s\n317:\tlearn: 0.3282423\ttotal: 1m 47s\tremaining: 1m 35s\n318:\tlearn: 0.3280177\ttotal: 1m 47s\tremaining: 1m 34s\n319:\tlearn: 0.3278476\ttotal: 1m 48s\tremaining: 1m 34s\n320:\tlearn: 0.3272437\ttotal: 1m 48s\tremaining: 1m 34s\n321:\tlearn: 0.3268048\ttotal: 1m 48s\tremaining: 1m 33s\n322:\tlearn: 0.3265030\ttotal: 1m 49s\tremaining: 1m 33s\n323:\tlearn: 0.3258931\ttotal: 1m 49s\tremaining: 1m 33s\n324:\tlearn: 0.3246765\ttotal: 1m 49s\tremaining: 1m 32s\n325:\tlearn: 0.3244565\ttotal: 1m 50s\tremaining: 1m 32s\n326:\tlearn: 0.3230338\ttotal: 1m 50s\tremaining: 1m 32s\n327:\tlearn: 0.3226087\ttotal: 1m 50s\tremaining: 1m 31s\n328:\tlearn: 0.3220451\ttotal: 1m 51s\tremaining: 1m 31s\n329:\tlearn: 0.3211752\ttotal: 1m 51s\tremaining: 1m 31s\n330:\tlearn: 0.3210026\ttotal: 1m 51s\tremaining: 1m 30s\n331:\tlearn: 0.3190369\ttotal: 1m 52s\tremaining: 1m 30s\n332:\tlearn: 0.3189482\ttotal: 1m 52s\tremaining: 1m 30s\n333:\tlearn: 0.3186870\ttotal: 1m 52s\tremaining: 1m 29s\n334:\tlearn: 0.3178389\ttotal: 1m 53s\tremaining: 1m 29s\n335:\tlearn: 0.3176720\ttotal: 1m 53s\tremaining: 1m 29s\n336:\tlearn: 0.3164921\ttotal: 1m 53s\tremaining: 1m 28s\n337:\tlearn: 0.3161664\ttotal: 1m 54s\tremaining: 1m 28s\n338:\tlearn: 0.3156052\ttotal: 1m 54s\tremaining: 1m 28s\n339:\tlearn: 0.3149102\ttotal: 1m 54s\tremaining: 1m 27s\n340:\tlearn: 0.3140356\ttotal: 1m 55s\tremaining: 1m 27s\n341:\tlearn: 0.3134622\ttotal: 1m 55s\tremaining: 1m 27s\n342:\tlearn: 0.3119662\ttotal: 1m 55s\tremaining: 1m 26s\n343:\tlearn: 0.3114111\ttotal: 1m 56s\tremaining: 1m 26s\n344:\tlearn: 0.3111929\ttotal: 1m 56s\tremaining: 1m 26s\n345:\tlearn: 0.3095008\ttotal: 1m 56s\tremaining: 1m 25s\n346:\tlearn: 0.3090853\ttotal: 1m 57s\tremaining: 1m 25s\n347:\tlearn: 0.3084007\ttotal: 1m 57s\tremaining: 1m 25s\n348:\tlearn: 0.3078353\ttotal: 1m 57s\tremaining: 1m 24s\n349:\tlearn: 0.3074314\ttotal: 1m 58s\tremaining: 1m 24s\n350:\tlearn: 0.3072335\ttotal: 1m 58s\tremaining: 1m 24s\n351:\tlearn: 0.3071383\ttotal: 1m 58s\tremaining: 1m 23s\n352:\tlearn: 0.3061764\ttotal: 1m 59s\tremaining: 1m 23s\n353:\tlearn: 0.3055268\ttotal: 1m 59s\tremaining: 1m 23s\n354:\tlearn: 0.3052167\ttotal: 1m 59s\tremaining: 1m 22s\n355:\tlearn: 0.3050411\ttotal: 2m\tremaining: 1m 22s\n356:\tlearn: 0.3048698\ttotal: 2m\tremaining: 1m 21s\n357:\tlearn: 0.3041153\ttotal: 2m\tremaining: 1m 21s\n358:\tlearn: 0.3030445\ttotal: 2m 1s\tremaining: 1m 21s\n359:\tlearn: 0.3021409\ttotal: 2m 1s\tremaining: 1m 20s\n360:\tlearn: 0.3013788\ttotal: 2m 1s\tremaining: 1m 20s\n361:\tlearn: 0.3008970\ttotal: 2m 2s\tremaining: 1m 20s\n362:\tlearn: 0.3004873\ttotal: 2m 2s\tremaining: 1m 19s\n363:\tlearn: 0.3001629\ttotal: 2m 2s\tremaining: 1m 19s\n364:\tlearn: 0.2990273\ttotal: 2m 3s\tremaining: 1m 19s\n365:\tlearn: 0.2986879\ttotal: 2m 3s\tremaining: 1m 18s\n366:\tlearn: 0.2985539\ttotal: 2m 3s\tremaining: 1m 18s\n367:\tlearn: 0.2975941\ttotal: 2m 4s\tremaining: 1m 18s\n368:\tlearn: 0.2974057\ttotal: 2m 4s\tremaining: 1m 17s\n369:\tlearn: 0.2972405\ttotal: 2m 4s\tremaining: 1m 17s\n370:\tlearn: 0.2970774\ttotal: 2m 5s\tremaining: 1m 17s\n371:\tlearn: 0.2969495\ttotal: 2m 5s\tremaining: 1m 16s\n372:\tlearn: 0.2968611\ttotal: 2m 5s\tremaining: 1m 16s\n373:\tlearn: 0.2963581\ttotal: 2m 6s\tremaining: 1m 16s\n374:\tlearn: 0.2962929\ttotal: 2m 6s\tremaining: 1m 15s\n375:\tlearn: 0.2959833\ttotal: 2m 6s\tremaining: 1m 15s\n376:\tlearn: 0.2958615\ttotal: 2m 7s\tremaining: 1m 15s\n377:\tlearn: 0.2957512\ttotal: 2m 7s\tremaining: 1m 14s\n378:\tlearn: 0.2926477\ttotal: 2m 7s\tremaining: 1m 14s\n379:\tlearn: 0.2922189\ttotal: 2m 8s\tremaining: 1m 14s\n380:\tlearn: 0.2919342\ttotal: 2m 8s\tremaining: 1m 13s\n381:\tlearn: 0.2916701\ttotal: 2m 8s\tremaining: 1m 13s\n382:\tlearn: 0.2899963\ttotal: 2m 9s\tremaining: 1m 13s\n383:\tlearn: 0.2896294\ttotal: 2m 9s\tremaining: 1m 12s\n384:\tlearn: 0.2892061\ttotal: 2m 9s\tremaining: 1m 12s\n385:\tlearn: 0.2890264\ttotal: 2m 10s\tremaining: 1m 12s\n386:\tlearn: 0.2889900\ttotal: 2m 10s\tremaining: 1m 11s\n387:\tlearn: 0.2889235\ttotal: 2m 10s\tremaining: 1m 11s\n388:\tlearn: 0.2888009\ttotal: 2m 11s\tremaining: 1m 11s\n389:\tlearn: 0.2887326\ttotal: 2m 11s\tremaining: 1m 10s\n390:\tlearn: 0.2885937\ttotal: 2m 11s\tremaining: 1m 10s\n391:\tlearn: 0.2885217\ttotal: 2m 12s\tremaining: 1m 10s\n392:\tlearn: 0.2860124\ttotal: 2m 12s\tremaining: 1m 9s\n393:\tlearn: 0.2854969\ttotal: 2m 12s\tremaining: 1m 9s\n394:\tlearn: 0.2853917\ttotal: 2m 13s\tremaining: 1m 9s\n395:\tlearn: 0.2849709\ttotal: 2m 13s\tremaining: 1m 8s\n396:\tlearn: 0.2843691\ttotal: 2m 13s\tremaining: 1m 8s\n397:\tlearn: 0.2842061\ttotal: 2m 14s\tremaining: 1m 8s\n398:\tlearn: 0.2840050\ttotal: 2m 14s\tremaining: 1m 7s\n399:\tlearn: 0.2825639\ttotal: 2m 14s\tremaining: 1m 7s\n400:\tlearn: 0.2818850\ttotal: 2m 15s\tremaining: 1m 7s\n401:\tlearn: 0.2818027\ttotal: 2m 15s\tremaining: 1m 6s\n402:\tlearn: 0.2814420\ttotal: 2m 15s\tremaining: 1m 6s\n403:\tlearn: 0.2813321\ttotal: 2m 16s\tremaining: 1m 6s\n404:\tlearn: 0.2811070\ttotal: 2m 16s\tremaining: 1m 5s\n405:\tlearn: 0.2806378\ttotal: 2m 16s\tremaining: 1m 5s\n406:\tlearn: 0.2804970\ttotal: 2m 17s\tremaining: 1m 5s\n407:\tlearn: 0.2790952\ttotal: 2m 17s\tremaining: 1m 4s\n408:\tlearn: 0.2789245\ttotal: 2m 17s\tremaining: 1m 4s\n409:\tlearn: 0.2786600\ttotal: 2m 18s\tremaining: 1m 4s\n410:\tlearn: 0.2786024\ttotal: 2m 18s\tremaining: 1m 3s\n411:\tlearn: 0.2781422\ttotal: 2m 18s\tremaining: 1m 3s\n412:\tlearn: 0.2778817\ttotal: 2m 19s\tremaining: 1m 3s\n413:\tlearn: 0.2776274\ttotal: 2m 19s\tremaining: 1m 2s\n414:\tlearn: 0.2774420\ttotal: 2m 19s\tremaining: 1m 2s\n415:\tlearn: 0.2767285\ttotal: 2m 20s\tremaining: 1m 2s\n416:\tlearn: 0.2766437\ttotal: 2m 20s\tremaining: 1m 1s\n417:\tlearn: 0.2764121\ttotal: 2m 20s\tremaining: 1m 1s\n418:\tlearn: 0.2762265\ttotal: 2m 21s\tremaining: 1m 1s\n419:\tlearn: 0.2760224\ttotal: 2m 21s\tremaining: 1m\n420:\tlearn: 0.2752682\ttotal: 2m 21s\tremaining: 1m\n421:\tlearn: 0.2749811\ttotal: 2m 22s\tremaining: 1m\n422:\tlearn: 0.2748368\ttotal: 2m 22s\tremaining: 59.7s\n423:\tlearn: 0.2733696\ttotal: 2m 22s\tremaining: 59.3s\n424:\tlearn: 0.2732088\ttotal: 2m 23s\tremaining: 59s\n425:\tlearn: 0.2729519\ttotal: 2m 23s\tremaining: 58.7s\n426:\tlearn: 0.2724928\ttotal: 2m 23s\tremaining: 58.3s\n427:\tlearn: 0.2723481\ttotal: 2m 24s\tremaining: 58s\n428:\tlearn: 0.2722150\ttotal: 2m 24s\tremaining: 57.7s\n429:\tlearn: 0.2720542\ttotal: 2m 24s\tremaining: 57.3s\n430:\tlearn: 0.2716611\ttotal: 2m 25s\tremaining: 57s\n431:\tlearn: 0.2714638\ttotal: 2m 25s\tremaining: 56.6s\n432:\tlearn: 0.2709442\ttotal: 2m 25s\tremaining: 56.3s\n433:\tlearn: 0.2705787\ttotal: 2m 26s\tremaining: 56s\n434:\tlearn: 0.2702092\ttotal: 2m 26s\tremaining: 55.6s\n435:\tlearn: 0.2700053\ttotal: 2m 26s\tremaining: 55.3s\n436:\tlearn: 0.2697183\ttotal: 2m 27s\tremaining: 54.9s\n437:\tlearn: 0.2692054\ttotal: 2m 27s\tremaining: 54.6s\n438:\tlearn: 0.2688430\ttotal: 2m 27s\tremaining: 54.3s\n439:\tlearn: 0.2681696\ttotal: 2m 28s\tremaining: 53.9s\n440:\tlearn: 0.2680608\ttotal: 2m 28s\tremaining: 53.6s\n441:\tlearn: 0.2677892\ttotal: 2m 28s\tremaining: 53.3s\n442:\tlearn: 0.2669134\ttotal: 2m 29s\tremaining: 52.9s\n443:\tlearn: 0.2667229\ttotal: 2m 29s\tremaining: 52.6s\n444:\tlearn: 0.2663939\ttotal: 2m 30s\tremaining: 52.2s\n445:\tlearn: 0.2662284\ttotal: 2m 30s\tremaining: 51.9s\n446:\tlearn: 0.2660838\ttotal: 2m 30s\tremaining: 51.6s\n447:\tlearn: 0.2652546\ttotal: 2m 31s\tremaining: 51.2s\n448:\tlearn: 0.2649113\ttotal: 2m 31s\tremaining: 50.9s\n449:\tlearn: 0.2646264\ttotal: 2m 31s\tremaining: 50.6s\n450:\tlearn: 0.2640092\ttotal: 2m 32s\tremaining: 50.2s\n451:\tlearn: 0.2639315\ttotal: 2m 32s\tremaining: 49.9s\n452:\tlearn: 0.2635818\ttotal: 2m 32s\tremaining: 49.5s\n453:\tlearn: 0.2634546\ttotal: 2m 33s\tremaining: 49.2s\n454:\tlearn: 0.2633266\ttotal: 2m 33s\tremaining: 48.9s\n455:\tlearn: 0.2624830\ttotal: 2m 33s\tremaining: 48.5s\n456:\tlearn: 0.2619488\ttotal: 2m 34s\tremaining: 48.2s\n457:\tlearn: 0.2612975\ttotal: 2m 34s\tremaining: 47.9s\n458:\tlearn: 0.2612228\ttotal: 2m 34s\tremaining: 47.5s\n459:\tlearn: 0.2610867\ttotal: 2m 35s\tremaining: 47.2s\n460:\tlearn: 0.2608449\ttotal: 2m 35s\tremaining: 46.8s\n461:\tlearn: 0.2607459\ttotal: 2m 35s\tremaining: 46.5s\n462:\tlearn: 0.2605741\ttotal: 2m 36s\tremaining: 46.2s\n463:\tlearn: 0.2603606\ttotal: 2m 36s\tremaining: 45.8s\n464:\tlearn: 0.2602481\ttotal: 2m 36s\tremaining: 45.5s\n465:\tlearn: 0.2601970\ttotal: 2m 37s\tremaining: 45.2s\n466:\tlearn: 0.2600809\ttotal: 2m 37s\tremaining: 44.8s\n467:\tlearn: 0.2599912\ttotal: 2m 37s\tremaining: 44.5s\n468:\tlearn: 0.2598910\ttotal: 2m 38s\tremaining: 44.1s\n469:\tlearn: 0.2598355\ttotal: 2m 38s\tremaining: 43.8s\n470:\tlearn: 0.2596301\ttotal: 2m 38s\tremaining: 43.5s\n471:\tlearn: 0.2577545\ttotal: 2m 39s\tremaining: 43.1s\n472:\tlearn: 0.2574333\ttotal: 2m 39s\tremaining: 42.8s\n473:\tlearn: 0.2573892\ttotal: 2m 39s\tremaining: 42.5s\n474:\tlearn: 0.2567864\ttotal: 2m 40s\tremaining: 42.1s\n475:\tlearn: 0.2565903\ttotal: 2m 40s\tremaining: 41.8s\n476:\tlearn: 0.2562889\ttotal: 2m 40s\tremaining: 41.4s\n477:\tlearn: 0.2558736\ttotal: 2m 41s\tremaining: 41.1s\n478:\tlearn: 0.2550624\ttotal: 2m 41s\tremaining: 40.8s\n479:\tlearn: 0.2549058\ttotal: 2m 41s\tremaining: 40.4s\n480:\tlearn: 0.2545588\ttotal: 2m 42s\tremaining: 40.1s\n481:\tlearn: 0.2544473\ttotal: 2m 42s\tremaining: 39.8s\n482:\tlearn: 0.2543833\ttotal: 2m 42s\tremaining: 39.4s\n483:\tlearn: 0.2541775\ttotal: 2m 43s\tremaining: 39.1s\n484:\tlearn: 0.2540892\ttotal: 2m 43s\tremaining: 38.7s\n485:\tlearn: 0.2538434\ttotal: 2m 43s\tremaining: 38.4s\n486:\tlearn: 0.2537359\ttotal: 2m 44s\tremaining: 38.1s\n487:\tlearn: 0.2536559\ttotal: 2m 44s\tremaining: 37.7s\n488:\tlearn: 0.2532882\ttotal: 2m 44s\tremaining: 37.4s\n489:\tlearn: 0.2532275\ttotal: 2m 45s\tremaining: 37s\n490:\tlearn: 0.2514730\ttotal: 2m 45s\tremaining: 36.7s\n491:\tlearn: 0.2513768\ttotal: 2m 45s\tremaining: 36.4s\n492:\tlearn: 0.2512312\ttotal: 2m 46s\tremaining: 36s\n493:\tlearn: 0.2510198\ttotal: 2m 46s\tremaining: 35.7s\n494:\tlearn: 0.2509508\ttotal: 2m 46s\tremaining: 35.4s\n495:\tlearn: 0.2504005\ttotal: 2m 47s\tremaining: 35s\n496:\tlearn: 0.2499269\ttotal: 2m 47s\tremaining: 34.7s\n497:\tlearn: 0.2498811\ttotal: 2m 47s\tremaining: 34.4s\n498:\tlearn: 0.2495931\ttotal: 2m 48s\tremaining: 34s\n499:\tlearn: 0.2494172\ttotal: 2m 48s\tremaining: 33.7s\n500:\tlearn: 0.2491454\ttotal: 2m 48s\tremaining: 33.3s\n501:\tlearn: 0.2490827\ttotal: 2m 49s\tremaining: 33s\n502:\tlearn: 0.2487774\ttotal: 2m 49s\tremaining: 32.7s\n503:\tlearn: 0.2480340\ttotal: 2m 49s\tremaining: 32.3s\n504:\tlearn: 0.2477232\ttotal: 2m 50s\tremaining: 32s\n505:\tlearn: 0.2476051\ttotal: 2m 50s\tremaining: 31.7s\n506:\tlearn: 0.2475222\ttotal: 2m 50s\tremaining: 31.3s\n507:\tlearn: 0.2473516\ttotal: 2m 51s\tremaining: 31s\n508:\tlearn: 0.2472549\ttotal: 2m 51s\tremaining: 30.6s\n509:\tlearn: 0.2470828\ttotal: 2m 51s\tremaining: 30.3s\n510:\tlearn: 0.2469605\ttotal: 2m 52s\tremaining: 30s\n511:\tlearn: 0.2467465\ttotal: 2m 52s\tremaining: 29.6s\n512:\tlearn: 0.2462839\ttotal: 2m 52s\tremaining: 29.3s\n513:\tlearn: 0.2462164\ttotal: 2m 53s\tremaining: 29s\n514:\tlearn: 0.2461786\ttotal: 2m 53s\tremaining: 28.6s\n515:\tlearn: 0.2460452\ttotal: 2m 53s\tremaining: 28.3s\n516:\tlearn: 0.2459021\ttotal: 2m 54s\tremaining: 27.9s\n517:\tlearn: 0.2458220\ttotal: 2m 54s\tremaining: 27.6s\n518:\tlearn: 0.2457557\ttotal: 2m 54s\tremaining: 27.3s\n519:\tlearn: 0.2456872\ttotal: 2m 55s\tremaining: 26.9s\n520:\tlearn: 0.2456427\ttotal: 2m 55s\tremaining: 26.6s\n521:\tlearn: 0.2455599\ttotal: 2m 55s\tremaining: 26.3s\n522:\tlearn: 0.2453841\ttotal: 2m 56s\tremaining: 25.9s\n523:\tlearn: 0.2452703\ttotal: 2m 56s\tremaining: 25.6s\n524:\tlearn: 0.2446439\ttotal: 2m 56s\tremaining: 25.2s\n525:\tlearn: 0.2444760\ttotal: 2m 57s\tremaining: 24.9s\n526:\tlearn: 0.2440993\ttotal: 2m 57s\tremaining: 24.6s\n527:\tlearn: 0.2438212\ttotal: 2m 57s\tremaining: 24.2s\n528:\tlearn: 0.2435923\ttotal: 2m 58s\tremaining: 23.9s\n529:\tlearn: 0.2433653\ttotal: 2m 58s\tremaining: 23.6s\n530:\tlearn: 0.2428449\ttotal: 2m 58s\tremaining: 23.2s\n531:\tlearn: 0.2427772\ttotal: 2m 59s\tremaining: 22.9s\n532:\tlearn: 0.2425694\ttotal: 2m 59s\tremaining: 22.6s\n533:\tlearn: 0.2425173\ttotal: 2m 59s\tremaining: 22.2s\n534:\tlearn: 0.2423412\ttotal: 3m\tremaining: 21.9s\n535:\tlearn: 0.2422375\ttotal: 3m\tremaining: 21.5s\n536:\tlearn: 0.2421921\ttotal: 3m\tremaining: 21.2s\n537:\tlearn: 0.2421528\ttotal: 3m 1s\tremaining: 20.9s\n538:\tlearn: 0.2419140\ttotal: 3m 1s\tremaining: 20.5s\n539:\tlearn: 0.2415396\ttotal: 3m 1s\tremaining: 20.2s\n540:\tlearn: 0.2413204\ttotal: 3m 2s\tremaining: 19.9s\n541:\tlearn: 0.2412059\ttotal: 3m 2s\tremaining: 19.5s\n542:\tlearn: 0.2410406\ttotal: 3m 2s\tremaining: 19.2s\n543:\tlearn: 0.2409794\ttotal: 3m 3s\tremaining: 18.8s\n544:\tlearn: 0.2408380\ttotal: 3m 3s\tremaining: 18.5s\n545:\tlearn: 0.2407388\ttotal: 3m 3s\tremaining: 18.2s\n546:\tlearn: 0.2403938\ttotal: 3m 4s\tremaining: 17.8s\n547:\tlearn: 0.2402446\ttotal: 3m 4s\tremaining: 17.5s\n548:\tlearn: 0.2401331\ttotal: 3m 4s\tremaining: 17.2s\n549:\tlearn: 0.2398731\ttotal: 3m 5s\tremaining: 16.8s\n550:\tlearn: 0.2392750\ttotal: 3m 5s\tremaining: 16.5s\n551:\tlearn: 0.2391011\ttotal: 3m 5s\tremaining: 16.2s\n552:\tlearn: 0.2389612\ttotal: 3m 6s\tremaining: 15.8s\n553:\tlearn: 0.2388610\ttotal: 3m 6s\tremaining: 15.5s\n554:\tlearn: 0.2386036\ttotal: 3m 6s\tremaining: 15.1s\n555:\tlearn: 0.2367792\ttotal: 3m 7s\tremaining: 14.8s\n556:\tlearn: 0.2366837\ttotal: 3m 7s\tremaining: 14.5s\n557:\tlearn: 0.2362763\ttotal: 3m 7s\tremaining: 14.1s\n558:\tlearn: 0.2358593\ttotal: 3m 8s\tremaining: 13.8s\n559:\tlearn: 0.2357866\ttotal: 3m 8s\tremaining: 13.5s\n560:\tlearn: 0.2352064\ttotal: 3m 8s\tremaining: 13.1s\n561:\tlearn: 0.2350925\ttotal: 3m 9s\tremaining: 12.8s\n562:\tlearn: 0.2340897\ttotal: 3m 9s\tremaining: 12.4s\n563:\tlearn: 0.2320336\ttotal: 3m 9s\tremaining: 12.1s\n564:\tlearn: 0.2317938\ttotal: 3m 10s\tremaining: 11.8s\n565:\tlearn: 0.2316691\ttotal: 3m 10s\tremaining: 11.4s\n566:\tlearn: 0.2316236\ttotal: 3m 10s\tremaining: 11.1s\n567:\tlearn: 0.2315064\ttotal: 3m 11s\tremaining: 10.8s\n568:\tlearn: 0.2312778\ttotal: 3m 11s\tremaining: 10.4s\n569:\tlearn: 0.2310113\ttotal: 3m 11s\tremaining: 10.1s\n570:\tlearn: 0.2301444\ttotal: 3m 12s\tremaining: 9.76s\n571:\tlearn: 0.2297789\ttotal: 3m 12s\tremaining: 9.42s\n572:\tlearn: 0.2296908\ttotal: 3m 12s\tremaining: 9.08s\n573:\tlearn: 0.2294930\ttotal: 3m 13s\tremaining: 8.75s\n574:\tlearn: 0.2284489\ttotal: 3m 13s\tremaining: 8.41s\n575:\tlearn: 0.2284211\ttotal: 3m 13s\tremaining: 8.07s\n576:\tlearn: 0.2274553\ttotal: 3m 14s\tremaining: 7.74s\n577:\tlearn: 0.2274058\ttotal: 3m 14s\tremaining: 7.4s\n578:\tlearn: 0.2272647\ttotal: 3m 14s\tremaining: 7.07s\n579:\tlearn: 0.2271897\ttotal: 3m 15s\tremaining: 6.73s\n580:\tlearn: 0.2270632\ttotal: 3m 15s\tremaining: 6.39s\n581:\tlearn: 0.2268723\ttotal: 3m 15s\tremaining: 6.06s\n582:\tlearn: 0.2268043\ttotal: 3m 16s\tremaining: 5.72s\n583:\tlearn: 0.2267352\ttotal: 3m 16s\tremaining: 5.38s\n584:\tlearn: 0.2265368\ttotal: 3m 16s\tremaining: 5.05s\n585:\tlearn: 0.2264677\ttotal: 3m 17s\tremaining: 4.71s\n586:\tlearn: 0.2260906\ttotal: 3m 17s\tremaining: 4.37s\n587:\tlearn: 0.2260544\ttotal: 3m 17s\tremaining: 4.04s\n588:\tlearn: 0.2260020\ttotal: 3m 18s\tremaining: 3.7s\n589:\tlearn: 0.2259091\ttotal: 3m 18s\tremaining: 3.36s\n590:\tlearn: 0.2257064\ttotal: 3m 18s\tremaining: 3.03s\n591:\tlearn: 0.2256335\ttotal: 3m 19s\tremaining: 2.69s\n592:\tlearn: 0.2255946\ttotal: 3m 19s\tremaining: 2.35s\n593:\tlearn: 0.2255315\ttotal: 3m 19s\tremaining: 2.02s\n594:\tlearn: 0.2254309\ttotal: 3m 20s\tremaining: 1.68s\n595:\tlearn: 0.2251618\ttotal: 3m 20s\tremaining: 1.34s\n596:\tlearn: 0.2250662\ttotal: 3m 20s\tremaining: 1.01s\n597:\tlearn: 0.2250286\ttotal: 3m 21s\tremaining: 673ms\n598:\tlearn: 0.2249756\ttotal: 3m 21s\tremaining: 336ms\n599:\tlearn: 0.2248950\ttotal: 3m 21s\tremaining: 0us\ncat_fit_done\nmodel_ready\n0:\tlearn: 2.1989043\ttotal: 460ms\tremaining: 4m 35s\n1:\tlearn: 2.1575768\ttotal: 910ms\tremaining: 4m 32s\n2:\tlearn: 2.1092197\ttotal: 1.37s\tremaining: 4m 33s\n3:\tlearn: 2.0542984\ttotal: 1.85s\tremaining: 4m 36s\n4:\tlearn: 2.0160414\ttotal: 2.31s\tremaining: 4m 35s\n5:\tlearn: 1.9743098\ttotal: 2.78s\tremaining: 4m 35s\n6:\tlearn: 1.9450325\ttotal: 3.23s\tremaining: 4m 34s\n7:\tlearn: 1.9086563\ttotal: 3.72s\tremaining: 4m 35s\n8:\tlearn: 1.8713050\ttotal: 4.19s\tremaining: 4m 34s\n9:\tlearn: 1.8402124\ttotal: 4.66s\tremaining: 4m 34s\n10:\tlearn: 1.8198796\ttotal: 5.11s\tremaining: 4m 33s\n11:\tlearn: 1.7962211\ttotal: 5.57s\tremaining: 4m 33s\n12:\tlearn: 1.7757909\ttotal: 6.03s\tremaining: 4m 32s\n13:\tlearn: 1.7473081\ttotal: 6.52s\tremaining: 4m 32s\n13:\tlearn: 1.7473081\ttotal: 6.52s\tremaining: 4m 32s\n14:\tlearn: 1.7283699\ttotal: 6.97s\tremaining: 4m 32s\n15:\tlearn: 1.7129369\ttotal: 7.43s\tremaining: 4m 31s\n16:\tlearn: 1.6897774\ttotal: 7.88s\tremaining: 4m 30s\n17:\tlearn: 1.6763387\ttotal: 8.34s\tremaining: 4m 29s\n18:\tlearn: 1.6592090\ttotal: 8.8s\tremaining: 4m 29s\n19:\tlearn: 1.6470025\ttotal: 9.25s\tremaining: 4m 28s\n20:\tlearn: 1.6305828\ttotal: 9.71s\tremaining: 4m 27s\n21:\tlearn: 1.6148420\ttotal: 10.2s\tremaining: 4m 27s\n22:\tlearn: 1.6039817\ttotal: 10.7s\tremaining: 4m 27s\n23:\tlearn: 1.5891174\ttotal: 11.1s\tremaining: 4m 26s\n24:\tlearn: 1.5771912\ttotal: 11.6s\tremaining: 4m 26s\n25:\tlearn: 1.5701174\ttotal: 12s\tremaining: 4m 25s\n26:\tlearn: 1.5613164\ttotal: 12.5s\tremaining: 4m 24s\n27:\tlearn: 1.5444271\ttotal: 12.9s\tremaining: 4m 24s\n28:\tlearn: 1.5284118\ttotal: 13.4s\tremaining: 4m 24s\n29:\tlearn: 1.5121448\ttotal: 13.9s\tremaining: 4m 24s\n30:\tlearn: 1.5021460\ttotal: 14.4s\tremaining: 4m 23s\n31:\tlearn: 1.4942263\ttotal: 14.8s\tremaining: 4m 22s\n32:\tlearn: 1.4808550\ttotal: 15.3s\tremaining: 4m 22s\n33:\tlearn: 1.4749659\ttotal: 15.7s\tremaining: 4m 21s\n34:\tlearn: 1.4600173\ttotal: 16.2s\tremaining: 4m 21s\n35:\tlearn: 1.4497139\ttotal: 16.7s\tremaining: 4m 20s\n36:\tlearn: 1.4419941\ttotal: 17.1s\tremaining: 4m 20s\n37:\tlearn: 1.4348185\ttotal: 17.6s\tremaining: 4m 19s\n38:\tlearn: 1.4268974\ttotal: 18s\tremaining: 4m 19s\n39:\tlearn: 1.4169370\ttotal: 18.5s\tremaining: 4m 18s\n40:\tlearn: 1.4073579\ttotal: 18.9s\tremaining: 4m 18s\n41:\tlearn: 1.4026074\ttotal: 19.4s\tremaining: 4m 17s\n42:\tlearn: 1.3960452\ttotal: 19.8s\tremaining: 4m 16s\n43:\tlearn: 1.3856573\ttotal: 20.3s\tremaining: 4m 16s\n44:\tlearn: 1.3811749\ttotal: 20.8s\tremaining: 4m 16s\n45:\tlearn: 1.3776977\ttotal: 21.2s\tremaining: 4m 15s\n46:\tlearn: 1.3759719\ttotal: 21.7s\tremaining: 4m 14s\n47:\tlearn: 1.3686735\ttotal: 22.1s\tremaining: 4m 14s\n48:\tlearn: 1.3604770\ttotal: 22.6s\tremaining: 4m 13s\n49:\tlearn: 1.3520473\ttotal: 23s\tremaining: 4m 13s\n50:\tlearn: 1.3459032\ttotal: 23.5s\tremaining: 4m 12s\n51:\tlearn: 1.3404574\ttotal: 23.9s\tremaining: 4m 12s\n52:\tlearn: 1.3287982\ttotal: 24.4s\tremaining: 4m 12s\n53:\tlearn: 1.3215768\ttotal: 24.9s\tremaining: 4m 11s\n54:\tlearn: 1.3168157\ttotal: 25.3s\tremaining: 4m 11s\n55:\tlearn: 1.3131660\ttotal: 25.8s\tremaining: 4m 10s\n56:\tlearn: 1.3071618\ttotal: 26.2s\tremaining: 4m 9s\n57:\tlearn: 1.3056854\ttotal: 26.7s\tremaining: 4m 9s\n58:\tlearn: 1.2952174\ttotal: 27.1s\tremaining: 4m 8s\n59:\tlearn: 1.2892991\ttotal: 27.6s\tremaining: 4m 8s\n60:\tlearn: 1.2828783\ttotal: 28s\tremaining: 4m 7s\n61:\tlearn: 1.2794061\ttotal: 28.5s\tremaining: 4m 7s\n62:\tlearn: 1.2744358\ttotal: 29s\tremaining: 4m 6s\n63:\tlearn: 1.2720949\ttotal: 29.4s\tremaining: 4m 6s\n64:\tlearn: 1.2615688\ttotal: 29.9s\tremaining: 4m 5s\n65:\tlearn: 1.2561719\ttotal: 30.3s\tremaining: 4m 5s\n66:\tlearn: 1.2515105\ttotal: 30.8s\tremaining: 4m 4s\n67:\tlearn: 1.2457353\ttotal: 31.2s\tremaining: 4m 4s\n68:\tlearn: 1.2420992\ttotal: 31.7s\tremaining: 4m 3s\n69:\tlearn: 1.2409528\ttotal: 32.1s\tremaining: 4m 3s\n70:\tlearn: 1.2377063\ttotal: 32.6s\tremaining: 4m 2s\n71:\tlearn: 1.2319568\ttotal: 33s\tremaining: 4m 2s\n72:\tlearn: 1.2286047\ttotal: 33.5s\tremaining: 4m 1s\n73:\tlearn: 1.2259128\ttotal: 33.9s\tremaining: 4m 1s\n74:\tlearn: 1.2216224\ttotal: 34.4s\tremaining: 4m\n75:\tlearn: 1.2156825\ttotal: 34.8s\tremaining: 4m\n76:\tlearn: 1.2143929\ttotal: 35.3s\tremaining: 3m 59s\n77:\tlearn: 1.2101425\ttotal: 35.7s\tremaining: 3m 58s\n78:\tlearn: 1.2075019\ttotal: 36.2s\tremaining: 3m 58s\n79:\tlearn: 1.2018075\ttotal: 36.6s\tremaining: 3m 57s\n80:\tlearn: 1.1964981\ttotal: 37.1s\tremaining: 3m 57s\n81:\tlearn: 1.1955501\ttotal: 37.5s\tremaining: 3m 56s\n82:\tlearn: 1.1880142\ttotal: 38s\tremaining: 3m 56s\n83:\tlearn: 1.1834016\ttotal: 38.4s\tremaining: 3m 56s\n84:\tlearn: 1.1790496\ttotal: 38.9s\tremaining: 3m 55s\n85:\tlearn: 1.1717535\ttotal: 39.3s\tremaining: 3m 55s\n86:\tlearn: 1.1654940\ttotal: 39.8s\tremaining: 3m 54s\n87:\tlearn: 1.1618409\ttotal: 40.2s\tremaining: 3m 54s\n88:\tlearn: 1.1566406\ttotal: 40.7s\tremaining: 3m 53s\n89:\tlearn: 1.1517567\ttotal: 41.1s\tremaining: 3m 53s\n90:\tlearn: 1.1439293\ttotal: 41.6s\tremaining: 3m 52s\n91:\tlearn: 1.1397785\ttotal: 42.1s\tremaining: 3m 52s\n92:\tlearn: 1.1347635\ttotal: 42.5s\tremaining: 3m 51s\n93:\tlearn: 1.1288724\ttotal: 43s\tremaining: 3m 51s\n94:\tlearn: 1.1268177\ttotal: 43.4s\tremaining: 3m 50s\n95:\tlearn: 1.1219324\ttotal: 43.9s\tremaining: 3m 50s\n96:\tlearn: 1.1157022\ttotal: 44.4s\tremaining: 3m 49s\n97:\tlearn: 1.1153750\ttotal: 44.8s\tremaining: 3m 49s\n98:\tlearn: 1.1090336\ttotal: 45.3s\tremaining: 3m 49s\n99:\tlearn: 1.1032667\ttotal: 45.7s\tremaining: 3m 48s\n100:\tlearn: 1.0985736\ttotal: 46.2s\tremaining: 3m 48s\n101:\tlearn: 1.0915038\ttotal: 46.7s\tremaining: 3m 47s\n102:\tlearn: 1.0881377\ttotal: 47.1s\tremaining: 3m 47s\n103:\tlearn: 1.0780975\ttotal: 47.6s\tremaining: 3m 47s\n104:\tlearn: 1.0706036\ttotal: 48.1s\tremaining: 3m 46s\n105:\tlearn: 1.0666525\ttotal: 48.6s\tremaining: 3m 46s\n106:\tlearn: 1.0640089\ttotal: 49s\tremaining: 3m 45s\n107:\tlearn: 1.0533707\ttotal: 49.5s\tremaining: 3m 45s\n108:\tlearn: 1.0512069\ttotal: 49.9s\tremaining: 3m 44s\n109:\tlearn: 1.0505327\ttotal: 50.4s\tremaining: 3m 44s\n110:\tlearn: 1.0490436\ttotal: 50.8s\tremaining: 3m 43s\n111:\tlearn: 1.0481793\ttotal: 51.2s\tremaining: 3m 43s\n112:\tlearn: 1.0457714\ttotal: 51.7s\tremaining: 3m 42s\n113:\tlearn: 1.0420426\ttotal: 52.1s\tremaining: 3m 42s\n114:\tlearn: 1.0350455\ttotal: 52.6s\tremaining: 3m 42s\n115:\tlearn: 1.0338324\ttotal: 53.1s\tremaining: 3m 41s\n116:\tlearn: 1.0329888\ttotal: 53.5s\tremaining: 3m 40s\n117:\tlearn: 1.0261722\ttotal: 54s\tremaining: 3m 40s\n118:\tlearn: 1.0184392\ttotal: 54.5s\tremaining: 3m 40s\n119:\tlearn: 1.0168457\ttotal: 54.9s\tremaining: 3m 39s\n120:\tlearn: 1.0129067\ttotal: 55.4s\tremaining: 3m 39s\n121:\tlearn: 1.0075284\ttotal: 55.9s\tremaining: 3m 38s\n122:\tlearn: 1.0038434\ttotal: 56.3s\tremaining: 3m 38s\n123:\tlearn: 1.0001120\ttotal: 56.8s\tremaining: 3m 37s\n124:\tlearn: 0.9971604\ttotal: 57.2s\tremaining: 3m 37s\n125:\tlearn: 0.9918683\ttotal: 57.7s\tremaining: 3m 37s\n126:\tlearn: 0.9896603\ttotal: 58.2s\tremaining: 3m 36s\n127:\tlearn: 0.9881042\ttotal: 58.6s\tremaining: 3m 36s\n128:\tlearn: 0.9839196\ttotal: 59.1s\tremaining: 3m 35s\n129:\tlearn: 0.9810612\ttotal: 59.5s\tremaining: 3m 35s\n130:\tlearn: 0.9798297\ttotal: 59.9s\tremaining: 3m 34s\n131:\tlearn: 0.9781794\ttotal: 1m\tremaining: 3m 34s\n132:\tlearn: 0.9738946\ttotal: 1m\tremaining: 3m 33s\n133:\tlearn: 0.9725239\ttotal: 1m 1s\tremaining: 3m 33s\n134:\tlearn: 0.9688202\ttotal: 1m 1s\tremaining: 3m 32s\n135:\tlearn: 0.9634761\ttotal: 1m 2s\tremaining: 3m 32s\n136:\tlearn: 0.9616319\ttotal: 1m 2s\tremaining: 3m 31s\n137:\tlearn: 0.9550124\ttotal: 1m 3s\tremaining: 3m 31s\n138:\tlearn: 0.9489558\ttotal: 1m 3s\tremaining: 3m 31s\n139:\tlearn: 0.9472170\ttotal: 1m 4s\tremaining: 3m 30s\n140:\tlearn: 0.9448435\ttotal: 1m 4s\tremaining: 3m 30s\n141:\tlearn: 0.9432646\ttotal: 1m 5s\tremaining: 3m 29s\n142:\tlearn: 0.9410048\ttotal: 1m 5s\tremaining: 3m 29s\n143:\tlearn: 0.9400834\ttotal: 1m 5s\tremaining: 3m 28s\n144:\tlearn: 0.9387774\ttotal: 1m 6s\tremaining: 3m 28s\n145:\tlearn: 0.9364167\ttotal: 1m 6s\tremaining: 3m 27s\n146:\tlearn: 0.9345635\ttotal: 1m 7s\tremaining: 3m 27s\n147:\tlearn: 0.9267851\ttotal: 1m 7s\tremaining: 3m 26s\n148:\tlearn: 0.9236463\ttotal: 1m 8s\tremaining: 3m 26s\n149:\tlearn: 0.9228132\ttotal: 1m 8s\tremaining: 3m 25s\n150:\tlearn: 0.9217911\ttotal: 1m 9s\tremaining: 3m 25s\n151:\tlearn: 0.9213955\ttotal: 1m 9s\tremaining: 3m 24s\n152:\tlearn: 0.9209157\ttotal: 1m 9s\tremaining: 3m 24s\n153:\tlearn: 0.9203414\ttotal: 1m 10s\tremaining: 3m 23s\n154:\tlearn: 0.9170385\ttotal: 1m 10s\tremaining: 3m 23s\n155:\tlearn: 0.9165055\ttotal: 1m 11s\tremaining: 3m 22s\n156:\tlearn: 0.9115052\ttotal: 1m 11s\tremaining: 3m 22s\n157:\tlearn: 0.9073805\ttotal: 1m 12s\tremaining: 3m 22s\n158:\tlearn: 0.9059431\ttotal: 1m 12s\tremaining: 3m 21s\n159:\tlearn: 0.9000244\ttotal: 1m 13s\tremaining: 3m 21s\n160:\tlearn: 0.8898557\ttotal: 1m 13s\tremaining: 3m 20s\n161:\tlearn: 0.8871717\ttotal: 1m 14s\tremaining: 3m 20s\n162:\tlearn: 0.8861669\ttotal: 1m 14s\tremaining: 3m 19s\n163:\tlearn: 0.8836810\ttotal: 1m 15s\tremaining: 3m 19s\n164:\tlearn: 0.8794964\ttotal: 1m 15s\tremaining: 3m 18s\n165:\tlearn: 0.8753126\ttotal: 1m 15s\tremaining: 3m 18s\n166:\tlearn: 0.8746698\ttotal: 1m 16s\tremaining: 3m 18s\n167:\tlearn: 0.8711633\ttotal: 1m 16s\tremaining: 3m 17s\n168:\tlearn: 0.8706870\ttotal: 1m 17s\tremaining: 3m 17s\n169:\tlearn: 0.8677221\ttotal: 1m 17s\tremaining: 3m 16s\n170:\tlearn: 0.8670070\ttotal: 1m 18s\tremaining: 3m 16s\n171:\tlearn: 0.8640074\ttotal: 1m 18s\tremaining: 3m 15s\n172:\tlearn: 0.8629065\ttotal: 1m 19s\tremaining: 3m 15s\n173:\tlearn: 0.8615469\ttotal: 1m 19s\tremaining: 3m 14s\n174:\tlearn: 0.8567060\ttotal: 1m 19s\tremaining: 3m 14s\n175:\tlearn: 0.8514206\ttotal: 1m 20s\tremaining: 3m 13s\n176:\tlearn: 0.8500136\ttotal: 1m 20s\tremaining: 3m 13s\n177:\tlearn: 0.8464439\ttotal: 1m 21s\tremaining: 3m 12s\n178:\tlearn: 0.8448460\ttotal: 1m 21s\tremaining: 3m 12s\n179:\tlearn: 0.8399636\ttotal: 1m 22s\tremaining: 3m 12s\n180:\tlearn: 0.8389195\ttotal: 1m 22s\tremaining: 3m 11s\n181:\tlearn: 0.8382156\ttotal: 1m 23s\tremaining: 3m 11s\n182:\tlearn: 0.8369846\ttotal: 1m 23s\tremaining: 3m 10s\n183:\tlearn: 0.8355198\ttotal: 1m 24s\tremaining: 3m 10s\n184:\tlearn: 0.8289328\ttotal: 1m 24s\tremaining: 3m 9s\n185:\tlearn: 0.8267192\ttotal: 1m 25s\tremaining: 3m 9s\n186:\tlearn: 0.8257324\ttotal: 1m 25s\tremaining: 3m 8s\n187:\tlearn: 0.8250300\ttotal: 1m 25s\tremaining: 3m 8s\n188:\tlearn: 0.8219047\ttotal: 1m 26s\tremaining: 3m 7s\n189:\tlearn: 0.8214594\ttotal: 1m 26s\tremaining: 3m 7s\n190:\tlearn: 0.8153801\ttotal: 1m 27s\tremaining: 3m 7s\n191:\tlearn: 0.8109628\ttotal: 1m 27s\tremaining: 3m 6s\n192:\tlearn: 0.8103334\ttotal: 1m 28s\tremaining: 3m 6s\n193:\tlearn: 0.8086058\ttotal: 1m 28s\tremaining: 3m 5s\n194:\tlearn: 0.8078339\ttotal: 1m 29s\tremaining: 3m 5s\n195:\tlearn: 0.8055596\ttotal: 1m 29s\tremaining: 3m 4s\n196:\tlearn: 0.8043119\ttotal: 1m 30s\tremaining: 3m 4s\n197:\tlearn: 0.8031651\ttotal: 1m 30s\tremaining: 3m 3s\n198:\tlearn: 0.8009899\ttotal: 1m 30s\tremaining: 3m 3s\n199:\tlearn: 0.7998409\ttotal: 1m 31s\tremaining: 3m 2s\n200:\tlearn: 0.7990784\ttotal: 1m 31s\tremaining: 3m 2s\n201:\tlearn: 0.7969280\ttotal: 1m 32s\tremaining: 3m 1s\n202:\tlearn: 0.7913432\ttotal: 1m 32s\tremaining: 3m 1s\n203:\tlearn: 0.7882602\ttotal: 1m 33s\tremaining: 3m 1s\n204:\tlearn: 0.7870188\ttotal: 1m 33s\tremaining: 3m\n205:\tlearn: 0.7861332\ttotal: 1m 34s\tremaining: 3m\n206:\tlearn: 0.7854050\ttotal: 1m 34s\tremaining: 2m 59s\n207:\tlearn: 0.7841797\ttotal: 1m 35s\tremaining: 2m 59s\n208:\tlearn: 0.7818457\ttotal: 1m 35s\tremaining: 2m 58s\n209:\tlearn: 0.7809680\ttotal: 1m 35s\tremaining: 2m 58s\n210:\tlearn: 0.7772446\ttotal: 1m 36s\tremaining: 2m 57s\n211:\tlearn: 0.7747591\ttotal: 1m 36s\tremaining: 2m 57s\n212:\tlearn: 0.7706066\ttotal: 1m 37s\tremaining: 2m 56s\n213:\tlearn: 0.7701535\ttotal: 1m 37s\tremaining: 2m 56s\n214:\tlearn: 0.7685868\ttotal: 1m 38s\tremaining: 2m 56s\n215:\tlearn: 0.7681850\ttotal: 1m 38s\tremaining: 2m 55s\n216:\tlearn: 0.7672329\ttotal: 1m 39s\tremaining: 2m 55s\n217:\tlearn: 0.7645688\ttotal: 1m 39s\tremaining: 2m 54s\n218:\tlearn: 0.7640280\ttotal: 1m 40s\tremaining: 2m 54s\n219:\tlearn: 0.7626949\ttotal: 1m 40s\tremaining: 2m 53s\n220:\tlearn: 0.7619310\ttotal: 1m 40s\tremaining: 2m 53s\n221:\tlearn: 0.7615286\ttotal: 1m 41s\tremaining: 2m 52s\n222:\tlearn: 0.7600586\ttotal: 1m 41s\tremaining: 2m 52s\n223:\tlearn: 0.7572548\ttotal: 1m 42s\tremaining: 2m 51s\n224:\tlearn: 0.7566470\ttotal: 1m 42s\tremaining: 2m 51s\n225:\tlearn: 0.7517110\ttotal: 1m 43s\tremaining: 2m 50s\n226:\tlearn: 0.7505208\ttotal: 1m 43s\tremaining: 2m 50s\n227:\tlearn: 0.7483997\ttotal: 1m 44s\tremaining: 2m 49s\n228:\tlearn: 0.7483306\ttotal: 1m 44s\tremaining: 2m 49s\n229:\tlearn: 0.7471254\ttotal: 1m 45s\tremaining: 2m 48s\n230:\tlearn: 0.7453388\ttotal: 1m 45s\tremaining: 2m 48s\n231:\tlearn: 0.7420733\ttotal: 1m 45s\tremaining: 2m 48s\n232:\tlearn: 0.7412749\ttotal: 1m 46s\tremaining: 2m 47s\n233:\tlearn: 0.7391195\ttotal: 1m 46s\tremaining: 2m 47s\n234:\tlearn: 0.7383592\ttotal: 1m 47s\tremaining: 2m 46s\n235:\tlearn: 0.7378999\ttotal: 1m 47s\tremaining: 2m 46s\n236:\tlearn: 0.7370222\ttotal: 1m 48s\tremaining: 2m 45s\n237:\tlearn: 0.7346911\ttotal: 1m 48s\tremaining: 2m 45s\n238:\tlearn: 0.7325942\ttotal: 1m 49s\tremaining: 2m 44s\n239:\tlearn: 0.7298912\ttotal: 1m 49s\tremaining: 2m 44s\n240:\tlearn: 0.7295240\ttotal: 1m 50s\tremaining: 2m 43s\n241:\tlearn: 0.7286297\ttotal: 1m 50s\tremaining: 2m 43s\n242:\tlearn: 0.7249869\ttotal: 1m 50s\tremaining: 2m 42s\n243:\tlearn: 0.7215524\ttotal: 1m 51s\tremaining: 2m 42s\n244:\tlearn: 0.7194706\ttotal: 1m 51s\tremaining: 2m 42s\n245:\tlearn: 0.7184281\ttotal: 1m 52s\tremaining: 2m 41s\n246:\tlearn: 0.7172322\ttotal: 1m 52s\tremaining: 2m 41s\n247:\tlearn: 0.7168289\ttotal: 1m 53s\tremaining: 2m 40s\n248:\tlearn: 0.7151610\ttotal: 1m 53s\tremaining: 2m 40s\n249:\tlearn: 0.7147270\ttotal: 1m 54s\tremaining: 2m 39s\n250:\tlearn: 0.7139766\ttotal: 1m 54s\tremaining: 2m 39s\n251:\tlearn: 0.7114194\ttotal: 1m 54s\tremaining: 2m 38s\n252:\tlearn: 0.7105157\ttotal: 1m 55s\tremaining: 2m 38s\n253:\tlearn: 0.7077204\ttotal: 1m 55s\tremaining: 2m 37s\n254:\tlearn: 0.7046899\ttotal: 1m 56s\tremaining: 2m 37s\n255:\tlearn: 0.7024917\ttotal: 1m 56s\tremaining: 2m 36s\n256:\tlearn: 0.7015299\ttotal: 1m 57s\tremaining: 2m 36s\n257:\tlearn: 0.6983109\ttotal: 1m 57s\tremaining: 2m 36s\n258:\tlearn: 0.6978382\ttotal: 1m 58s\tremaining: 2m 35s\n259:\tlearn: 0.6977075\ttotal: 1m 58s\tremaining: 2m 35s\n260:\tlearn: 0.6965610\ttotal: 1m 59s\tremaining: 2m 34s\n261:\tlearn: 0.6959737\ttotal: 1m 59s\tremaining: 2m 34s\n262:\tlearn: 0.6910873\ttotal: 2m\tremaining: 2m 33s\n263:\tlearn: 0.6905469\ttotal: 2m\tremaining: 2m 33s\n264:\tlearn: 0.6878622\ttotal: 2m\tremaining: 2m 32s\n265:\tlearn: 0.6873634\ttotal: 2m 1s\tremaining: 2m 32s\n266:\tlearn: 0.6859956\ttotal: 2m 1s\tremaining: 2m 31s\n267:\tlearn: 0.6848604\ttotal: 2m 2s\tremaining: 2m 31s\n268:\tlearn: 0.6845335\ttotal: 2m 2s\tremaining: 2m 31s\n269:\tlearn: 0.6843073\ttotal: 2m 3s\tremaining: 2m 30s\n270:\tlearn: 0.6822316\ttotal: 2m 3s\tremaining: 2m 30s\n271:\tlearn: 0.6819003\ttotal: 2m 4s\tremaining: 2m 29s\n272:\tlearn: 0.6811328\ttotal: 2m 4s\tremaining: 2m 29s\n273:\tlearn: 0.6765499\ttotal: 2m 5s\tremaining: 2m 28s\n274:\tlearn: 0.6764394\ttotal: 2m 5s\tremaining: 2m 28s\n275:\tlearn: 0.6748779\ttotal: 2m 5s\tremaining: 2m 27s\n276:\tlearn: 0.6745709\ttotal: 2m 6s\tremaining: 2m 27s\n277:\tlearn: 0.6741418\ttotal: 2m 6s\tremaining: 2m 26s\n278:\tlearn: 0.6738511\ttotal: 2m 7s\tremaining: 2m 26s\n279:\tlearn: 0.6733354\ttotal: 2m 7s\tremaining: 2m 25s\n280:\tlearn: 0.6728358\ttotal: 2m 8s\tremaining: 2m 25s\n281:\tlearn: 0.6718393\ttotal: 2m 8s\tremaining: 2m 24s\n282:\tlearn: 0.6707620\ttotal: 2m 9s\tremaining: 2m 24s\n283:\tlearn: 0.6691584\ttotal: 2m 9s\tremaining: 2m 24s\n284:\tlearn: 0.6687234\ttotal: 2m 9s\tremaining: 2m 23s\n285:\tlearn: 0.6682866\ttotal: 2m 10s\tremaining: 2m 23s\n286:\tlearn: 0.6676632\ttotal: 2m 10s\tremaining: 2m 22s\n287:\tlearn: 0.6670345\ttotal: 2m 11s\tremaining: 2m 22s\n288:\tlearn: 0.6667958\ttotal: 2m 11s\tremaining: 2m 21s\n289:\tlearn: 0.6659818\ttotal: 2m 12s\tremaining: 2m 21s\n290:\tlearn: 0.6627007\ttotal: 2m 12s\tremaining: 2m 20s\n291:\tlearn: 0.6613432\ttotal: 2m 13s\tremaining: 2m 20s\n292:\tlearn: 0.6610477\ttotal: 2m 13s\tremaining: 2m 19s\n293:\tlearn: 0.6601252\ttotal: 2m 13s\tremaining: 2m 19s\n294:\tlearn: 0.6597802\ttotal: 2m 14s\tremaining: 2m 18s\n295:\tlearn: 0.6591728\ttotal: 2m 14s\tremaining: 2m 18s\n296:\tlearn: 0.6584455\ttotal: 2m 15s\tremaining: 2m 18s\n297:\tlearn: 0.6579906\ttotal: 2m 15s\tremaining: 2m 17s\n298:\tlearn: 0.6553859\ttotal: 2m 16s\tremaining: 2m 17s\n299:\tlearn: 0.6546961\ttotal: 2m 16s\tremaining: 2m 16s\n300:\tlearn: 0.6532094\ttotal: 2m 17s\tremaining: 2m 16s\n301:\tlearn: 0.6528435\ttotal: 2m 17s\tremaining: 2m 15s\n302:\tlearn: 0.6524810\ttotal: 2m 17s\tremaining: 2m 15s\n303:\tlearn: 0.6520227\ttotal: 2m 18s\tremaining: 2m 14s\n304:\tlearn: 0.6505756\ttotal: 2m 18s\tremaining: 2m 14s\n305:\tlearn: 0.6502293\ttotal: 2m 19s\tremaining: 2m 13s\n306:\tlearn: 0.6498764\ttotal: 2m 19s\tremaining: 2m 13s\n307:\tlearn: 0.6466626\ttotal: 2m 20s\tremaining: 2m 12s\n308:\tlearn: 0.6459942\ttotal: 2m 20s\tremaining: 2m 12s\n309:\tlearn: 0.6451976\ttotal: 2m 21s\tremaining: 2m 12s\n310:\tlearn: 0.6438989\ttotal: 2m 21s\tremaining: 2m 11s\n311:\tlearn: 0.6435773\ttotal: 2m 22s\tremaining: 2m 11s\n312:\tlearn: 0.6431219\ttotal: 2m 22s\tremaining: 2m 10s\n313:\tlearn: 0.6401169\ttotal: 2m 22s\tremaining: 2m 10s\n314:\tlearn: 0.6382102\ttotal: 2m 23s\tremaining: 2m 9s\n315:\tlearn: 0.6373439\ttotal: 2m 23s\tremaining: 2m 9s\n316:\tlearn: 0.6370265\ttotal: 2m 24s\tremaining: 2m 8s\n317:\tlearn: 0.6352630\ttotal: 2m 24s\tremaining: 2m 8s\n318:\tlearn: 0.6335383\ttotal: 2m 25s\tremaining: 2m 7s\n319:\tlearn: 0.6333515\ttotal: 2m 25s\tremaining: 2m 7s\n320:\tlearn: 0.6327120\ttotal: 2m 26s\tremaining: 2m 7s\n321:\tlearn: 0.6315426\ttotal: 2m 26s\tremaining: 2m 6s\n322:\tlearn: 0.6311569\ttotal: 2m 27s\tremaining: 2m 6s\n323:\tlearn: 0.6298889\ttotal: 2m 27s\tremaining: 2m 5s\n324:\tlearn: 0.6293861\ttotal: 2m 27s\tremaining: 2m 5s\n325:\tlearn: 0.6292008\ttotal: 2m 28s\tremaining: 2m 4s\n326:\tlearn: 0.6283846\ttotal: 2m 28s\tremaining: 2m 4s\n327:\tlearn: 0.6243710\ttotal: 2m 29s\tremaining: 2m 3s\n328:\tlearn: 0.6233372\ttotal: 2m 29s\tremaining: 2m 3s\n329:\tlearn: 0.6225396\ttotal: 2m 30s\tremaining: 2m 2s\n330:\tlearn: 0.6223021\ttotal: 2m 30s\tremaining: 2m 2s\n331:\tlearn: 0.6213622\ttotal: 2m 31s\tremaining: 2m 1s\n332:\tlearn: 0.6206769\ttotal: 2m 31s\tremaining: 2m 1s\n333:\tlearn: 0.6201394\ttotal: 2m 31s\tremaining: 2m 1s\n334:\tlearn: 0.6186908\ttotal: 2m 32s\tremaining: 2m\n335:\tlearn: 0.6184619\ttotal: 2m 32s\tremaining: 2m\n336:\tlearn: 0.6181585\ttotal: 2m 33s\tremaining: 1m 59s\n337:\tlearn: 0.6178117\ttotal: 2m 33s\tremaining: 1m 59s\n338:\tlearn: 0.6174793\ttotal: 2m 34s\tremaining: 1m 58s\n339:\tlearn: 0.6171829\ttotal: 2m 34s\tremaining: 1m 58s\n340:\tlearn: 0.6168073\ttotal: 2m 35s\tremaining: 1m 57s\n341:\tlearn: 0.6157385\ttotal: 2m 35s\tremaining: 1m 57s\n342:\tlearn: 0.6143824\ttotal: 2m 36s\tremaining: 1m 56s\n343:\tlearn: 0.6132993\ttotal: 2m 36s\tremaining: 1m 56s\n344:\tlearn: 0.6130641\ttotal: 2m 36s\tremaining: 1m 55s\n345:\tlearn: 0.6119315\ttotal: 2m 37s\tremaining: 1m 55s\n346:\tlearn: 0.6112886\ttotal: 2m 37s\tremaining: 1m 55s\n347:\tlearn: 0.6093828\ttotal: 2m 38s\tremaining: 1m 54s\n348:\tlearn: 0.6091881\ttotal: 2m 38s\tremaining: 1m 54s\n349:\tlearn: 0.6069295\ttotal: 2m 39s\tremaining: 1m 53s\n350:\tlearn: 0.6040003\ttotal: 2m 39s\tremaining: 1m 53s\n351:\tlearn: 0.6030503\ttotal: 2m 40s\tremaining: 1m 52s\n352:\tlearn: 0.6026798\ttotal: 2m 40s\tremaining: 1m 52s\n353:\tlearn: 0.6024059\ttotal: 2m 41s\tremaining: 1m 51s\n354:\tlearn: 0.6021664\ttotal: 2m 41s\tremaining: 1m 51s\n355:\tlearn: 0.6006384\ttotal: 2m 41s\tremaining: 1m 50s\n356:\tlearn: 0.5994259\ttotal: 2m 42s\tremaining: 1m 50s\n357:\tlearn: 0.5987250\ttotal: 2m 42s\tremaining: 1m 50s\n358:\tlearn: 0.5981130\ttotal: 2m 43s\tremaining: 1m 49s\n359:\tlearn: 0.5958600\ttotal: 2m 43s\tremaining: 1m 49s\n360:\tlearn: 0.5954113\ttotal: 2m 44s\tremaining: 1m 48s\n361:\tlearn: 0.5953376\ttotal: 2m 44s\tremaining: 1m 48s\n362:\tlearn: 0.5939833\ttotal: 2m 45s\tremaining: 1m 47s\n363:\tlearn: 0.5932329\ttotal: 2m 45s\tremaining: 1m 47s\n364:\tlearn: 0.5913654\ttotal: 2m 46s\tremaining: 1m 46s\n365:\tlearn: 0.5904019\ttotal: 2m 46s\tremaining: 1m 46s\n366:\tlearn: 0.5902636\ttotal: 2m 46s\tremaining: 1m 45s\n367:\tlearn: 0.5900200\ttotal: 2m 47s\tremaining: 1m 45s\n368:\tlearn: 0.5897224\ttotal: 2m 47s\tremaining: 1m 45s\n369:\tlearn: 0.5888271\ttotal: 2m 48s\tremaining: 1m 44s\n370:\tlearn: 0.5881827\ttotal: 2m 48s\tremaining: 1m 44s\n371:\tlearn: 0.5876007\ttotal: 2m 49s\tremaining: 1m 43s\n372:\tlearn: 0.5873914\ttotal: 2m 49s\tremaining: 1m 43s\n373:\tlearn: 0.5848109\ttotal: 2m 50s\tremaining: 1m 42s\n374:\tlearn: 0.5846054\ttotal: 2m 50s\tremaining: 1m 42s\n375:\tlearn: 0.5841572\ttotal: 2m 50s\tremaining: 1m 41s\n376:\tlearn: 0.5814120\ttotal: 2m 51s\tremaining: 1m 41s\n377:\tlearn: 0.5805431\ttotal: 2m 51s\tremaining: 1m 40s\n378:\tlearn: 0.5803371\ttotal: 2m 52s\tremaining: 1m 40s\n379:\tlearn: 0.5801917\ttotal: 2m 52s\tremaining: 1m 40s\n380:\tlearn: 0.5796626\ttotal: 2m 53s\tremaining: 1m 39s\n381:\tlearn: 0.5788694\ttotal: 2m 53s\tremaining: 1m 39s\n382:\tlearn: 0.5769167\ttotal: 2m 54s\tremaining: 1m 38s\n383:\tlearn: 0.5762018\ttotal: 2m 54s\tremaining: 1m 38s\n384:\tlearn: 0.5759706\ttotal: 2m 55s\tremaining: 1m 37s\n385:\tlearn: 0.5743464\ttotal: 2m 55s\tremaining: 1m 37s\n386:\tlearn: 0.5742093\ttotal: 2m 55s\tremaining: 1m 36s\n387:\tlearn: 0.5740177\ttotal: 2m 56s\tremaining: 1m 36s\n388:\tlearn: 0.5738758\ttotal: 2m 56s\tremaining: 1m 35s\n389:\tlearn: 0.5732572\ttotal: 2m 57s\tremaining: 1m 35s\n390:\tlearn: 0.5731370\ttotal: 2m 57s\tremaining: 1m 34s\n391:\tlearn: 0.5725895\ttotal: 2m 58s\tremaining: 1m 34s\n392:\tlearn: 0.5723908\ttotal: 2m 58s\tremaining: 1m 34s\n393:\tlearn: 0.5722506\ttotal: 2m 59s\tremaining: 1m 33s\n394:\tlearn: 0.5715357\ttotal: 2m 59s\tremaining: 1m 33s\n395:\tlearn: 0.5707251\ttotal: 2m 59s\tremaining: 1m 32s\n396:\tlearn: 0.5705880\ttotal: 3m\tremaining: 1m 32s\n397:\tlearn: 0.5698075\ttotal: 3m\tremaining: 1m 31s\n398:\tlearn: 0.5689001\ttotal: 3m 1s\tremaining: 1m 31s\n399:\tlearn: 0.5674943\ttotal: 3m 1s\tremaining: 1m 30s\n400:\tlearn: 0.5672582\ttotal: 3m 2s\tremaining: 1m 30s\n401:\tlearn: 0.5670476\ttotal: 3m 2s\tremaining: 1m 29s\n402:\tlearn: 0.5668315\ttotal: 3m 3s\tremaining: 1m 29s\n403:\tlearn: 0.5667236\ttotal: 3m 3s\tremaining: 1m 29s\n404:\tlearn: 0.5644782\ttotal: 3m 3s\tremaining: 1m 28s\n405:\tlearn: 0.5625901\ttotal: 3m 4s\tremaining: 1m 28s\n406:\tlearn: 0.5624050\ttotal: 3m 4s\tremaining: 1m 27s\n407:\tlearn: 0.5622053\ttotal: 3m 5s\tremaining: 1m 27s\n408:\tlearn: 0.5603592\ttotal: 3m 5s\tremaining: 1m 26s\n409:\tlearn: 0.5602256\ttotal: 3m 6s\tremaining: 1m 26s\n410:\tlearn: 0.5590248\ttotal: 3m 6s\tremaining: 1m 25s\n411:\tlearn: 0.5582251\ttotal: 3m 7s\tremaining: 1m 25s\n412:\tlearn: 0.5580656\ttotal: 3m 7s\tremaining: 1m 24s\n413:\tlearn: 0.5568176\ttotal: 3m 8s\tremaining: 1m 24s\n414:\tlearn: 0.5557313\ttotal: 3m 8s\tremaining: 1m 24s\n415:\tlearn: 0.5555576\ttotal: 3m 8s\tremaining: 1m 23s\n416:\tlearn: 0.5554160\ttotal: 3m 9s\tremaining: 1m 23s\n417:\tlearn: 0.5535985\ttotal: 3m 9s\tremaining: 1m 22s\n418:\tlearn: 0.5534790\ttotal: 3m 10s\tremaining: 1m 22s\n419:\tlearn: 0.5510205\ttotal: 3m 10s\tremaining: 1m 21s\n420:\tlearn: 0.5500837\ttotal: 3m 11s\tremaining: 1m 21s\n421:\tlearn: 0.5498519\ttotal: 3m 11s\tremaining: 1m 20s\n422:\tlearn: 0.5496933\ttotal: 3m 12s\tremaining: 1m 20s\n423:\tlearn: 0.5496299\ttotal: 3m 12s\tremaining: 1m 19s\n424:\tlearn: 0.5494012\ttotal: 3m 13s\tremaining: 1m 19s\n425:\tlearn: 0.5490486\ttotal: 3m 13s\tremaining: 1m 19s\n426:\tlearn: 0.5489496\ttotal: 3m 13s\tremaining: 1m 18s\n427:\tlearn: 0.5487500\ttotal: 3m 14s\tremaining: 1m 18s\n428:\tlearn: 0.5478936\ttotal: 3m 14s\tremaining: 1m 17s\n429:\tlearn: 0.5476966\ttotal: 3m 15s\tremaining: 1m 17s\n430:\tlearn: 0.5472645\ttotal: 3m 15s\tremaining: 1m 16s\n431:\tlearn: 0.5471094\ttotal: 3m 16s\tremaining: 1m 16s\n432:\tlearn: 0.5468851\ttotal: 3m 16s\tremaining: 1m 15s\n433:\tlearn: 0.5465968\ttotal: 3m 17s\tremaining: 1m 15s\n434:\tlearn: 0.5461817\ttotal: 3m 17s\tremaining: 1m 14s\n435:\tlearn: 0.5460474\ttotal: 3m 17s\tremaining: 1m 14s\n436:\tlearn: 0.5454371\ttotal: 3m 18s\tremaining: 1m 13s\n437:\tlearn: 0.5450833\ttotal: 3m 18s\tremaining: 1m 13s\n438:\tlearn: 0.5449101\ttotal: 3m 19s\tremaining: 1m 13s\n439:\tlearn: 0.5442932\ttotal: 3m 19s\tremaining: 1m 12s\n440:\tlearn: 0.5433446\ttotal: 3m 20s\tremaining: 1m 12s\n441:\tlearn: 0.5432897\ttotal: 3m 20s\tremaining: 1m 11s\n442:\tlearn: 0.5429993\ttotal: 3m 21s\tremaining: 1m 11s\n443:\tlearn: 0.5417225\ttotal: 3m 21s\tremaining: 1m 10s\n444:\tlearn: 0.5414049\ttotal: 3m 21s\tremaining: 1m 10s\n445:\tlearn: 0.5411860\ttotal: 3m 22s\tremaining: 1m 9s\n446:\tlearn: 0.5411173\ttotal: 3m 22s\tremaining: 1m 9s\n447:\tlearn: 0.5404268\ttotal: 3m 23s\tremaining: 1m 8s\n448:\tlearn: 0.5403214\ttotal: 3m 23s\tremaining: 1m 8s\n449:\tlearn: 0.5398705\ttotal: 3m 24s\tremaining: 1m 8s\n450:\tlearn: 0.5396350\ttotal: 3m 24s\tremaining: 1m 7s\n451:\tlearn: 0.5380730\ttotal: 3m 25s\tremaining: 1m 7s\n452:\tlearn: 0.5378558\ttotal: 3m 25s\tremaining: 1m 6s\n453:\tlearn: 0.5377564\ttotal: 3m 25s\tremaining: 1m 6s\n454:\tlearn: 0.5374593\ttotal: 3m 26s\tremaining: 1m 5s\n455:\tlearn: 0.5373567\ttotal: 3m 26s\tremaining: 1m 5s\n456:\tlearn: 0.5372985\ttotal: 3m 27s\tremaining: 1m 4s\n457:\tlearn: 0.5371847\ttotal: 3m 27s\tremaining: 1m 4s\n458:\tlearn: 0.5369600\ttotal: 3m 28s\tremaining: 1m 3s\n459:\tlearn: 0.5362492\ttotal: 3m 28s\tremaining: 1m 3s\n460:\tlearn: 0.5353512\ttotal: 3m 29s\tremaining: 1m 3s\n461:\tlearn: 0.5345496\ttotal: 3m 29s\tremaining: 1m 2s\n462:\tlearn: 0.5340836\ttotal: 3m 29s\tremaining: 1m 2s\n463:\tlearn: 0.5336272\ttotal: 3m 30s\tremaining: 1m 1s\n464:\tlearn: 0.5332801\ttotal: 3m 30s\tremaining: 1m 1s\n465:\tlearn: 0.5319331\ttotal: 3m 31s\tremaining: 1m\n466:\tlearn: 0.5308888\ttotal: 3m 31s\tremaining: 1m\n467:\tlearn: 0.5305297\ttotal: 3m 32s\tremaining: 59.8s\n468:\tlearn: 0.5304092\ttotal: 3m 32s\tremaining: 59.4s\n469:\tlearn: 0.5303285\ttotal: 3m 33s\tremaining: 58.9s\n470:\tlearn: 0.5302434\ttotal: 3m 33s\tremaining: 58.5s\n471:\tlearn: 0.5300087\ttotal: 3m 33s\tremaining: 58s\n472:\tlearn: 0.5299072\ttotal: 3m 34s\tremaining: 57.6s\n473:\tlearn: 0.5272274\ttotal: 3m 34s\tremaining: 57.1s\n474:\tlearn: 0.5271091\ttotal: 3m 35s\tremaining: 56.7s\n475:\tlearn: 0.5268251\ttotal: 3m 35s\tremaining: 56.2s\n476:\tlearn: 0.5255184\ttotal: 3m 36s\tremaining: 55.8s\n477:\tlearn: 0.5249374\ttotal: 3m 36s\tremaining: 55.3s\n478:\tlearn: 0.5244001\ttotal: 3m 37s\tremaining: 54.8s\n479:\tlearn: 0.5239138\ttotal: 3m 37s\tremaining: 54.4s\n480:\tlearn: 0.5236621\ttotal: 3m 38s\tremaining: 53.9s\n481:\tlearn: 0.5216644\ttotal: 3m 38s\tremaining: 53.5s\n482:\tlearn: 0.5216090\ttotal: 3m 38s\tremaining: 53s\n483:\tlearn: 0.5210796\ttotal: 3m 39s\tremaining: 52.6s\n484:\tlearn: 0.5209379\ttotal: 3m 39s\tremaining: 52.1s\n485:\tlearn: 0.5194984\ttotal: 3m 40s\tremaining: 51.7s\n486:\tlearn: 0.5194323\ttotal: 3m 40s\tremaining: 51.2s\n487:\tlearn: 0.5192979\ttotal: 3m 41s\tremaining: 50.8s\n488:\tlearn: 0.5192129\ttotal: 3m 41s\tremaining: 50.3s\n489:\tlearn: 0.5187435\ttotal: 3m 42s\tremaining: 49.8s\n490:\tlearn: 0.5174551\ttotal: 3m 42s\tremaining: 49.4s\n491:\tlearn: 0.5172004\ttotal: 3m 42s\tremaining: 48.9s\n492:\tlearn: 0.5170729\ttotal: 3m 43s\tremaining: 48.5s\n493:\tlearn: 0.5163183\ttotal: 3m 43s\tremaining: 48s\n494:\tlearn: 0.5154281\ttotal: 3m 44s\tremaining: 47.6s\n495:\tlearn: 0.5150256\ttotal: 3m 44s\tremaining: 47.1s\n496:\tlearn: 0.5148939\ttotal: 3m 45s\tremaining: 46.7s\n497:\tlearn: 0.5148016\ttotal: 3m 45s\tremaining: 46.2s\n498:\tlearn: 0.5137388\ttotal: 3m 46s\tremaining: 45.8s\n499:\tlearn: 0.5134613\ttotal: 3m 46s\tremaining: 45.3s\n500:\tlearn: 0.5132423\ttotal: 3m 46s\tremaining: 44.8s\n501:\tlearn: 0.5131806\ttotal: 3m 47s\tremaining: 44.4s\n502:\tlearn: 0.5127448\ttotal: 3m 47s\tremaining: 43.9s\n503:\tlearn: 0.5124795\ttotal: 3m 48s\tremaining: 43.5s\n504:\tlearn: 0.5120913\ttotal: 3m 48s\tremaining: 43s\n505:\tlearn: 0.5120178\ttotal: 3m 49s\tremaining: 42.6s\n506:\tlearn: 0.5102517\ttotal: 3m 49s\tremaining: 42.1s\n507:\tlearn: 0.5095367\ttotal: 3m 50s\tremaining: 41.7s\n508:\tlearn: 0.5092891\ttotal: 3m 50s\tremaining: 41.2s\n509:\tlearn: 0.5090305\ttotal: 3m 50s\tremaining: 40.8s\n510:\tlearn: 0.5084442\ttotal: 3m 51s\tremaining: 40.3s\n511:\tlearn: 0.5074087\ttotal: 3m 51s\tremaining: 39.9s\n512:\tlearn: 0.5073231\ttotal: 3m 52s\tremaining: 39.4s\n513:\tlearn: 0.5060171\ttotal: 3m 52s\tremaining: 39s\n514:\tlearn: 0.5059730\ttotal: 3m 53s\tremaining: 38.5s\n515:\tlearn: 0.5059115\ttotal: 3m 53s\tremaining: 38s\n516:\tlearn: 0.5058352\ttotal: 3m 54s\tremaining: 37.6s\n517:\tlearn: 0.5056435\ttotal: 3m 54s\tremaining: 37.1s\n518:\tlearn: 0.5041613\ttotal: 3m 55s\tremaining: 36.7s\n519:\tlearn: 0.5040912\ttotal: 3m 55s\tremaining: 36.2s\n520:\tlearn: 0.5032030\ttotal: 3m 55s\tremaining: 35.8s\n521:\tlearn: 0.5022416\ttotal: 3m 56s\tremaining: 35.3s\n522:\tlearn: 0.5019955\ttotal: 3m 56s\tremaining: 34.9s\n523:\tlearn: 0.5017039\ttotal: 3m 57s\tremaining: 34.4s\n524:\tlearn: 0.5010290\ttotal: 3m 57s\tremaining: 34s\n525:\tlearn: 0.5005995\ttotal: 3m 58s\tremaining: 33.5s\n526:\tlearn: 0.5004339\ttotal: 3m 58s\tremaining: 33.1s\n527:\tlearn: 0.5003172\ttotal: 3m 59s\tremaining: 32.6s\n528:\tlearn: 0.4988383\ttotal: 3m 59s\tremaining: 32.1s\n529:\tlearn: 0.4985209\ttotal: 3m 59s\tremaining: 31.7s\n530:\tlearn: 0.4981414\ttotal: 4m\tremaining: 31.2s\n531:\tlearn: 0.4979779\ttotal: 4m\tremaining: 30.8s\n532:\tlearn: 0.4978194\ttotal: 4m 1s\tremaining: 30.3s\n533:\tlearn: 0.4977046\ttotal: 4m 1s\tremaining: 29.9s\n534:\tlearn: 0.4976630\ttotal: 4m 2s\tremaining: 29.4s\n535:\tlearn: 0.4974400\ttotal: 4m 2s\tremaining: 29s\n536:\tlearn: 0.4973518\ttotal: 4m 3s\tremaining: 28.5s\n537:\tlearn: 0.4972293\ttotal: 4m 3s\tremaining: 28.1s\n538:\tlearn: 0.4971718\ttotal: 4m 3s\tremaining: 27.6s\n539:\tlearn: 0.4969023\ttotal: 4m 4s\tremaining: 27.2s\n540:\tlearn: 0.4962224\ttotal: 4m 4s\tremaining: 26.7s\n541:\tlearn: 0.4958347\ttotal: 4m 5s\tremaining: 26.2s\n542:\tlearn: 0.4940075\ttotal: 4m 5s\tremaining: 25.8s\n543:\tlearn: 0.4920275\ttotal: 4m 6s\tremaining: 25.3s\n544:\tlearn: 0.4919762\ttotal: 4m 6s\tremaining: 24.9s\n545:\tlearn: 0.4919246\ttotal: 4m 7s\tremaining: 24.4s\n546:\tlearn: 0.4918365\ttotal: 4m 7s\tremaining: 24s\n547:\tlearn: 0.4916658\ttotal: 4m 7s\tremaining: 23.5s\n548:\tlearn: 0.4913606\ttotal: 4m 8s\tremaining: 23.1s\n549:\tlearn: 0.4900546\ttotal: 4m 8s\tremaining: 22.6s\n550:\tlearn: 0.4879623\ttotal: 4m 9s\tremaining: 22.2s\n551:\tlearn: 0.4878690\ttotal: 4m 9s\tremaining: 21.7s\n552:\tlearn: 0.4878052\ttotal: 4m 10s\tremaining: 21.3s\n553:\tlearn: 0.4874902\ttotal: 4m 10s\tremaining: 20.8s\n554:\tlearn: 0.4866432\ttotal: 4m 11s\tremaining: 20.4s\n555:\tlearn: 0.4864932\ttotal: 4m 11s\tremaining: 19.9s\n556:\tlearn: 0.4864107\ttotal: 4m 12s\tremaining: 19.5s\n557:\tlearn: 0.4863172\ttotal: 4m 12s\tremaining: 19s\n558:\tlearn: 0.4862442\ttotal: 4m 12s\tremaining: 18.6s\n559:\tlearn: 0.4860794\ttotal: 4m 13s\tremaining: 18.1s\n560:\tlearn: 0.4858828\ttotal: 4m 13s\tremaining: 17.6s\n561:\tlearn: 0.4853013\ttotal: 4m 14s\tremaining: 17.2s\n562:\tlearn: 0.4852098\ttotal: 4m 14s\tremaining: 16.7s\n563:\tlearn: 0.4850454\ttotal: 4m 15s\tremaining: 16.3s\n564:\tlearn: 0.4848013\ttotal: 4m 15s\tremaining: 15.8s\n565:\tlearn: 0.4839787\ttotal: 4m 16s\tremaining: 15.4s\n566:\tlearn: 0.4836625\ttotal: 4m 16s\tremaining: 14.9s\n567:\tlearn: 0.4834544\ttotal: 4m 16s\tremaining: 14.5s\n568:\tlearn: 0.4827477\ttotal: 4m 17s\tremaining: 14s\n569:\tlearn: 0.4826583\ttotal: 4m 17s\tremaining: 13.6s\n570:\tlearn: 0.4816830\ttotal: 4m 18s\tremaining: 13.1s\n571:\tlearn: 0.4815734\ttotal: 4m 18s\tremaining: 12.7s\n572:\tlearn: 0.4813563\ttotal: 4m 19s\tremaining: 12.2s\n573:\tlearn: 0.4806417\ttotal: 4m 19s\tremaining: 11.8s\n574:\tlearn: 0.4798525\ttotal: 4m 20s\tremaining: 11.3s\n575:\tlearn: 0.4796386\ttotal: 4m 20s\tremaining: 10.9s\n576:\tlearn: 0.4789443\ttotal: 4m 21s\tremaining: 10.4s\n577:\tlearn: 0.4785192\ttotal: 4m 21s\tremaining: 9.95s\n578:\tlearn: 0.4784826\ttotal: 4m 21s\tremaining: 9.5s\n579:\tlearn: 0.4783923\ttotal: 4m 22s\tremaining: 9.04s\n580:\tlearn: 0.4783127\ttotal: 4m 22s\tremaining: 8.59s\n581:\tlearn: 0.4780269\ttotal: 4m 23s\tremaining: 8.14s\n582:\tlearn: 0.4778864\ttotal: 4m 23s\tremaining: 7.69s\n583:\tlearn: 0.4774954\ttotal: 4m 24s\tremaining: 7.24s\n584:\tlearn: 0.4774409\ttotal: 4m 24s\tremaining: 6.78s\n585:\tlearn: 0.4772781\ttotal: 4m 24s\tremaining: 6.33s\n586:\tlearn: 0.4770636\ttotal: 4m 25s\tremaining: 5.88s\n587:\tlearn: 0.4763020\ttotal: 4m 25s\tremaining: 5.43s\n588:\tlearn: 0.4760154\ttotal: 4m 26s\tremaining: 4.97s\n589:\tlearn: 0.4755553\ttotal: 4m 26s\tremaining: 4.52s\n590:\tlearn: 0.4754798\ttotal: 4m 27s\tremaining: 4.07s\n591:\tlearn: 0.4754324\ttotal: 4m 27s\tremaining: 3.62s\n592:\tlearn: 0.4749767\ttotal: 4m 28s\tremaining: 3.16s\n593:\tlearn: 0.4747865\ttotal: 4m 28s\tremaining: 2.71s\n594:\tlearn: 0.4746102\ttotal: 4m 28s\tremaining: 2.26s\n595:\tlearn: 0.4744723\ttotal: 4m 29s\tremaining: 1.81s\n596:\tlearn: 0.4740808\ttotal: 4m 29s\tremaining: 1.36s\n597:\tlearn: 0.4735042\ttotal: 4m 30s\tremaining: 904ms\n598:\tlearn: 0.4726549\ttotal: 4m 30s\tremaining: 452ms\n599:\tlearn: 0.4725023\ttotal: 4m 31s\tremaining: 0us\ncat_fit_done\nmodel_ready\n0:\tlearn: 2.7012412\ttotal: 356ms\tremaining: 3m 33s\n1:\tlearn: 2.6226766\ttotal: 699ms\tremaining: 3m 29s\n2:\tlearn: 2.5672642\ttotal: 1.06s\tremaining: 3m 30s\n3:\tlearn: 2.5198858\ttotal: 1.41s\tremaining: 3m 29s\n4:\tlearn: 2.4644550\ttotal: 1.76s\tremaining: 3m 29s\n5:\tlearn: 2.3966877\ttotal: 2.12s\tremaining: 3m 29s\n6:\tlearn: 2.3570223\ttotal: 2.47s\tremaining: 3m 29s\n7:\tlearn: 2.3244929\ttotal: 2.83s\tremaining: 3m 29s\n8:\tlearn: 2.2810424\ttotal: 3.17s\tremaining: 3m 28s\n9:\tlearn: 2.2485649\ttotal: 3.52s\tremaining: 3m 27s\n10:\tlearn: 2.2269918\ttotal: 3.88s\tremaining: 3m 27s\n11:\tlearn: 2.1833125\ttotal: 4.24s\tremaining: 3m 27s\n12:\tlearn: 2.1580889\ttotal: 4.58s\tremaining: 3m 26s\n13:\tlearn: 2.1340950\ttotal: 4.93s\tremaining: 3m 26s\n14:\tlearn: 2.1041488\ttotal: 5.29s\tremaining: 3m 26s\n15:\tlearn: 2.0761270\ttotal: 5.64s\tremaining: 3m 25s\n16:\tlearn: 2.0397440\ttotal: 6s\tremaining: 3m 25s\n17:\tlearn: 2.0221848\ttotal: 6.34s\tremaining: 3m 25s\n18:\tlearn: 1.9976403\ttotal: 6.69s\tremaining: 3m 24s\n19:\tlearn: 1.9640502\ttotal: 7.04s\tremaining: 3m 24s\n20:\tlearn: 1.9414993\ttotal: 7.38s\tremaining: 3m 23s\n21:\tlearn: 1.9236985\ttotal: 7.74s\tremaining: 3m 23s\n22:\tlearn: 1.9069373\ttotal: 8.08s\tremaining: 3m 22s\n23:\tlearn: 1.8850745\ttotal: 8.43s\tremaining: 3m 22s\n24:\tlearn: 1.8698284\ttotal: 8.78s\tremaining: 3m 21s\n25:\tlearn: 1.8544280\ttotal: 9.12s\tremaining: 3m 21s\n26:\tlearn: 1.8387650\ttotal: 9.47s\tremaining: 3m 20s\n27:\tlearn: 1.8128838\ttotal: 9.83s\tremaining: 3m 20s\n28:\tlearn: 1.7904731\ttotal: 10.2s\tremaining: 3m 20s\n29:\tlearn: 1.7769257\ttotal: 10.6s\tremaining: 3m 20s\n30:\tlearn: 1.7667867\ttotal: 10.9s\tremaining: 3m 20s\n31:\tlearn: 1.7546023\ttotal: 11.3s\tremaining: 3m 19s\n32:\tlearn: 1.7378140\ttotal: 11.6s\tremaining: 3m 19s\n33:\tlearn: 1.7228179\ttotal: 11.9s\tremaining: 3m 18s\n34:\tlearn: 1.7040353\ttotal: 12.3s\tremaining: 3m 18s\n35:\tlearn: 1.6936953\ttotal: 12.6s\tremaining: 3m 17s\n36:\tlearn: 1.6838832\ttotal: 13s\tremaining: 3m 17s\n37:\tlearn: 1.6691960\ttotal: 13.3s\tremaining: 3m 17s\n38:\tlearn: 1.6619700\ttotal: 13.7s\tremaining: 3m 16s\n39:\tlearn: 1.6481878\ttotal: 14s\tremaining: 3m 16s\n40:\tlearn: 1.6224519\ttotal: 14.4s\tremaining: 3m 16s\n41:\tlearn: 1.6124336\ttotal: 14.7s\tremaining: 3m 15s\n42:\tlearn: 1.5948434\ttotal: 15.1s\tremaining: 3m 15s\n43:\tlearn: 1.5766619\ttotal: 15.5s\tremaining: 3m 15s\n44:\tlearn: 1.5713911\ttotal: 15.8s\tremaining: 3m 14s\n45:\tlearn: 1.5661020\ttotal: 16.1s\tremaining: 3m 14s\n46:\tlearn: 1.5501166\ttotal: 16.5s\tremaining: 3m 14s\n47:\tlearn: 1.5377562\ttotal: 16.8s\tremaining: 3m 13s\n48:\tlearn: 1.5282874\ttotal: 17.2s\tremaining: 3m 13s\n49:\tlearn: 1.5218079\ttotal: 17.5s\tremaining: 3m 12s\n50:\tlearn: 1.5131082\ttotal: 17.9s\tremaining: 3m 12s\n51:\tlearn: 1.5050564\ttotal: 18.2s\tremaining: 3m 11s\n52:\tlearn: 1.4982252\ttotal: 18.5s\tremaining: 3m 11s\n53:\tlearn: 1.4910134\ttotal: 18.9s\tremaining: 3m 10s\n54:\tlearn: 1.4846153\ttotal: 19.2s\tremaining: 3m 10s\n55:\tlearn: 1.4731234\ttotal: 19.6s\tremaining: 3m 10s\n56:\tlearn: 1.4669956\ttotal: 19.9s\tremaining: 3m 9s\n57:\tlearn: 1.4522181\ttotal: 20.3s\tremaining: 3m 9s\n58:\tlearn: 1.4444892\ttotal: 20.6s\tremaining: 3m 9s\n59:\tlearn: 1.4353928\ttotal: 21s\tremaining: 3m 8s\n60:\tlearn: 1.4266275\ttotal: 21.3s\tremaining: 3m 8s\n61:\tlearn: 1.4239241\ttotal: 21.7s\tremaining: 3m 7s\n62:\tlearn: 1.4177187\ttotal: 22s\tremaining: 3m 7s\n63:\tlearn: 1.4107233\ttotal: 22.3s\tremaining: 3m 7s\n64:\tlearn: 1.4017207\ttotal: 22.7s\tremaining: 3m 6s\n65:\tlearn: 1.3919450\ttotal: 23s\tremaining: 3m 6s\n66:\tlearn: 1.3815393\ttotal: 23.4s\tremaining: 3m 6s\n67:\tlearn: 1.3675316\ttotal: 23.7s\tremaining: 3m 5s\n68:\tlearn: 1.3619073\ttotal: 24.1s\tremaining: 3m 5s\n69:\tlearn: 1.3536737\ttotal: 24.4s\tremaining: 3m 5s\n70:\tlearn: 1.3467225\ttotal: 24.8s\tremaining: 3m 4s\n71:\tlearn: 1.3431765\ttotal: 25.1s\tremaining: 3m 4s\n72:\tlearn: 1.3409802\ttotal: 25.5s\tremaining: 3m 3s\n73:\tlearn: 1.3259760\ttotal: 25.8s\tremaining: 3m 3s\n74:\tlearn: 1.3143684\ttotal: 26.2s\tremaining: 3m 3s\n75:\tlearn: 1.3066191\ttotal: 26.5s\tremaining: 3m 2s\n76:\tlearn: 1.2964108\ttotal: 26.9s\tremaining: 3m 2s\n77:\tlearn: 1.2909942\ttotal: 27.2s\tremaining: 3m 2s\n78:\tlearn: 1.2776111\ttotal: 27.6s\tremaining: 3m 1s\n79:\tlearn: 1.2720397\ttotal: 27.9s\tremaining: 3m 1s\n80:\tlearn: 1.2598957\ttotal: 28.3s\tremaining: 3m 1s\n81:\tlearn: 1.2511848\ttotal: 28.6s\tremaining: 3m\n82:\tlearn: 1.2439386\ttotal: 29s\tremaining: 3m\n83:\tlearn: 1.2375141\ttotal: 29.3s\tremaining: 3m\n84:\tlearn: 1.2341181\ttotal: 29.7s\tremaining: 2m 59s\n85:\tlearn: 1.2218095\ttotal: 30s\tremaining: 2m 59s\n86:\tlearn: 1.2117140\ttotal: 30.4s\tremaining: 2m 59s\n87:\tlearn: 1.1996007\ttotal: 30.7s\tremaining: 2m 58s\n88:\tlearn: 1.1842591\ttotal: 31.1s\tremaining: 2m 58s\n89:\tlearn: 1.1734051\ttotal: 31.4s\tremaining: 2m 58s\n90:\tlearn: 1.1673791\ttotal: 31.8s\tremaining: 2m 57s\n91:\tlearn: 1.1517022\ttotal: 32.2s\tremaining: 2m 57s\n92:\tlearn: 1.1483481\ttotal: 32.5s\tremaining: 2m 57s\n93:\tlearn: 1.1359328\ttotal: 32.9s\tremaining: 2m 56s\n94:\tlearn: 1.1328316\ttotal: 33.2s\tremaining: 2m 56s\n95:\tlearn: 1.1189868\ttotal: 33.6s\tremaining: 2m 56s\n96:\tlearn: 1.1098021\ttotal: 33.9s\tremaining: 2m 56s\n97:\tlearn: 1.0962627\ttotal: 34.3s\tremaining: 2m 55s\n98:\tlearn: 1.0909584\ttotal: 34.7s\tremaining: 2m 55s\n99:\tlearn: 1.0843929\ttotal: 35s\tremaining: 2m 55s\n100:\tlearn: 1.0797217\ttotal: 35.3s\tremaining: 2m 54s\n101:\tlearn: 1.0756561\ttotal: 35.7s\tremaining: 2m 54s\n102:\tlearn: 1.0597846\ttotal: 36.1s\tremaining: 2m 54s\n103:\tlearn: 1.0548042\ttotal: 36.4s\tremaining: 2m 53s\n104:\tlearn: 1.0454671\ttotal: 36.8s\tremaining: 2m 53s\n105:\tlearn: 1.0354612\ttotal: 37.1s\tremaining: 2m 53s\n106:\tlearn: 1.0232965\ttotal: 37.5s\tremaining: 2m 52s\n107:\tlearn: 1.0204285\ttotal: 37.8s\tremaining: 2m 52s\n108:\tlearn: 1.0145067\ttotal: 38.2s\tremaining: 2m 52s\n109:\tlearn: 1.0134416\ttotal: 38.5s\tremaining: 2m 51s\n110:\tlearn: 1.0096218\ttotal: 38.9s\tremaining: 2m 51s\n111:\tlearn: 1.0024682\ttotal: 39.2s\tremaining: 2m 50s\n112:\tlearn: 0.9994146\ttotal: 39.6s\tremaining: 2m 50s\n113:\tlearn: 0.9962189\ttotal: 39.9s\tremaining: 2m 50s\n114:\tlearn: 0.9888114\ttotal: 40.3s\tremaining: 2m 49s\n115:\tlearn: 0.9787314\ttotal: 40.6s\tremaining: 2m 49s\n116:\tlearn: 0.9749832\ttotal: 41s\tremaining: 2m 49s\n117:\tlearn: 0.9689260\ttotal: 41.4s\tremaining: 2m 48s\n118:\tlearn: 0.9682270\ttotal: 41.7s\tremaining: 2m 48s\n119:\tlearn: 0.9629354\ttotal: 42.1s\tremaining: 2m 48s\n120:\tlearn: 0.9599510\ttotal: 42.4s\tremaining: 2m 47s\n121:\tlearn: 0.9550040\ttotal: 42.8s\tremaining: 2m 47s\n122:\tlearn: 0.9489797\ttotal: 43.1s\tremaining: 2m 47s\n123:\tlearn: 0.9441826\ttotal: 43.5s\tremaining: 2m 46s\n124:\tlearn: 0.9422371\ttotal: 43.8s\tremaining: 2m 46s\n125:\tlearn: 0.9379118\ttotal: 44.2s\tremaining: 2m 46s\n126:\tlearn: 0.9292942\ttotal: 44.5s\tremaining: 2m 45s\n127:\tlearn: 0.9259937\ttotal: 44.9s\tremaining: 2m 45s\n128:\tlearn: 0.9171563\ttotal: 45.2s\tremaining: 2m 45s\n129:\tlearn: 0.9069849\ttotal: 45.6s\tremaining: 2m 44s\n130:\tlearn: 0.9048521\ttotal: 45.9s\tremaining: 2m 44s\n131:\tlearn: 0.8939246\ttotal: 46.3s\tremaining: 2m 44s\n132:\tlearn: 0.8850830\ttotal: 46.7s\tremaining: 2m 43s\n133:\tlearn: 0.8829990\ttotal: 47s\tremaining: 2m 43s\n134:\tlearn: 0.8777628\ttotal: 47.4s\tremaining: 2m 43s\n135:\tlearn: 0.8752135\ttotal: 47.7s\tremaining: 2m 42s\n136:\tlearn: 0.8662001\ttotal: 48.1s\tremaining: 2m 42s\n137:\tlearn: 0.8597315\ttotal: 48.4s\tremaining: 2m 42s\n138:\tlearn: 0.8582278\ttotal: 48.8s\tremaining: 2m 41s\n139:\tlearn: 0.8494019\ttotal: 49.1s\tremaining: 2m 41s\n140:\tlearn: 0.8468479\ttotal: 49.5s\tremaining: 2m 41s\n141:\tlearn: 0.8428941\ttotal: 49.8s\tremaining: 2m 40s\n142:\tlearn: 0.8393039\ttotal: 50.2s\tremaining: 2m 40s\n143:\tlearn: 0.8331010\ttotal: 50.5s\tremaining: 2m 40s\n144:\tlearn: 0.8297539\ttotal: 50.9s\tremaining: 2m 39s\n145:\tlearn: 0.8208811\ttotal: 51.2s\tremaining: 2m 39s\n146:\tlearn: 0.8148926\ttotal: 51.6s\tremaining: 2m 39s\n147:\tlearn: 0.8121890\ttotal: 51.9s\tremaining: 2m 38s\n148:\tlearn: 0.8057491\ttotal: 52.3s\tremaining: 2m 38s\n149:\tlearn: 0.8005796\ttotal: 52.7s\tremaining: 2m 38s\n150:\tlearn: 0.7938994\ttotal: 53s\tremaining: 2m 37s\n151:\tlearn: 0.7918888\ttotal: 53.4s\tremaining: 2m 37s\n152:\tlearn: 0.7899126\ttotal: 53.7s\tremaining: 2m 36s\n153:\tlearn: 0.7853132\ttotal: 54.1s\tremaining: 2m 36s\n154:\tlearn: 0.7806703\ttotal: 54.4s\tremaining: 2m 36s\n155:\tlearn: 0.7730171\ttotal: 54.8s\tremaining: 2m 35s\n156:\tlearn: 0.7652347\ttotal: 55.1s\tremaining: 2m 35s\n157:\tlearn: 0.7623709\ttotal: 55.5s\tremaining: 2m 35s\n158:\tlearn: 0.7599942\ttotal: 55.8s\tremaining: 2m 34s\n159:\tlearn: 0.7570040\ttotal: 56.2s\tremaining: 2m 34s\n160:\tlearn: 0.7544750\ttotal: 56.5s\tremaining: 2m 34s\n161:\tlearn: 0.7498981\ttotal: 56.9s\tremaining: 2m 33s\n162:\tlearn: 0.7492276\ttotal: 57.2s\tremaining: 2m 33s\n163:\tlearn: 0.7436330\ttotal: 57.6s\tremaining: 2m 33s\n164:\tlearn: 0.7368879\ttotal: 58s\tremaining: 2m 32s\n165:\tlearn: 0.7309407\ttotal: 58.3s\tremaining: 2m 32s\n166:\tlearn: 0.7300823\ttotal: 58.7s\tremaining: 2m 32s\n167:\tlearn: 0.7287716\ttotal: 59s\tremaining: 2m 31s\n168:\tlearn: 0.7270727\ttotal: 59.3s\tremaining: 2m 31s\n169:\tlearn: 0.7245138\ttotal: 59.7s\tremaining: 2m 30s\n170:\tlearn: 0.7188865\ttotal: 1m\tremaining: 2m 30s\n171:\tlearn: 0.7175022\ttotal: 1m\tremaining: 2m 30s\n172:\tlearn: 0.7163928\ttotal: 1m\tremaining: 2m 29s\n173:\tlearn: 0.7156612\ttotal: 1m 1s\tremaining: 2m 29s\n174:\tlearn: 0.7104380\ttotal: 1m 1s\tremaining: 2m 29s\n175:\tlearn: 0.7092009\ttotal: 1m 1s\tremaining: 2m 28s\n176:\tlearn: 0.7052009\ttotal: 1m 2s\tremaining: 2m 28s\n177:\tlearn: 0.7042237\ttotal: 1m 2s\tremaining: 2m 28s\n178:\tlearn: 0.6979241\ttotal: 1m 2s\tremaining: 2m 27s\n179:\tlearn: 0.6974435\ttotal: 1m 3s\tremaining: 2m 27s\n180:\tlearn: 0.6969551\ttotal: 1m 3s\tremaining: 2m 27s\n181:\tlearn: 0.6936226\ttotal: 1m 3s\tremaining: 2m 26s\n182:\tlearn: 0.6900166\ttotal: 1m 4s\tremaining: 2m 26s\n183:\tlearn: 0.6879073\ttotal: 1m 4s\tremaining: 2m 26s\n184:\tlearn: 0.6859800\ttotal: 1m 4s\tremaining: 2m 25s\n185:\tlearn: 0.6830069\ttotal: 1m 5s\tremaining: 2m 25s\n186:\tlearn: 0.6777935\ttotal: 1m 5s\tremaining: 2m 24s\n187:\tlearn: 0.6749211\ttotal: 1m 5s\tremaining: 2m 24s\n188:\tlearn: 0.6707717\ttotal: 1m 6s\tremaining: 2m 24s\n189:\tlearn: 0.6665529\ttotal: 1m 6s\tremaining: 2m 23s\n190:\tlearn: 0.6633132\ttotal: 1m 7s\tremaining: 2m 23s\n191:\tlearn: 0.6596924\ttotal: 1m 7s\tremaining: 2m 23s\n192:\tlearn: 0.6519799\ttotal: 1m 7s\tremaining: 2m 22s\n193:\tlearn: 0.6509317\ttotal: 1m 8s\tremaining: 2m 22s\n194:\tlearn: 0.6488255\ttotal: 1m 8s\tremaining: 2m 22s\n195:\tlearn: 0.6445522\ttotal: 1m 8s\tremaining: 2m 21s\n196:\tlearn: 0.6428697\ttotal: 1m 9s\tremaining: 2m 21s\n197:\tlearn: 0.6365444\ttotal: 1m 9s\tremaining: 2m 21s\n198:\tlearn: 0.6362034\ttotal: 1m 9s\tremaining: 2m 20s\n199:\tlearn: 0.6309556\ttotal: 1m 10s\tremaining: 2m 20s\n200:\tlearn: 0.6287108\ttotal: 1m 10s\tremaining: 2m 20s\n201:\tlearn: 0.6263504\ttotal: 1m 10s\tremaining: 2m 19s\n202:\tlearn: 0.6255622\ttotal: 1m 11s\tremaining: 2m 19s\n203:\tlearn: 0.6243829\ttotal: 1m 11s\tremaining: 2m 19s\n204:\tlearn: 0.6230303\ttotal: 1m 11s\tremaining: 2m 18s\n205:\tlearn: 0.6217073\ttotal: 1m 12s\tremaining: 2m 18s\n206:\tlearn: 0.6160736\ttotal: 1m 12s\tremaining: 2m 18s\n207:\tlearn: 0.6139681\ttotal: 1m 13s\tremaining: 2m 17s\n208:\tlearn: 0.6104238\ttotal: 1m 13s\tremaining: 2m 17s\n209:\tlearn: 0.6048577\ttotal: 1m 13s\tremaining: 2m 17s\n210:\tlearn: 0.6041795\ttotal: 1m 14s\tremaining: 2m 16s\n211:\tlearn: 0.6035670\ttotal: 1m 14s\tremaining: 2m 16s\n212:\tlearn: 0.6023937\ttotal: 1m 14s\tremaining: 2m 15s\n213:\tlearn: 0.6016964\ttotal: 1m 15s\tremaining: 2m 15s\n214:\tlearn: 0.6003589\ttotal: 1m 15s\tremaining: 2m 15s\n215:\tlearn: 0.5986016\ttotal: 1m 15s\tremaining: 2m 14s\n216:\tlearn: 0.5980130\ttotal: 1m 16s\tremaining: 2m 14s\n217:\tlearn: 0.5967798\ttotal: 1m 16s\tremaining: 2m 14s\n218:\tlearn: 0.5955780\ttotal: 1m 16s\tremaining: 2m 13s\n219:\tlearn: 0.5922501\ttotal: 1m 17s\tremaining: 2m 13s\n220:\tlearn: 0.5916189\ttotal: 1m 17s\tremaining: 2m 13s\n221:\tlearn: 0.5894158\ttotal: 1m 17s\tremaining: 2m 12s\n222:\tlearn: 0.5862233\ttotal: 1m 18s\tremaining: 2m 12s\n223:\tlearn: 0.5858128\ttotal: 1m 18s\tremaining: 2m 12s\n224:\tlearn: 0.5844812\ttotal: 1m 19s\tremaining: 2m 11s\n225:\tlearn: 0.5827055\ttotal: 1m 19s\tremaining: 2m 11s\n226:\tlearn: 0.5816695\ttotal: 1m 19s\tremaining: 2m 11s\n227:\tlearn: 0.5798941\ttotal: 1m 20s\tremaining: 2m 10s\n228:\tlearn: 0.5791088\ttotal: 1m 20s\tremaining: 2m 10s\n229:\tlearn: 0.5778313\ttotal: 1m 20s\tremaining: 2m 9s\n230:\tlearn: 0.5747382\ttotal: 1m 21s\tremaining: 2m 9s\n231:\tlearn: 0.5743165\ttotal: 1m 21s\tremaining: 2m 9s\n232:\tlearn: 0.5716550\ttotal: 1m 21s\tremaining: 2m 8s\n233:\tlearn: 0.5682247\ttotal: 1m 22s\tremaining: 2m 8s\n234:\tlearn: 0.5643792\ttotal: 1m 22s\tremaining: 2m 8s\n235:\tlearn: 0.5635776\ttotal: 1m 22s\tremaining: 2m 7s\n236:\tlearn: 0.5627668\ttotal: 1m 23s\tremaining: 2m 7s\n237:\tlearn: 0.5623366\ttotal: 1m 23s\tremaining: 2m 7s\n238:\tlearn: 0.5579854\ttotal: 1m 23s\tremaining: 2m 6s\n239:\tlearn: 0.5564254\ttotal: 1m 24s\tremaining: 2m 6s\n240:\tlearn: 0.5547497\ttotal: 1m 24s\tremaining: 2m 6s\n241:\tlearn: 0.5543305\ttotal: 1m 25s\tremaining: 2m 5s\n242:\tlearn: 0.5536743\ttotal: 1m 25s\tremaining: 2m 5s\n243:\tlearn: 0.5526824\ttotal: 1m 25s\tremaining: 2m 5s\n244:\tlearn: 0.5482430\ttotal: 1m 26s\tremaining: 2m 4s\n245:\tlearn: 0.5462420\ttotal: 1m 26s\tremaining: 2m 4s\n246:\tlearn: 0.5455912\ttotal: 1m 26s\tremaining: 2m 3s\n247:\tlearn: 0.5426035\ttotal: 1m 27s\tremaining: 2m 3s\n248:\tlearn: 0.5380185\ttotal: 1m 27s\tremaining: 2m 3s\n249:\tlearn: 0.5357961\ttotal: 1m 27s\tremaining: 2m 2s\n250:\tlearn: 0.5353948\ttotal: 1m 28s\tremaining: 2m 2s\n251:\tlearn: 0.5338221\ttotal: 1m 28s\tremaining: 2m 2s\n252:\tlearn: 0.5334665\ttotal: 1m 28s\tremaining: 2m 1s\n253:\tlearn: 0.5326194\ttotal: 1m 29s\tremaining: 2m 1s\n254:\tlearn: 0.5285734\ttotal: 1m 29s\tremaining: 2m 1s\n255:\tlearn: 0.5272919\ttotal: 1m 29s\tremaining: 2m\n256:\tlearn: 0.5250982\ttotal: 1m 30s\tremaining: 2m\n257:\tlearn: 0.5223633\ttotal: 1m 30s\tremaining: 2m\n258:\tlearn: 0.5201052\ttotal: 1m 30s\tremaining: 1m 59s\n259:\tlearn: 0.5196659\ttotal: 1m 31s\tremaining: 1m 59s\n260:\tlearn: 0.5191822\ttotal: 1m 31s\tremaining: 1m 59s\n261:\tlearn: 0.5185673\ttotal: 1m 32s\tremaining: 1m 58s\n262:\tlearn: 0.5179025\ttotal: 1m 32s\tremaining: 1m 58s\n263:\tlearn: 0.5171039\ttotal: 1m 32s\tremaining: 1m 57s\n264:\tlearn: 0.5159177\ttotal: 1m 33s\tremaining: 1m 57s\n265:\tlearn: 0.5150133\ttotal: 1m 33s\tremaining: 1m 57s\n266:\tlearn: 0.5144106\ttotal: 1m 33s\tremaining: 1m 56s\n267:\tlearn: 0.5140145\ttotal: 1m 34s\tremaining: 1m 56s\n268:\tlearn: 0.5134113\ttotal: 1m 34s\tremaining: 1m 56s\n269:\tlearn: 0.5129581\ttotal: 1m 34s\tremaining: 1m 55s\n270:\tlearn: 0.5125335\ttotal: 1m 35s\tremaining: 1m 55s\n271:\tlearn: 0.5111840\ttotal: 1m 35s\tremaining: 1m 55s\n272:\tlearn: 0.5099862\ttotal: 1m 35s\tremaining: 1m 54s\n273:\tlearn: 0.5063845\ttotal: 1m 36s\tremaining: 1m 54s\n274:\tlearn: 0.5049439\ttotal: 1m 36s\tremaining: 1m 54s\n275:\tlearn: 0.5029184\ttotal: 1m 36s\tremaining: 1m 53s\n276:\tlearn: 0.5021238\ttotal: 1m 37s\tremaining: 1m 53s\n277:\tlearn: 0.5019594\ttotal: 1m 37s\tremaining: 1m 53s\n278:\tlearn: 0.4994366\ttotal: 1m 37s\tremaining: 1m 52s\n279:\tlearn: 0.4987372\ttotal: 1m 38s\tremaining: 1m 52s\n280:\tlearn: 0.4980174\ttotal: 1m 38s\tremaining: 1m 51s\n281:\tlearn: 0.4966843\ttotal: 1m 38s\tremaining: 1m 51s\n282:\tlearn: 0.4925072\ttotal: 1m 39s\tremaining: 1m 51s\n283:\tlearn: 0.4915898\ttotal: 1m 39s\tremaining: 1m 50s\n284:\tlearn: 0.4907221\ttotal: 1m 40s\tremaining: 1m 50s\n285:\tlearn: 0.4886118\ttotal: 1m 40s\tremaining: 1m 50s\n286:\tlearn: 0.4871925\ttotal: 1m 40s\tremaining: 1m 49s\n287:\tlearn: 0.4862021\ttotal: 1m 41s\tremaining: 1m 49s\n288:\tlearn: 0.4856244\ttotal: 1m 41s\tremaining: 1m 49s\n289:\tlearn: 0.4847688\ttotal: 1m 41s\tremaining: 1m 48s\n290:\tlearn: 0.4817211\ttotal: 1m 42s\tremaining: 1m 48s\n291:\tlearn: 0.4813487\ttotal: 1m 42s\tremaining: 1m 48s\n292:\tlearn: 0.4791181\ttotal: 1m 42s\tremaining: 1m 47s\n293:\tlearn: 0.4771754\ttotal: 1m 43s\tremaining: 1m 47s\n294:\tlearn: 0.4768692\ttotal: 1m 43s\tremaining: 1m 47s\n295:\tlearn: 0.4759207\ttotal: 1m 43s\tremaining: 1m 46s\n296:\tlearn: 0.4735192\ttotal: 1m 44s\tremaining: 1m 46s\n297:\tlearn: 0.4732086\ttotal: 1m 44s\tremaining: 1m 45s\n298:\tlearn: 0.4727592\ttotal: 1m 44s\tremaining: 1m 45s\n299:\tlearn: 0.4724254\ttotal: 1m 45s\tremaining: 1m 45s\n300:\tlearn: 0.4714536\ttotal: 1m 45s\tremaining: 1m 44s\n301:\tlearn: 0.4708170\ttotal: 1m 45s\tremaining: 1m 44s\n302:\tlearn: 0.4648441\ttotal: 1m 46s\tremaining: 1m 44s\n303:\tlearn: 0.4641574\ttotal: 1m 46s\tremaining: 1m 43s\n304:\tlearn: 0.4636292\ttotal: 1m 47s\tremaining: 1m 43s\n305:\tlearn: 0.4619199\ttotal: 1m 47s\tremaining: 1m 43s\n306:\tlearn: 0.4612488\ttotal: 1m 47s\tremaining: 1m 42s\n307:\tlearn: 0.4587964\ttotal: 1m 48s\tremaining: 1m 42s\n308:\tlearn: 0.4581094\ttotal: 1m 48s\tremaining: 1m 42s\n309:\tlearn: 0.4570795\ttotal: 1m 48s\tremaining: 1m 41s\n310:\tlearn: 0.4566654\ttotal: 1m 49s\tremaining: 1m 41s\n311:\tlearn: 0.4552852\ttotal: 1m 49s\tremaining: 1m 41s\n312:\tlearn: 0.4540746\ttotal: 1m 49s\tremaining: 1m 40s\n313:\tlearn: 0.4529064\ttotal: 1m 50s\tremaining: 1m 40s\n314:\tlearn: 0.4524163\ttotal: 1m 50s\tremaining: 1m 40s\n315:\tlearn: 0.4518849\ttotal: 1m 50s\tremaining: 1m 39s\n316:\tlearn: 0.4512889\ttotal: 1m 51s\tremaining: 1m 39s\n317:\tlearn: 0.4511093\ttotal: 1m 51s\tremaining: 1m 38s\n318:\tlearn: 0.4473349\ttotal: 1m 51s\tremaining: 1m 38s\n319:\tlearn: 0.4466760\ttotal: 1m 52s\tremaining: 1m 38s\n320:\tlearn: 0.4453649\ttotal: 1m 52s\tremaining: 1m 37s\n321:\tlearn: 0.4447518\ttotal: 1m 52s\tremaining: 1m 37s\n322:\tlearn: 0.4445683\ttotal: 1m 53s\tremaining: 1m 37s\n323:\tlearn: 0.4441967\ttotal: 1m 53s\tremaining: 1m 36s\n324:\tlearn: 0.4440135\ttotal: 1m 54s\tremaining: 1m 36s\n325:\tlearn: 0.4426641\ttotal: 1m 54s\tremaining: 1m 36s\n326:\tlearn: 0.4421789\ttotal: 1m 54s\tremaining: 1m 35s\n327:\tlearn: 0.4418779\ttotal: 1m 55s\tremaining: 1m 35s\n328:\tlearn: 0.4387498\ttotal: 1m 55s\tremaining: 1m 35s\n329:\tlearn: 0.4382091\ttotal: 1m 55s\tremaining: 1m 34s\n330:\tlearn: 0.4378028\ttotal: 1m 56s\tremaining: 1m 34s\n331:\tlearn: 0.4375398\ttotal: 1m 56s\tremaining: 1m 34s\n332:\tlearn: 0.4372866\ttotal: 1m 56s\tremaining: 1m 33s\n333:\tlearn: 0.4370413\ttotal: 1m 57s\tremaining: 1m 33s\n334:\tlearn: 0.4364125\ttotal: 1m 57s\tremaining: 1m 32s\n335:\tlearn: 0.4358647\ttotal: 1m 57s\tremaining: 1m 32s\n336:\tlearn: 0.4352653\ttotal: 1m 58s\tremaining: 1m 32s\n337:\tlearn: 0.4350091\ttotal: 1m 58s\tremaining: 1m 31s\n338:\tlearn: 0.4343225\ttotal: 1m 58s\tremaining: 1m 31s\n339:\tlearn: 0.4334986\ttotal: 1m 59s\tremaining: 1m 31s\n340:\tlearn: 0.4299348\ttotal: 1m 59s\tremaining: 1m 30s\n341:\tlearn: 0.4297290\ttotal: 1m 59s\tremaining: 1m 30s\n342:\tlearn: 0.4288192\ttotal: 2m\tremaining: 1m 30s\n343:\tlearn: 0.4286536\ttotal: 2m\tremaining: 1m 29s\n344:\tlearn: 0.4279721\ttotal: 2m\tremaining: 1m 29s\n345:\tlearn: 0.4254593\ttotal: 2m 1s\tremaining: 1m 29s\n346:\tlearn: 0.4251074\ttotal: 2m 1s\tremaining: 1m 28s\n347:\tlearn: 0.4247042\ttotal: 2m 2s\tremaining: 1m 28s\n348:\tlearn: 0.4238231\ttotal: 2m 2s\tremaining: 1m 28s\n349:\tlearn: 0.4234875\ttotal: 2m 2s\tremaining: 1m 27s\n350:\tlearn: 0.4233233\ttotal: 2m 3s\tremaining: 1m 27s\n351:\tlearn: 0.4223484\ttotal: 2m 3s\tremaining: 1m 26s\n352:\tlearn: 0.4208099\ttotal: 2m 3s\tremaining: 1m 26s\n353:\tlearn: 0.4205943\ttotal: 2m 4s\tremaining: 1m 26s\n354:\tlearn: 0.4185423\ttotal: 2m 4s\tremaining: 1m 25s\n355:\tlearn: 0.4175753\ttotal: 2m 4s\tremaining: 1m 25s\n356:\tlearn: 0.4174598\ttotal: 2m 5s\tremaining: 1m 25s\n357:\tlearn: 0.4170031\ttotal: 2m 5s\tremaining: 1m 24s\n358:\tlearn: 0.4152541\ttotal: 2m 5s\tremaining: 1m 24s\n359:\tlearn: 0.4146648\ttotal: 2m 6s\tremaining: 1m 24s\n360:\tlearn: 0.4134827\ttotal: 2m 6s\tremaining: 1m 23s\n361:\tlearn: 0.4133356\ttotal: 2m 6s\tremaining: 1m 23s\n362:\tlearn: 0.4130511\ttotal: 2m 7s\tremaining: 1m 23s\n363:\tlearn: 0.4129229\ttotal: 2m 7s\tremaining: 1m 22s\n364:\tlearn: 0.4126138\ttotal: 2m 7s\tremaining: 1m 22s\n365:\tlearn: 0.4125482\ttotal: 2m 8s\tremaining: 1m 22s\n366:\tlearn: 0.4122600\ttotal: 2m 8s\tremaining: 1m 21s\n367:\tlearn: 0.4121362\ttotal: 2m 8s\tremaining: 1m 21s\n368:\tlearn: 0.4109706\ttotal: 2m 9s\tremaining: 1m 20s\n369:\tlearn: 0.4108055\ttotal: 2m 9s\tremaining: 1m 20s\n370:\tlearn: 0.4104391\ttotal: 2m 10s\tremaining: 1m 20s\n371:\tlearn: 0.4101599\ttotal: 2m 10s\tremaining: 1m 19s\n372:\tlearn: 0.4099303\ttotal: 2m 10s\tremaining: 1m 19s\n373:\tlearn: 0.4096051\ttotal: 2m 11s\tremaining: 1m 19s\n374:\tlearn: 0.4078447\ttotal: 2m 11s\tremaining: 1m 18s\n375:\tlearn: 0.4074316\ttotal: 2m 11s\tremaining: 1m 18s\n376:\tlearn: 0.4072742\ttotal: 2m 12s\tremaining: 1m 18s\n377:\tlearn: 0.4054593\ttotal: 2m 12s\tremaining: 1m 17s\n378:\tlearn: 0.4053577\ttotal: 2m 12s\tremaining: 1m 17s\n379:\tlearn: 0.4049524\ttotal: 2m 13s\tremaining: 1m 17s\n380:\tlearn: 0.4049078\ttotal: 2m 13s\tremaining: 1m 16s\n381:\tlearn: 0.4048259\ttotal: 2m 13s\tremaining: 1m 16s\n382:\tlearn: 0.4018953\ttotal: 2m 14s\tremaining: 1m 16s\n383:\tlearn: 0.4016549\ttotal: 2m 14s\tremaining: 1m 15s\n384:\tlearn: 0.4015763\ttotal: 2m 14s\tremaining: 1m 15s\n385:\tlearn: 0.4011451\ttotal: 2m 15s\tremaining: 1m 14s\n386:\tlearn: 0.4005573\ttotal: 2m 15s\tremaining: 1m 14s\n387:\tlearn: 0.3997768\ttotal: 2m 15s\tremaining: 1m 14s\n388:\tlearn: 0.3996588\ttotal: 2m 16s\tremaining: 1m 13s\n389:\tlearn: 0.3982195\ttotal: 2m 16s\tremaining: 1m 13s\n390:\tlearn: 0.3978170\ttotal: 2m 17s\tremaining: 1m 13s\n391:\tlearn: 0.3975611\ttotal: 2m 17s\tremaining: 1m 12s\n392:\tlearn: 0.3974374\ttotal: 2m 17s\tremaining: 1m 12s\n393:\tlearn: 0.3966284\ttotal: 2m 18s\tremaining: 1m 12s\n394:\tlearn: 0.3956154\ttotal: 2m 18s\tremaining: 1m 11s\n395:\tlearn: 0.3953040\ttotal: 2m 18s\tremaining: 1m 11s\n396:\tlearn: 0.3949845\ttotal: 2m 19s\tremaining: 1m 11s\n397:\tlearn: 0.3927752\ttotal: 2m 19s\tremaining: 1m 10s\n398:\tlearn: 0.3915834\ttotal: 2m 19s\tremaining: 1m 10s\n399:\tlearn: 0.3914964\ttotal: 2m 20s\tremaining: 1m 10s\n400:\tlearn: 0.3899113\ttotal: 2m 20s\tremaining: 1m 9s\n401:\tlearn: 0.3892928\ttotal: 2m 20s\tremaining: 1m 9s\n402:\tlearn: 0.3891301\ttotal: 2m 21s\tremaining: 1m 9s\n403:\tlearn: 0.3864595\ttotal: 2m 21s\tremaining: 1m 8s\n404:\tlearn: 0.3861227\ttotal: 2m 21s\tremaining: 1m 8s\n405:\tlearn: 0.3825310\ttotal: 2m 22s\tremaining: 1m 7s\n406:\tlearn: 0.3823522\ttotal: 2m 22s\tremaining: 1m 7s\n407:\tlearn: 0.3817478\ttotal: 2m 22s\tremaining: 1m 7s\n408:\tlearn: 0.3815221\ttotal: 2m 23s\tremaining: 1m 6s\n409:\tlearn: 0.3814397\ttotal: 2m 23s\tremaining: 1m 6s\n410:\tlearn: 0.3808634\ttotal: 2m 24s\tremaining: 1m 6s\n411:\tlearn: 0.3805569\ttotal: 2m 24s\tremaining: 1m 5s\n412:\tlearn: 0.3804253\ttotal: 2m 24s\tremaining: 1m 5s\n413:\tlearn: 0.3802547\ttotal: 2m 25s\tremaining: 1m 5s\n414:\tlearn: 0.3796644\ttotal: 2m 25s\tremaining: 1m 4s\n415:\tlearn: 0.3794309\ttotal: 2m 25s\tremaining: 1m 4s\n416:\tlearn: 0.3790524\ttotal: 2m 26s\tremaining: 1m 4s\n417:\tlearn: 0.3789002\ttotal: 2m 26s\tremaining: 1m 3s\n418:\tlearn: 0.3779768\ttotal: 2m 26s\tremaining: 1m 3s\n419:\tlearn: 0.3779071\ttotal: 2m 27s\tremaining: 1m 3s\n420:\tlearn: 0.3771769\ttotal: 2m 27s\tremaining: 1m 2s\n421:\tlearn: 0.3770735\ttotal: 2m 27s\tremaining: 1m 2s\n422:\tlearn: 0.3769599\ttotal: 2m 28s\tremaining: 1m 1s\n423:\tlearn: 0.3769036\ttotal: 2m 28s\tremaining: 1m 1s\n424:\tlearn: 0.3763181\ttotal: 2m 28s\tremaining: 1m 1s\n425:\tlearn: 0.3762076\ttotal: 2m 29s\tremaining: 1m\n426:\tlearn: 0.3745028\ttotal: 2m 29s\tremaining: 1m\n427:\tlearn: 0.3742216\ttotal: 2m 29s\tremaining: 1m\n428:\tlearn: 0.3726778\ttotal: 2m 30s\tremaining: 59.9s\n429:\tlearn: 0.3722459\ttotal: 2m 30s\tremaining: 59.5s\n430:\tlearn: 0.3720218\ttotal: 2m 30s\tremaining: 59.2s\n431:\tlearn: 0.3714220\ttotal: 2m 31s\tremaining: 58.8s\n432:\tlearn: 0.3710958\ttotal: 2m 31s\tremaining: 58.5s\n433:\tlearn: 0.3708849\ttotal: 2m 32s\tremaining: 58.1s\n434:\tlearn: 0.3694392\ttotal: 2m 32s\tremaining: 57.8s\n435:\tlearn: 0.3683833\ttotal: 2m 32s\tremaining: 57.4s\n436:\tlearn: 0.3666587\ttotal: 2m 33s\tremaining: 57.1s\n437:\tlearn: 0.3659971\ttotal: 2m 33s\tremaining: 56.8s\n438:\tlearn: 0.3658263\ttotal: 2m 33s\tremaining: 56.4s\n439:\tlearn: 0.3657580\ttotal: 2m 34s\tremaining: 56s\n440:\tlearn: 0.3656160\ttotal: 2m 34s\tremaining: 55.7s\n441:\tlearn: 0.3652358\ttotal: 2m 34s\tremaining: 55.3s\n442:\tlearn: 0.3643295\ttotal: 2m 35s\tremaining: 55s\n443:\tlearn: 0.3640604\ttotal: 2m 35s\tremaining: 54.6s\n444:\tlearn: 0.3635050\ttotal: 2m 35s\tremaining: 54.3s\n445:\tlearn: 0.3633406\ttotal: 2m 36s\tremaining: 53.9s\n446:\tlearn: 0.3631372\ttotal: 2m 36s\tremaining: 53.6s\n447:\tlearn: 0.3630171\ttotal: 2m 36s\tremaining: 53.2s\n448:\tlearn: 0.3628966\ttotal: 2m 37s\tremaining: 52.9s\n449:\tlearn: 0.3624639\ttotal: 2m 37s\tremaining: 52.5s\n450:\tlearn: 0.3616515\ttotal: 2m 37s\tremaining: 52.2s\n451:\tlearn: 0.3608304\ttotal: 2m 38s\tremaining: 51.8s\n452:\tlearn: 0.3603567\ttotal: 2m 38s\tremaining: 51.5s\n453:\tlearn: 0.3602827\ttotal: 2m 39s\tremaining: 51.1s\n454:\tlearn: 0.3589238\ttotal: 2m 39s\tremaining: 50.8s\n455:\tlearn: 0.3586844\ttotal: 2m 39s\tremaining: 50.4s\n456:\tlearn: 0.3583146\ttotal: 2m 40s\tremaining: 50.1s\n457:\tlearn: 0.3580795\ttotal: 2m 40s\tremaining: 49.7s\n458:\tlearn: 0.3579833\ttotal: 2m 40s\tremaining: 49.4s\n459:\tlearn: 0.3577804\ttotal: 2m 41s\tremaining: 49s\n460:\tlearn: 0.3573984\ttotal: 2m 41s\tremaining: 48.7s\n461:\tlearn: 0.3565893\ttotal: 2m 41s\tremaining: 48.3s\n462:\tlearn: 0.3564627\ttotal: 2m 42s\tremaining: 48s\n463:\tlearn: 0.3536810\ttotal: 2m 42s\tremaining: 47.6s\n464:\tlearn: 0.3531373\ttotal: 2m 42s\tremaining: 47.3s\n465:\tlearn: 0.3527809\ttotal: 2m 43s\tremaining: 46.9s\n466:\tlearn: 0.3525687\ttotal: 2m 43s\tremaining: 46.6s\n467:\tlearn: 0.3521460\ttotal: 2m 43s\tremaining: 46.2s\n468:\tlearn: 0.3520609\ttotal: 2m 44s\tremaining: 45.9s\n469:\tlearn: 0.3519695\ttotal: 2m 44s\tremaining: 45.5s\n470:\tlearn: 0.3518785\ttotal: 2m 44s\tremaining: 45.2s\n471:\tlearn: 0.3517926\ttotal: 2m 45s\tremaining: 44.8s\n472:\tlearn: 0.3503647\ttotal: 2m 45s\tremaining: 44.5s\n473:\tlearn: 0.3501463\ttotal: 2m 45s\tremaining: 44.1s\n474:\tlearn: 0.3501127\ttotal: 2m 46s\tremaining: 43.8s\n475:\tlearn: 0.3487416\ttotal: 2m 46s\tremaining: 43.4s\n476:\tlearn: 0.3486542\ttotal: 2m 47s\tremaining: 43.1s\n477:\tlearn: 0.3486236\ttotal: 2m 47s\tremaining: 42.7s\n478:\tlearn: 0.3478259\ttotal: 2m 47s\tremaining: 42.4s\n479:\tlearn: 0.3476288\ttotal: 2m 48s\tremaining: 42s\n480:\tlearn: 0.3471907\ttotal: 2m 48s\tremaining: 41.7s\n481:\tlearn: 0.3469569\ttotal: 2m 48s\tremaining: 41.3s\n482:\tlearn: 0.3466759\ttotal: 2m 49s\tremaining: 41s\n483:\tlearn: 0.3465475\ttotal: 2m 49s\tremaining: 40.6s\n484:\tlearn: 0.3461730\ttotal: 2m 49s\tremaining: 40.3s\n485:\tlearn: 0.3461215\ttotal: 2m 50s\tremaining: 39.9s\n486:\tlearn: 0.3433438\ttotal: 2m 50s\tremaining: 39.6s\n487:\tlearn: 0.3424767\ttotal: 2m 50s\tremaining: 39.2s\n488:\tlearn: 0.3421923\ttotal: 2m 51s\tremaining: 38.9s\n489:\tlearn: 0.3394820\ttotal: 2m 51s\tremaining: 38.5s\n490:\tlearn: 0.3390631\ttotal: 2m 51s\tremaining: 38.2s\n491:\tlearn: 0.3375105\ttotal: 2m 52s\tremaining: 37.8s\n492:\tlearn: 0.3373527\ttotal: 2m 52s\tremaining: 37.5s\n493:\tlearn: 0.3369690\ttotal: 2m 53s\tremaining: 37.1s\n494:\tlearn: 0.3368088\ttotal: 2m 53s\tremaining: 36.8s\n495:\tlearn: 0.3361574\ttotal: 2m 53s\tremaining: 36.4s\n496:\tlearn: 0.3358699\ttotal: 2m 54s\tremaining: 36.1s\n497:\tlearn: 0.3356988\ttotal: 2m 54s\tremaining: 35.7s\n498:\tlearn: 0.3354506\ttotal: 2m 54s\tremaining: 35.4s\n499:\tlearn: 0.3351893\ttotal: 2m 55s\tremaining: 35s\n500:\tlearn: 0.3350514\ttotal: 2m 55s\tremaining: 34.7s\n501:\tlearn: 0.3337914\ttotal: 2m 55s\tremaining: 34.3s\n502:\tlearn: 0.3336956\ttotal: 2m 56s\tremaining: 34s\n503:\tlearn: 0.3327313\ttotal: 2m 56s\tremaining: 33.6s\n504:\tlearn: 0.3322328\ttotal: 2m 56s\tremaining: 33.3s\n505:\tlearn: 0.3316578\ttotal: 2m 57s\tremaining: 32.9s\n506:\tlearn: 0.3314844\ttotal: 2m 57s\tremaining: 32.6s\n507:\tlearn: 0.3312703\ttotal: 2m 57s\tremaining: 32.2s\n508:\tlearn: 0.3295141\ttotal: 2m 58s\tremaining: 31.9s\n509:\tlearn: 0.3294291\ttotal: 2m 58s\tremaining: 31.5s\n510:\tlearn: 0.3293719\ttotal: 2m 58s\tremaining: 31.2s\n511:\tlearn: 0.3292404\ttotal: 2m 59s\tremaining: 30.8s\n512:\tlearn: 0.3286635\ttotal: 2m 59s\tremaining: 30.5s\n513:\tlearn: 0.3282246\ttotal: 2m 59s\tremaining: 30.1s\n514:\tlearn: 0.3281810\ttotal: 3m\tremaining: 29.8s\n515:\tlearn: 0.3270842\ttotal: 3m\tremaining: 29.4s\n516:\tlearn: 0.3270271\ttotal: 3m 1s\tremaining: 29.1s\n517:\tlearn: 0.3268153\ttotal: 3m 1s\tremaining: 28.7s\n518:\tlearn: 0.3256824\ttotal: 3m 1s\tremaining: 28.4s\n519:\tlearn: 0.3227904\ttotal: 3m 2s\tremaining: 28s\n520:\tlearn: 0.3224833\ttotal: 3m 2s\tremaining: 27.7s\n521:\tlearn: 0.3223377\ttotal: 3m 2s\tremaining: 27.3s\n522:\tlearn: 0.3217822\ttotal: 3m 3s\tremaining: 27s\n523:\tlearn: 0.3214496\ttotal: 3m 3s\tremaining: 26.6s\n524:\tlearn: 0.3195337\ttotal: 3m 3s\tremaining: 26.3s\n525:\tlearn: 0.3192182\ttotal: 3m 4s\tremaining: 25.9s\n526:\tlearn: 0.3190972\ttotal: 3m 4s\tremaining: 25.6s\n527:\tlearn: 0.3188419\ttotal: 3m 4s\tremaining: 25.2s\n528:\tlearn: 0.3176568\ttotal: 3m 5s\tremaining: 24.9s\n529:\tlearn: 0.3174431\ttotal: 3m 5s\tremaining: 24.5s\n530:\tlearn: 0.3172326\ttotal: 3m 5s\tremaining: 24.2s\n531:\tlearn: 0.3169288\ttotal: 3m 6s\tremaining: 23.8s\n532:\tlearn: 0.3148143\ttotal: 3m 6s\tremaining: 23.5s\n533:\tlearn: 0.3146863\ttotal: 3m 7s\tremaining: 23.1s\n534:\tlearn: 0.3128010\ttotal: 3m 7s\tremaining: 22.8s\n535:\tlearn: 0.3126689\ttotal: 3m 7s\tremaining: 22.4s\n536:\tlearn: 0.3126028\ttotal: 3m 8s\tremaining: 22.1s\n537:\tlearn: 0.3123648\ttotal: 3m 8s\tremaining: 21.7s\n538:\tlearn: 0.3113161\ttotal: 3m 8s\tremaining: 21.4s\n539:\tlearn: 0.3112551\ttotal: 3m 9s\tremaining: 21s\n540:\tlearn: 0.3111604\ttotal: 3m 9s\tremaining: 20.7s\n541:\tlearn: 0.3108786\ttotal: 3m 9s\tremaining: 20.3s\n542:\tlearn: 0.3107415\ttotal: 3m 10s\tremaining: 20s\n543:\tlearn: 0.3105197\ttotal: 3m 10s\tremaining: 19.6s\n544:\tlearn: 0.3103624\ttotal: 3m 10s\tremaining: 19.3s\n545:\tlearn: 0.3102505\ttotal: 3m 11s\tremaining: 18.9s\n546:\tlearn: 0.3098884\ttotal: 3m 11s\tremaining: 18.6s\n547:\tlearn: 0.3095275\ttotal: 3m 11s\tremaining: 18.2s\n548:\tlearn: 0.3094330\ttotal: 3m 12s\tremaining: 17.9s\n549:\tlearn: 0.3073313\ttotal: 3m 12s\tremaining: 17.5s\n550:\tlearn: 0.3065475\ttotal: 3m 13s\tremaining: 17.2s\n551:\tlearn: 0.3064811\ttotal: 3m 13s\tremaining: 16.8s\n552:\tlearn: 0.3063528\ttotal: 3m 13s\tremaining: 16.5s\n553:\tlearn: 0.3061707\ttotal: 3m 14s\tremaining: 16.1s\n554:\tlearn: 0.3061259\ttotal: 3m 14s\tremaining: 15.8s\n555:\tlearn: 0.3060837\ttotal: 3m 14s\tremaining: 15.4s\n556:\tlearn: 0.3041218\ttotal: 3m 15s\tremaining: 15.1s\n557:\tlearn: 0.3015004\ttotal: 3m 15s\tremaining: 14.7s\n558:\tlearn: 0.3007186\ttotal: 3m 15s\tremaining: 14.4s\n559:\tlearn: 0.2996174\ttotal: 3m 16s\tremaining: 14s\n560:\tlearn: 0.2995615\ttotal: 3m 16s\tremaining: 13.7s\n561:\tlearn: 0.2984033\ttotal: 3m 16s\tremaining: 13.3s\n562:\tlearn: 0.2981840\ttotal: 3m 17s\tremaining: 13s\n563:\tlearn: 0.2980553\ttotal: 3m 17s\tremaining: 12.6s\n564:\tlearn: 0.2979498\ttotal: 3m 17s\tremaining: 12.3s\n565:\tlearn: 0.2977157\ttotal: 3m 18s\tremaining: 11.9s\n566:\tlearn: 0.2976375\ttotal: 3m 18s\tremaining: 11.6s\n567:\tlearn: 0.2973683\ttotal: 3m 18s\tremaining: 11.2s\n568:\tlearn: 0.2972307\ttotal: 3m 19s\tremaining: 10.9s\n569:\tlearn: 0.2971675\ttotal: 3m 19s\tremaining: 10.5s\n570:\tlearn: 0.2970811\ttotal: 3m 20s\tremaining: 10.2s\n571:\tlearn: 0.2966913\ttotal: 3m 20s\tremaining: 9.81s\n572:\tlearn: 0.2953481\ttotal: 3m 20s\tremaining: 9.46s\n573:\tlearn: 0.2948937\ttotal: 3m 21s\tremaining: 9.11s\n574:\tlearn: 0.2948240\ttotal: 3m 21s\tremaining: 8.76s\n575:\tlearn: 0.2946315\ttotal: 3m 21s\tremaining: 8.41s\n576:\tlearn: 0.2943687\ttotal: 3m 22s\tremaining: 8.06s\n577:\tlearn: 0.2941631\ttotal: 3m 22s\tremaining: 7.71s\n578:\tlearn: 0.2922786\ttotal: 3m 22s\tremaining: 7.36s\n579:\tlearn: 0.2920882\ttotal: 3m 23s\tremaining: 7.01s\n580:\tlearn: 0.2919768\ttotal: 3m 23s\tremaining: 6.66s\n581:\tlearn: 0.2914673\ttotal: 3m 23s\tremaining: 6.31s\n582:\tlearn: 0.2912092\ttotal: 3m 24s\tremaining: 5.96s\n583:\tlearn: 0.2911762\ttotal: 3m 24s\tremaining: 5.61s\n584:\tlearn: 0.2910264\ttotal: 3m 24s\tremaining: 5.25s\n585:\tlearn: 0.2907956\ttotal: 3m 25s\tremaining: 4.9s\n586:\tlearn: 0.2906855\ttotal: 3m 25s\tremaining: 4.55s\n587:\tlearn: 0.2901841\ttotal: 3m 26s\tremaining: 4.2s\n588:\tlearn: 0.2896921\ttotal: 3m 26s\tremaining: 3.85s\n589:\tlearn: 0.2895584\ttotal: 3m 26s\tremaining: 3.5s\n590:\tlearn: 0.2894370\ttotal: 3m 27s\tremaining: 3.15s\n591:\tlearn: 0.2891025\ttotal: 3m 27s\tremaining: 2.8s\n592:\tlearn: 0.2890536\ttotal: 3m 27s\tremaining: 2.45s\n593:\tlearn: 0.2890297\ttotal: 3m 28s\tremaining: 2.1s\n594:\tlearn: 0.2889611\ttotal: 3m 28s\tremaining: 1.75s\n595:\tlearn: 0.2882191\ttotal: 3m 28s\tremaining: 1.4s\n596:\tlearn: 0.2878065\ttotal: 3m 29s\tremaining: 1.05s\n597:\tlearn: 0.2861448\ttotal: 3m 29s\tremaining: 701ms\n598:\tlearn: 0.2852812\ttotal: 3m 29s\tremaining: 350ms\n599:\tlearn: 0.2851763\ttotal: 3m 30s\tremaining: 0us\ncat_fit_done\nmodel_ready\n0:\tlearn: 2.4898956\ttotal: 345ms\tremaining: 3m 26s\n1:\tlearn: 2.4248101\ttotal: 692ms\tremaining: 3m 26s\n2:\tlearn: 2.3697827\ttotal: 1.04s\tremaining: 3m 27s\n3:\tlearn: 2.3324217\ttotal: 1.39s\tremaining: 3m 26s\n4:\tlearn: 2.2915477\ttotal: 1.73s\tremaining: 3m 25s\n5:\tlearn: 2.2494033\ttotal: 2.07s\tremaining: 3m 25s\n6:\tlearn: 2.2098299\ttotal: 2.41s\tremaining: 3m 24s\n7:\tlearn: 2.1940779\ttotal: 2.75s\tremaining: 3m 23s\n8:\tlearn: 2.1594100\ttotal: 3.1s\tremaining: 3m 23s\n9:\tlearn: 2.1159006\ttotal: 3.46s\tremaining: 3m 23s\n10:\tlearn: 2.0943510\ttotal: 3.79s\tremaining: 3m 23s\n11:\tlearn: 2.0659096\ttotal: 4.13s\tremaining: 3m 22s\n12:\tlearn: 2.0448256\ttotal: 4.47s\tremaining: 3m 21s\n13:\tlearn: 2.0127513\ttotal: 4.81s\tremaining: 3m 21s\n14:\tlearn: 1.9826691\ttotal: 5.16s\tremaining: 3m 21s\n15:\tlearn: 1.9536199\ttotal: 5.5s\tremaining: 3m 20s\n16:\tlearn: 1.9320474\ttotal: 5.84s\tremaining: 3m 20s\n17:\tlearn: 1.9107828\ttotal: 6.18s\tremaining: 3m 19s\n18:\tlearn: 1.8910256\ttotal: 6.51s\tremaining: 3m 19s\n19:\tlearn: 1.8812532\ttotal: 6.85s\tremaining: 3m 18s\n20:\tlearn: 1.8416940\ttotal: 7.21s\tremaining: 3m 18s\n21:\tlearn: 1.8213770\ttotal: 7.55s\tremaining: 3m 18s\n22:\tlearn: 1.7991383\ttotal: 7.89s\tremaining: 3m 18s\n23:\tlearn: 1.7686168\ttotal: 8.24s\tremaining: 3m 17s\n24:\tlearn: 1.7473177\ttotal: 8.58s\tremaining: 3m 17s\n25:\tlearn: 1.7338525\ttotal: 8.77s\tremaining: 3m 13s\n26:\tlearn: 1.7173426\ttotal: 9.11s\tremaining: 3m 13s\n27:\tlearn: 1.7039817\ttotal: 9.44s\tremaining: 3m 12s\n28:\tlearn: 1.6937864\ttotal: 9.78s\tremaining: 3m 12s\n29:\tlearn: 1.6779202\ttotal: 10.1s\tremaining: 3m 12s\n30:\tlearn: 1.6690662\ttotal: 10.5s\tremaining: 3m 11s\n31:\tlearn: 1.6472292\ttotal: 10.8s\tremaining: 3m 11s\n32:\tlearn: 1.6246039\ttotal: 11.1s\tremaining: 3m 11s\n33:\tlearn: 1.6105538\ttotal: 11.5s\tremaining: 3m 11s\n34:\tlearn: 1.5938000\ttotal: 11.8s\tremaining: 3m 10s\n35:\tlearn: 1.5808379\ttotal: 12.2s\tremaining: 3m 10s\n36:\tlearn: 1.5691164\ttotal: 12.5s\tremaining: 3m 10s\n37:\tlearn: 1.5505261\ttotal: 12.8s\tremaining: 3m 10s\n38:\tlearn: 1.5367043\ttotal: 13.2s\tremaining: 3m 9s\n39:\tlearn: 1.5222945\ttotal: 13.5s\tremaining: 3m 9s\n40:\tlearn: 1.5083082\ttotal: 13.9s\tremaining: 3m 9s\n41:\tlearn: 1.4928805\ttotal: 14.2s\tremaining: 3m 8s\n42:\tlearn: 1.4740920\ttotal: 14.6s\tremaining: 3m 8s\n43:\tlearn: 1.4530938\ttotal: 14.9s\tremaining: 3m 8s\n44:\tlearn: 1.4426520\ttotal: 15.3s\tremaining: 3m 8s\n45:\tlearn: 1.4341186\ttotal: 15.6s\tremaining: 3m 7s\n46:\tlearn: 1.4198466\ttotal: 15.9s\tremaining: 3m 7s\n47:\tlearn: 1.4054983\ttotal: 16.3s\tremaining: 3m 7s\n48:\tlearn: 1.3931915\ttotal: 16.6s\tremaining: 3m 7s\n49:\tlearn: 1.3850152\ttotal: 17s\tremaining: 3m 6s\n50:\tlearn: 1.3704956\ttotal: 17.3s\tremaining: 3m 6s\n51:\tlearn: 1.3635181\ttotal: 17.7s\tremaining: 3m 6s\n52:\tlearn: 1.3548797\ttotal: 18s\tremaining: 3m 5s\n53:\tlearn: 1.3478623\ttotal: 18.3s\tremaining: 3m 5s\n54:\tlearn: 1.3437635\ttotal: 18.7s\tremaining: 3m 5s\n55:\tlearn: 1.3344861\ttotal: 19s\tremaining: 3m 4s\n56:\tlearn: 1.3298389\ttotal: 19.4s\tremaining: 3m 4s\n57:\tlearn: 1.3203105\ttotal: 19.7s\tremaining: 3m 4s\n58:\tlearn: 1.3098799\ttotal: 20.1s\tremaining: 3m 3s\n59:\tlearn: 1.2837263\ttotal: 20.4s\tremaining: 3m 3s\n60:\tlearn: 1.2768738\ttotal: 20.8s\tremaining: 3m 3s\n61:\tlearn: 1.2681653\ttotal: 21.1s\tremaining: 3m 3s\n62:\tlearn: 1.2609249\ttotal: 21.5s\tremaining: 3m 2s\n63:\tlearn: 1.2494724\ttotal: 21.8s\tremaining: 3m 2s\n64:\tlearn: 1.2394433\ttotal: 22.2s\tremaining: 3m 2s\n65:\tlearn: 1.2357131\ttotal: 22.5s\tremaining: 3m 1s\n66:\tlearn: 1.2239683\ttotal: 22.8s\tremaining: 3m 1s\n67:\tlearn: 1.2193232\ttotal: 23.2s\tremaining: 3m 1s\n68:\tlearn: 1.2034175\ttotal: 23.5s\tremaining: 3m 1s\n69:\tlearn: 1.1995411\ttotal: 23.9s\tremaining: 3m\n70:\tlearn: 1.1879625\ttotal: 24.2s\tremaining: 3m\n71:\tlearn: 1.1761670\ttotal: 24.6s\tremaining: 3m\n72:\tlearn: 1.1645141\ttotal: 24.9s\tremaining: 2m 59s\n73:\tlearn: 1.1567170\ttotal: 25.2s\tremaining: 2m 59s\n74:\tlearn: 1.1499033\ttotal: 25.6s\tremaining: 2m 59s\n75:\tlearn: 1.1456846\ttotal: 25.9s\tremaining: 2m 58s\n76:\tlearn: 1.1375572\ttotal: 26.3s\tremaining: 2m 58s\n77:\tlearn: 1.1338408\ttotal: 26.6s\tremaining: 2m 57s\n78:\tlearn: 1.1242022\ttotal: 26.9s\tremaining: 2m 57s\n79:\tlearn: 1.1160145\ttotal: 27.3s\tremaining: 2m 57s\n80:\tlearn: 1.1111195\ttotal: 27.6s\tremaining: 2m 57s\n81:\tlearn: 1.1027938\ttotal: 28s\tremaining: 2m 56s\n82:\tlearn: 1.0958394\ttotal: 28.3s\tremaining: 2m 56s\n83:\tlearn: 1.0906750\ttotal: 28.7s\tremaining: 2m 56s\n84:\tlearn: 1.0778088\ttotal: 29s\tremaining: 2m 55s\n85:\tlearn: 1.0654016\ttotal: 29.4s\tremaining: 2m 55s\n86:\tlearn: 1.0524608\ttotal: 29.7s\tremaining: 2m 55s\n87:\tlearn: 1.0362347\ttotal: 30.1s\tremaining: 2m 55s\n88:\tlearn: 1.0227557\ttotal: 30.5s\tremaining: 2m 54s\n89:\tlearn: 1.0120147\ttotal: 30.8s\tremaining: 2m 54s\n90:\tlearn: 1.0105490\ttotal: 31.1s\tremaining: 2m 54s\n91:\tlearn: 0.9980017\ttotal: 31.5s\tremaining: 2m 53s\n92:\tlearn: 0.9921849\ttotal: 31.8s\tremaining: 2m 53s\n93:\tlearn: 0.9828354\ttotal: 32.2s\tremaining: 2m 53s\n94:\tlearn: 0.9722768\ttotal: 32.5s\tremaining: 2m 53s\n95:\tlearn: 0.9649212\ttotal: 32.9s\tremaining: 2m 52s\n96:\tlearn: 0.9578208\ttotal: 33.2s\tremaining: 2m 52s\n97:\tlearn: 0.9518957\ttotal: 33.6s\tremaining: 2m 52s\n98:\tlearn: 0.9452409\ttotal: 33.9s\tremaining: 2m 51s\n99:\tlearn: 0.9354839\ttotal: 34.3s\tremaining: 2m 51s\n100:\tlearn: 0.9275396\ttotal: 34.6s\tremaining: 2m 51s\n101:\tlearn: 0.9234305\ttotal: 35s\tremaining: 2m 50s\n102:\tlearn: 0.9153054\ttotal: 35.3s\tremaining: 2m 50s\n103:\tlearn: 0.9070743\ttotal: 35.7s\tremaining: 2m 50s\n104:\tlearn: 0.9002704\ttotal: 36s\tremaining: 2m 49s\n105:\tlearn: 0.8910619\ttotal: 36.4s\tremaining: 2m 49s\n106:\tlearn: 0.8810078\ttotal: 36.7s\tremaining: 2m 49s\n107:\tlearn: 0.8745445\ttotal: 37.1s\tremaining: 2m 48s\n108:\tlearn: 0.8650590\ttotal: 37.4s\tremaining: 2m 48s\n109:\tlearn: 0.8533738\ttotal: 37.8s\tremaining: 2m 48s\n110:\tlearn: 0.8397085\ttotal: 38.1s\tremaining: 2m 47s\n111:\tlearn: 0.8331777\ttotal: 38.5s\tremaining: 2m 47s\n112:\tlearn: 0.8232144\ttotal: 38.8s\tremaining: 2m 47s\n113:\tlearn: 0.8201389\ttotal: 39.2s\tremaining: 2m 46s\n114:\tlearn: 0.8123507\ttotal: 39.5s\tremaining: 2m 46s\n115:\tlearn: 0.8071622\ttotal: 39.9s\tremaining: 2m 46s\n116:\tlearn: 0.8018629\ttotal: 40.2s\tremaining: 2m 45s\n117:\tlearn: 0.8003149\ttotal: 40.5s\tremaining: 2m 45s\n118:\tlearn: 0.7983391\ttotal: 40.9s\tremaining: 2m 45s\n119:\tlearn: 0.7972270\ttotal: 41.2s\tremaining: 2m 44s\n120:\tlearn: 0.7868850\ttotal: 41.6s\tremaining: 2m 44s\n121:\tlearn: 0.7837123\ttotal: 41.9s\tremaining: 2m 44s\n122:\tlearn: 0.7768811\ttotal: 42.3s\tremaining: 2m 43s\n123:\tlearn: 0.7704187\ttotal: 42.6s\tremaining: 2m 43s\n124:\tlearn: 0.7595056\ttotal: 43s\tremaining: 2m 43s\n125:\tlearn: 0.7528011\ttotal: 43.3s\tremaining: 2m 43s\n126:\tlearn: 0.7442164\ttotal: 43.7s\tremaining: 2m 42s\n127:\tlearn: 0.7389422\ttotal: 44s\tremaining: 2m 42s\n128:\tlearn: 0.7355324\ttotal: 44.4s\tremaining: 2m 42s\n129:\tlearn: 0.7329765\ttotal: 44.7s\tremaining: 2m 41s\n130:\tlearn: 0.7318174\ttotal: 45.1s\tremaining: 2m 41s\n131:\tlearn: 0.7280960\ttotal: 45.4s\tremaining: 2m 40s\n132:\tlearn: 0.7214649\ttotal: 45.8s\tremaining: 2m 40s\n133:\tlearn: 0.7161496\ttotal: 46.1s\tremaining: 2m 40s\n134:\tlearn: 0.7146540\ttotal: 46.5s\tremaining: 2m 40s\n135:\tlearn: 0.7122152\ttotal: 46.8s\tremaining: 2m 39s\n136:\tlearn: 0.7112582\ttotal: 47.1s\tremaining: 2m 39s\n137:\tlearn: 0.7064523\ttotal: 47.5s\tremaining: 2m 38s\n138:\tlearn: 0.6999461\ttotal: 47.8s\tremaining: 2m 38s\n139:\tlearn: 0.6930052\ttotal: 48.2s\tremaining: 2m 38s\n140:\tlearn: 0.6910832\ttotal: 48.5s\tremaining: 2m 37s\n141:\tlearn: 0.6857624\ttotal: 48.9s\tremaining: 2m 37s\n142:\tlearn: 0.6843880\ttotal: 49.2s\tremaining: 2m 37s\n143:\tlearn: 0.6746965\ttotal: 49.6s\tremaining: 2m 37s\n144:\tlearn: 0.6659335\ttotal: 49.9s\tremaining: 2m 36s\n145:\tlearn: 0.6589687\ttotal: 50.3s\tremaining: 2m 36s\n146:\tlearn: 0.6573361\ttotal: 50.6s\tremaining: 2m 36s\n147:\tlearn: 0.6495948\ttotal: 51s\tremaining: 2m 35s\n148:\tlearn: 0.6399968\ttotal: 51.4s\tremaining: 2m 35s\n149:\tlearn: 0.6355078\ttotal: 51.8s\tremaining: 2m 35s\n150:\tlearn: 0.6300465\ttotal: 52.1s\tremaining: 2m 34s\n151:\tlearn: 0.6283965\ttotal: 52.4s\tremaining: 2m 34s\n152:\tlearn: 0.6245648\ttotal: 52.8s\tremaining: 2m 34s\n153:\tlearn: 0.6175284\ttotal: 53.2s\tremaining: 2m 33s\n154:\tlearn: 0.6138549\ttotal: 53.5s\tremaining: 2m 33s\n155:\tlearn: 0.6134004\ttotal: 53.8s\tremaining: 2m 33s\n156:\tlearn: 0.6066385\ttotal: 54.2s\tremaining: 2m 32s\n157:\tlearn: 0.6033143\ttotal: 54.5s\tremaining: 2m 32s\n158:\tlearn: 0.5980472\ttotal: 54.9s\tremaining: 2m 32s\n159:\tlearn: 0.5939257\ttotal: 55.3s\tremaining: 2m 31s\n160:\tlearn: 0.5932189\ttotal: 55.6s\tremaining: 2m 31s\n161:\tlearn: 0.5884831\ttotal: 55.9s\tremaining: 2m 31s\n162:\tlearn: 0.5863034\ttotal: 56.3s\tremaining: 2m 30s\n163:\tlearn: 0.5841265\ttotal: 56.6s\tremaining: 2m 30s\n164:\tlearn: 0.5834319\ttotal: 57s\tremaining: 2m 30s\n165:\tlearn: 0.5795627\ttotal: 57.3s\tremaining: 2m 29s\n166:\tlearn: 0.5792399\ttotal: 57.7s\tremaining: 2m 29s\n167:\tlearn: 0.5741228\ttotal: 58s\tremaining: 2m 29s\n168:\tlearn: 0.5708064\ttotal: 58.4s\tremaining: 2m 28s\n169:\tlearn: 0.5683756\ttotal: 58.7s\tremaining: 2m 28s\n170:\tlearn: 0.5640308\ttotal: 59.1s\tremaining: 2m 28s\n171:\tlearn: 0.5633981\ttotal: 59.4s\tremaining: 2m 27s\n172:\tlearn: 0.5624914\ttotal: 59.7s\tremaining: 2m 27s\n173:\tlearn: 0.5618206\ttotal: 1m\tremaining: 2m 27s\n174:\tlearn: 0.5569933\ttotal: 1m\tremaining: 2m 26s\n175:\tlearn: 0.5563963\ttotal: 1m\tremaining: 2m 26s\n176:\tlearn: 0.5559152\ttotal: 1m 1s\tremaining: 2m 26s\n177:\tlearn: 0.5536830\ttotal: 1m 1s\tremaining: 2m 25s\n178:\tlearn: 0.5517975\ttotal: 1m 1s\tremaining: 2m 25s\n179:\tlearn: 0.5490034\ttotal: 1m 2s\tremaining: 2m 24s\n180:\tlearn: 0.5486652\ttotal: 1m 2s\tremaining: 2m 24s\n181:\tlearn: 0.5481797\ttotal: 1m 2s\tremaining: 2m 24s\n182:\tlearn: 0.5467596\ttotal: 1m 3s\tremaining: 2m 23s\n183:\tlearn: 0.5462415\ttotal: 1m 3s\tremaining: 2m 23s\n184:\tlearn: 0.5450457\ttotal: 1m 3s\tremaining: 2m 23s\n185:\tlearn: 0.5430716\ttotal: 1m 4s\tremaining: 2m 22s\n186:\tlearn: 0.5424713\ttotal: 1m 4s\tremaining: 2m 22s\n187:\tlearn: 0.5410823\ttotal: 1m 4s\tremaining: 2m 22s\n188:\tlearn: 0.5387813\ttotal: 1m 5s\tremaining: 2m 21s\n189:\tlearn: 0.5367007\ttotal: 1m 5s\tremaining: 2m 21s\n190:\tlearn: 0.5357390\ttotal: 1m 5s\tremaining: 2m 21s\n191:\tlearn: 0.5343485\ttotal: 1m 6s\tremaining: 2m 20s\n192:\tlearn: 0.5323368\ttotal: 1m 6s\tremaining: 2m 20s\n193:\tlearn: 0.5306411\ttotal: 1m 6s\tremaining: 2m 20s\n194:\tlearn: 0.5301295\ttotal: 1m 7s\tremaining: 2m 19s\n195:\tlearn: 0.5296286\ttotal: 1m 7s\tremaining: 2m 19s\n196:\tlearn: 0.5257831\ttotal: 1m 7s\tremaining: 2m 18s\n197:\tlearn: 0.5206036\ttotal: 1m 8s\tremaining: 2m 18s\n198:\tlearn: 0.5173999\ttotal: 1m 8s\tremaining: 2m 18s\n199:\tlearn: 0.5166908\ttotal: 1m 8s\tremaining: 2m 17s\n200:\tlearn: 0.5139169\ttotal: 1m 9s\tremaining: 2m 17s\n201:\tlearn: 0.5127985\ttotal: 1m 9s\tremaining: 2m 17s\n202:\tlearn: 0.5119116\ttotal: 1m 10s\tremaining: 2m 16s\n203:\tlearn: 0.5109226\ttotal: 1m 10s\tremaining: 2m 16s\n204:\tlearn: 0.5088411\ttotal: 1m 10s\tremaining: 2m 16s\n205:\tlearn: 0.5068773\ttotal: 1m 11s\tremaining: 2m 15s\n206:\tlearn: 0.5034338\ttotal: 1m 11s\tremaining: 2m 15s\n207:\tlearn: 0.5016897\ttotal: 1m 11s\tremaining: 2m 15s\n208:\tlearn: 0.4987859\ttotal: 1m 12s\tremaining: 2m 14s\n209:\tlearn: 0.4985166\ttotal: 1m 12s\tremaining: 2m 14s\n210:\tlearn: 0.4978915\ttotal: 1m 12s\tremaining: 2m 14s\n211:\tlearn: 0.4962845\ttotal: 1m 13s\tremaining: 2m 13s\n212:\tlearn: 0.4948365\ttotal: 1m 13s\tremaining: 2m 13s\n213:\tlearn: 0.4935467\ttotal: 1m 13s\tremaining: 2m 13s\n214:\tlearn: 0.4886057\ttotal: 1m 14s\tremaining: 2m 12s\n215:\tlearn: 0.4881285\ttotal: 1m 14s\tremaining: 2m 12s\n216:\tlearn: 0.4871199\ttotal: 1m 14s\tremaining: 2m 12s\n217:\tlearn: 0.4861458\ttotal: 1m 15s\tremaining: 2m 11s\n218:\tlearn: 0.4852931\ttotal: 1m 15s\tremaining: 2m 11s\n219:\tlearn: 0.4843714\ttotal: 1m 15s\tremaining: 2m 10s\n220:\tlearn: 0.4823567\ttotal: 1m 16s\tremaining: 2m 10s\n221:\tlearn: 0.4816072\ttotal: 1m 16s\tremaining: 2m 10s\n222:\tlearn: 0.4807533\ttotal: 1m 16s\tremaining: 2m 9s\n223:\tlearn: 0.4783517\ttotal: 1m 17s\tremaining: 2m 9s\n224:\tlearn: 0.4740502\ttotal: 1m 17s\tremaining: 2m 9s\n225:\tlearn: 0.4729398\ttotal: 1m 17s\tremaining: 2m 8s\n226:\tlearn: 0.4720636\ttotal: 1m 18s\tremaining: 2m 8s\n227:\tlearn: 0.4701092\ttotal: 1m 18s\tremaining: 2m 8s\n228:\tlearn: 0.4693453\ttotal: 1m 18s\tremaining: 2m 7s\n229:\tlearn: 0.4688734\ttotal: 1m 19s\tremaining: 2m 7s\n230:\tlearn: 0.4672013\ttotal: 1m 19s\tremaining: 2m 7s\n231:\tlearn: 0.4644981\ttotal: 1m 19s\tremaining: 2m 6s\n232:\tlearn: 0.4633706\ttotal: 1m 20s\tremaining: 2m 6s\n233:\tlearn: 0.4629647\ttotal: 1m 20s\tremaining: 2m 6s\n234:\tlearn: 0.4622957\ttotal: 1m 20s\tremaining: 2m 5s\n235:\tlearn: 0.4618715\ttotal: 1m 21s\tremaining: 2m 5s\n236:\tlearn: 0.4615367\ttotal: 1m 21s\tremaining: 2m 5s\n237:\tlearn: 0.4610521\ttotal: 1m 21s\tremaining: 2m 4s\n238:\tlearn: 0.4588471\ttotal: 1m 22s\tremaining: 2m 4s\n239:\tlearn: 0.4566403\ttotal: 1m 22s\tremaining: 2m 4s\n240:\tlearn: 0.4555279\ttotal: 1m 23s\tremaining: 2m 3s\n241:\tlearn: 0.4530756\ttotal: 1m 23s\tremaining: 2m 3s\n242:\tlearn: 0.4508230\ttotal: 1m 23s\tremaining: 2m 3s\n243:\tlearn: 0.4480991\ttotal: 1m 24s\tremaining: 2m 2s\n244:\tlearn: 0.4441441\ttotal: 1m 24s\tremaining: 2m 2s\n245:\tlearn: 0.4431955\ttotal: 1m 24s\tremaining: 2m 2s\n246:\tlearn: 0.4388945\ttotal: 1m 25s\tremaining: 2m 1s\n247:\tlearn: 0.4366897\ttotal: 1m 25s\tremaining: 2m 1s\n248:\tlearn: 0.4356167\ttotal: 1m 25s\tremaining: 2m 1s\n249:\tlearn: 0.4350142\ttotal: 1m 26s\tremaining: 2m\n250:\tlearn: 0.4336866\ttotal: 1m 26s\tremaining: 2m\n251:\tlearn: 0.4329079\ttotal: 1m 26s\tremaining: 2m\n252:\tlearn: 0.4293312\ttotal: 1m 27s\tremaining: 1m 59s\n253:\tlearn: 0.4278208\ttotal: 1m 27s\tremaining: 1m 59s\n254:\tlearn: 0.4268300\ttotal: 1m 27s\tremaining: 1m 59s\n255:\tlearn: 0.4260654\ttotal: 1m 28s\tremaining: 1m 58s\n256:\tlearn: 0.4257202\ttotal: 1m 28s\tremaining: 1m 58s\n257:\tlearn: 0.4244969\ttotal: 1m 28s\tremaining: 1m 57s\n258:\tlearn: 0.4210163\ttotal: 1m 29s\tremaining: 1m 57s\n259:\tlearn: 0.4199328\ttotal: 1m 29s\tremaining: 1m 57s\n260:\tlearn: 0.4189750\ttotal: 1m 30s\tremaining: 1m 56s\n261:\tlearn: 0.4153051\ttotal: 1m 30s\tremaining: 1m 56s\n262:\tlearn: 0.4148185\ttotal: 1m 30s\tremaining: 1m 56s\n263:\tlearn: 0.4119514\ttotal: 1m 31s\tremaining: 1m 55s\n264:\tlearn: 0.4115433\ttotal: 1m 31s\tremaining: 1m 55s\n265:\tlearn: 0.4092116\ttotal: 1m 31s\tremaining: 1m 55s\n266:\tlearn: 0.4090078\ttotal: 1m 32s\tremaining: 1m 54s\n267:\tlearn: 0.4079837\ttotal: 1m 32s\tremaining: 1m 54s\n268:\tlearn: 0.4058341\ttotal: 1m 32s\tremaining: 1m 54s\n269:\tlearn: 0.4019252\ttotal: 1m 33s\tremaining: 1m 53s\n270:\tlearn: 0.3998419\ttotal: 1m 33s\tremaining: 1m 53s\n271:\tlearn: 0.3976431\ttotal: 1m 33s\tremaining: 1m 53s\n272:\tlearn: 0.3962865\ttotal: 1m 34s\tremaining: 1m 52s\n273:\tlearn: 0.3960474\ttotal: 1m 34s\tremaining: 1m 52s\n274:\tlearn: 0.3957837\ttotal: 1m 34s\tremaining: 1m 52s\n275:\tlearn: 0.3952435\ttotal: 1m 35s\tremaining: 1m 51s\n276:\tlearn: 0.3932644\ttotal: 1m 35s\tremaining: 1m 51s\n277:\tlearn: 0.3919072\ttotal: 1m 35s\tremaining: 1m 51s\n278:\tlearn: 0.3915754\ttotal: 1m 36s\tremaining: 1m 50s\n279:\tlearn: 0.3909129\ttotal: 1m 36s\tremaining: 1m 50s\n280:\tlearn: 0.3901618\ttotal: 1m 36s\tremaining: 1m 50s\n281:\tlearn: 0.3898555\ttotal: 1m 37s\tremaining: 1m 49s\n282:\tlearn: 0.3863895\ttotal: 1m 37s\tremaining: 1m 49s\n283:\tlearn: 0.3855222\ttotal: 1m 38s\tremaining: 1m 49s\n284:\tlearn: 0.3846446\ttotal: 1m 38s\tremaining: 1m 48s\n285:\tlearn: 0.3837844\ttotal: 1m 38s\tremaining: 1m 48s\n286:\tlearn: 0.3831155\ttotal: 1m 39s\tremaining: 1m 48s\n287:\tlearn: 0.3826947\ttotal: 1m 39s\tremaining: 1m 47s\n288:\tlearn: 0.3798118\ttotal: 1m 39s\tremaining: 1m 47s\n289:\tlearn: 0.3784609\ttotal: 1m 40s\tremaining: 1m 46s\n290:\tlearn: 0.3782291\ttotal: 1m 40s\tremaining: 1m 46s\n291:\tlearn: 0.3776568\ttotal: 1m 40s\tremaining: 1m 46s\n292:\tlearn: 0.3767533\ttotal: 1m 41s\tremaining: 1m 45s\n293:\tlearn: 0.3758340\ttotal: 1m 41s\tremaining: 1m 45s\n294:\tlearn: 0.3750905\ttotal: 1m 41s\tremaining: 1m 45s\n295:\tlearn: 0.3738547\ttotal: 1m 42s\tremaining: 1m 44s\n296:\tlearn: 0.3732979\ttotal: 1m 42s\tremaining: 1m 44s\n297:\tlearn: 0.3728655\ttotal: 1m 42s\tremaining: 1m 44s\n298:\tlearn: 0.3726884\ttotal: 1m 43s\tremaining: 1m 43s\n299:\tlearn: 0.3718702\ttotal: 1m 43s\tremaining: 1m 43s\n300:\tlearn: 0.3716451\ttotal: 1m 43s\tremaining: 1m 43s\n301:\tlearn: 0.3712183\ttotal: 1m 44s\tremaining: 1m 42s\n302:\tlearn: 0.3707584\ttotal: 1m 44s\tremaining: 1m 42s\n303:\tlearn: 0.3702682\ttotal: 1m 44s\tremaining: 1m 42s\n304:\tlearn: 0.3694952\ttotal: 1m 45s\tremaining: 1m 41s\n305:\tlearn: 0.3678953\ttotal: 1m 45s\tremaining: 1m 41s\n306:\tlearn: 0.3670751\ttotal: 1m 45s\tremaining: 1m 41s\n307:\tlearn: 0.3666636\ttotal: 1m 46s\tremaining: 1m 40s\n308:\tlearn: 0.3646649\ttotal: 1m 46s\tremaining: 1m 40s\n309:\tlearn: 0.3635596\ttotal: 1m 46s\tremaining: 1m 40s\n310:\tlearn: 0.3630814\ttotal: 1m 47s\tremaining: 1m 39s\n311:\tlearn: 0.3626581\ttotal: 1m 47s\tremaining: 1m 39s\n312:\tlearn: 0.3623901\ttotal: 1m 47s\tremaining: 1m 39s\n313:\tlearn: 0.3617508\ttotal: 1m 48s\tremaining: 1m 38s\n314:\tlearn: 0.3605286\ttotal: 1m 48s\tremaining: 1m 38s\n315:\tlearn: 0.3593392\ttotal: 1m 48s\tremaining: 1m 37s\n316:\tlearn: 0.3592228\ttotal: 1m 49s\tremaining: 1m 37s\n317:\tlearn: 0.3580874\ttotal: 1m 49s\tremaining: 1m 37s\n318:\tlearn: 0.3578209\ttotal: 1m 50s\tremaining: 1m 36s\n319:\tlearn: 0.3574014\ttotal: 1m 50s\tremaining: 1m 36s\n320:\tlearn: 0.3569856\ttotal: 1m 50s\tremaining: 1m 36s\n321:\tlearn: 0.3556008\ttotal: 1m 51s\tremaining: 1m 35s\n322:\tlearn: 0.3534369\ttotal: 1m 51s\tremaining: 1m 35s\n323:\tlearn: 0.3530257\ttotal: 1m 51s\tremaining: 1m 35s\n324:\tlearn: 0.3521528\ttotal: 1m 52s\tremaining: 1m 34s\n325:\tlearn: 0.3509847\ttotal: 1m 52s\tremaining: 1m 34s\n326:\tlearn: 0.3494743\ttotal: 1m 52s\tremaining: 1m 34s\n327:\tlearn: 0.3489555\ttotal: 1m 53s\tremaining: 1m 33s\n328:\tlearn: 0.3482255\ttotal: 1m 53s\tremaining: 1m 33s\n329:\tlearn: 0.3480890\ttotal: 1m 53s\tremaining: 1m 33s\n330:\tlearn: 0.3478728\ttotal: 1m 54s\tremaining: 1m 32s\n331:\tlearn: 0.3476227\ttotal: 1m 54s\tremaining: 1m 32s\n332:\tlearn: 0.3475174\ttotal: 1m 54s\tremaining: 1m 32s\n333:\tlearn: 0.3468289\ttotal: 1m 55s\tremaining: 1m 31s\n334:\tlearn: 0.3465087\ttotal: 1m 55s\tremaining: 1m 31s\n335:\tlearn: 0.3461886\ttotal: 1m 55s\tremaining: 1m 31s\n336:\tlearn: 0.3456264\ttotal: 1m 56s\tremaining: 1m 30s\n337:\tlearn: 0.3452243\ttotal: 1m 56s\tremaining: 1m 30s\n338:\tlearn: 0.3448653\ttotal: 1m 56s\tremaining: 1m 29s\n339:\tlearn: 0.3444576\ttotal: 1m 57s\tremaining: 1m 29s\n340:\tlearn: 0.3441699\ttotal: 1m 57s\tremaining: 1m 29s\n341:\tlearn: 0.3437061\ttotal: 1m 57s\tremaining: 1m 28s\n342:\tlearn: 0.3431976\ttotal: 1m 58s\tremaining: 1m 28s\n343:\tlearn: 0.3428632\ttotal: 1m 58s\tremaining: 1m 28s\n344:\tlearn: 0.3425453\ttotal: 1m 58s\tremaining: 1m 27s\n345:\tlearn: 0.3416504\ttotal: 1m 59s\tremaining: 1m 27s\n346:\tlearn: 0.3401673\ttotal: 1m 59s\tremaining: 1m 27s\n347:\tlearn: 0.3395160\ttotal: 1m 59s\tremaining: 1m 26s\n348:\tlearn: 0.3385912\ttotal: 2m\tremaining: 1m 26s\n349:\tlearn: 0.3384304\ttotal: 2m\tremaining: 1m 26s\n350:\tlearn: 0.3372704\ttotal: 2m 1s\tremaining: 1m 25s\n351:\tlearn: 0.3366480\ttotal: 2m 1s\tremaining: 1m 25s\n352:\tlearn: 0.3363101\ttotal: 2m 1s\tremaining: 1m 25s\n353:\tlearn: 0.3340606\ttotal: 2m 2s\tremaining: 1m 24s\n354:\tlearn: 0.3334547\ttotal: 2m 2s\tremaining: 1m 24s\n355:\tlearn: 0.3332505\ttotal: 2m 2s\tremaining: 1m 24s\n356:\tlearn: 0.3322968\ttotal: 2m 3s\tremaining: 1m 23s\n357:\tlearn: 0.3320314\ttotal: 2m 3s\tremaining: 1m 23s\n358:\tlearn: 0.3311469\ttotal: 2m 3s\tremaining: 1m 23s\n359:\tlearn: 0.3306600\ttotal: 2m 4s\tremaining: 1m 22s\n360:\tlearn: 0.3303355\ttotal: 2m 4s\tremaining: 1m 22s\n361:\tlearn: 0.3298833\ttotal: 2m 4s\tremaining: 1m 22s\n362:\tlearn: 0.3286243\ttotal: 2m 5s\tremaining: 1m 21s\n363:\tlearn: 0.3279974\ttotal: 2m 5s\tremaining: 1m 21s\n364:\tlearn: 0.3277520\ttotal: 2m 5s\tremaining: 1m 21s\n365:\tlearn: 0.3269596\ttotal: 2m 6s\tremaining: 1m 20s\n366:\tlearn: 0.3266910\ttotal: 2m 6s\tremaining: 1m 20s\n367:\tlearn: 0.3265224\ttotal: 2m 6s\tremaining: 1m 19s\n368:\tlearn: 0.3263535\ttotal: 2m 7s\tremaining: 1m 19s\n369:\tlearn: 0.3254143\ttotal: 2m 7s\tremaining: 1m 19s\n370:\tlearn: 0.3247483\ttotal: 2m 7s\tremaining: 1m 18s\n371:\tlearn: 0.3246338\ttotal: 2m 8s\tremaining: 1m 18s\n372:\tlearn: 0.3243807\ttotal: 2m 8s\tremaining: 1m 18s\n373:\tlearn: 0.3242364\ttotal: 2m 8s\tremaining: 1m 17s\n374:\tlearn: 0.3236354\ttotal: 2m 9s\tremaining: 1m 17s\n375:\tlearn: 0.3235763\ttotal: 2m 9s\tremaining: 1m 17s\n376:\tlearn: 0.3231385\ttotal: 2m 9s\tremaining: 1m 16s\n377:\tlearn: 0.3218013\ttotal: 2m 10s\tremaining: 1m 16s\n378:\tlearn: 0.3213130\ttotal: 2m 10s\tremaining: 1m 16s\n379:\tlearn: 0.3205214\ttotal: 2m 10s\tremaining: 1m 15s\n380:\tlearn: 0.3199316\ttotal: 2m 11s\tremaining: 1m 15s\n381:\tlearn: 0.3190392\ttotal: 2m 11s\tremaining: 1m 15s\n382:\tlearn: 0.3187363\ttotal: 2m 11s\tremaining: 1m 14s\n383:\tlearn: 0.3179056\ttotal: 2m 12s\tremaining: 1m 14s\n384:\tlearn: 0.3176438\ttotal: 2m 12s\tremaining: 1m 14s\n385:\tlearn: 0.3169951\ttotal: 2m 13s\tremaining: 1m 13s\n386:\tlearn: 0.3162447\ttotal: 2m 13s\tremaining: 1m 13s\n387:\tlearn: 0.3161016\ttotal: 2m 13s\tremaining: 1m 13s\n388:\tlearn: 0.3157059\ttotal: 2m 14s\tremaining: 1m 12s\n389:\tlearn: 0.3153081\ttotal: 2m 14s\tremaining: 1m 12s\n390:\tlearn: 0.3150417\ttotal: 2m 14s\tremaining: 1m 12s\n391:\tlearn: 0.3146503\ttotal: 2m 15s\tremaining: 1m 11s\n392:\tlearn: 0.3144998\ttotal: 2m 15s\tremaining: 1m 11s\n393:\tlearn: 0.3133478\ttotal: 2m 15s\tremaining: 1m 10s\n394:\tlearn: 0.3121759\ttotal: 2m 16s\tremaining: 1m 10s\n395:\tlearn: 0.3119446\ttotal: 2m 16s\tremaining: 1m 10s\n396:\tlearn: 0.3112324\ttotal: 2m 16s\tremaining: 1m 9s\n397:\tlearn: 0.3110400\ttotal: 2m 17s\tremaining: 1m 9s\n398:\tlearn: 0.3106787\ttotal: 2m 17s\tremaining: 1m 9s\n399:\tlearn: 0.3095935\ttotal: 2m 17s\tremaining: 1m 8s\n400:\tlearn: 0.3090096\ttotal: 2m 18s\tremaining: 1m 8s\n401:\tlearn: 0.3074904\ttotal: 2m 18s\tremaining: 1m 8s\n402:\tlearn: 0.3070448\ttotal: 2m 18s\tremaining: 1m 7s\n403:\tlearn: 0.3063857\ttotal: 2m 19s\tremaining: 1m 7s\n404:\tlearn: 0.3060191\ttotal: 2m 19s\tremaining: 1m 7s\n405:\tlearn: 0.3058667\ttotal: 2m 19s\tremaining: 1m 6s\n406:\tlearn: 0.3057028\ttotal: 2m 20s\tremaining: 1m 6s\n407:\tlearn: 0.3054022\ttotal: 2m 20s\tremaining: 1m 6s\n408:\tlearn: 0.3040318\ttotal: 2m 20s\tremaining: 1m 5s\n409:\tlearn: 0.3032665\ttotal: 2m 21s\tremaining: 1m 5s\n410:\tlearn: 0.3030954\ttotal: 2m 21s\tremaining: 1m 5s\n411:\tlearn: 0.3029440\ttotal: 2m 21s\tremaining: 1m 4s\n412:\tlearn: 0.3018189\ttotal: 2m 22s\tremaining: 1m 4s\n413:\tlearn: 0.3013566\ttotal: 2m 22s\tremaining: 1m 4s\n414:\tlearn: 0.3010661\ttotal: 2m 23s\tremaining: 1m 3s\n415:\tlearn: 0.3009679\ttotal: 2m 23s\tremaining: 1m 3s\n416:\tlearn: 0.3006516\ttotal: 2m 23s\tremaining: 1m 3s\n417:\tlearn: 0.2999726\ttotal: 2m 24s\tremaining: 1m 2s\n418:\tlearn: 0.2997584\ttotal: 2m 24s\tremaining: 1m 2s\n419:\tlearn: 0.2996278\ttotal: 2m 24s\tremaining: 1m 2s\n420:\tlearn: 0.2980070\ttotal: 2m 25s\tremaining: 1m 1s\n421:\tlearn: 0.2978149\ttotal: 2m 25s\tremaining: 1m 1s\n422:\tlearn: 0.2975054\ttotal: 2m 25s\tremaining: 1m\n423:\tlearn: 0.2973847\ttotal: 2m 26s\tremaining: 1m\n424:\tlearn: 0.2971026\ttotal: 2m 26s\tremaining: 1m\n425:\tlearn: 0.2970218\ttotal: 2m 26s\tremaining: 60s\n426:\tlearn: 0.2969123\ttotal: 2m 27s\tremaining: 59.6s\n427:\tlearn: 0.2968049\ttotal: 2m 27s\tremaining: 59.3s\n428:\tlearn: 0.2966107\ttotal: 2m 27s\tremaining: 58.9s\n429:\tlearn: 0.2964793\ttotal: 2m 28s\tremaining: 58.6s\n430:\tlearn: 0.2963494\ttotal: 2m 28s\tremaining: 58.2s\n431:\tlearn: 0.2960774\ttotal: 2m 28s\tremaining: 57.9s\n432:\tlearn: 0.2959448\ttotal: 2m 29s\tremaining: 57.5s\n433:\tlearn: 0.2956283\ttotal: 2m 29s\tremaining: 57.2s\n434:\tlearn: 0.2951994\ttotal: 2m 29s\tremaining: 56.8s\n435:\tlearn: 0.2945088\ttotal: 2m 30s\tremaining: 56.5s\n436:\tlearn: 0.2943145\ttotal: 2m 30s\tremaining: 56.1s\n437:\tlearn: 0.2940394\ttotal: 2m 30s\tremaining: 55.8s\n438:\tlearn: 0.2934308\ttotal: 2m 31s\tremaining: 55.5s\n439:\tlearn: 0.2932482\ttotal: 2m 31s\tremaining: 55.1s\n440:\tlearn: 0.2911197\ttotal: 2m 31s\tremaining: 54.8s\n441:\tlearn: 0.2909200\ttotal: 2m 32s\tremaining: 54.4s\n442:\tlearn: 0.2886312\ttotal: 2m 32s\tremaining: 54.1s\n443:\tlearn: 0.2879997\ttotal: 2m 32s\tremaining: 53.7s\n444:\tlearn: 0.2872705\ttotal: 2m 33s\tremaining: 53.4s\n445:\tlearn: 0.2869239\ttotal: 2m 33s\tremaining: 53.1s\n446:\tlearn: 0.2869018\ttotal: 2m 34s\tremaining: 52.7s\n447:\tlearn: 0.2858959\ttotal: 2m 34s\tremaining: 52.4s\n448:\tlearn: 0.2854097\ttotal: 2m 34s\tremaining: 52s\n449:\tlearn: 0.2852504\ttotal: 2m 35s\tremaining: 51.7s\n450:\tlearn: 0.2841682\ttotal: 2m 35s\tremaining: 51.3s\n451:\tlearn: 0.2840338\ttotal: 2m 35s\tremaining: 51s\n452:\tlearn: 0.2838232\ttotal: 2m 36s\tremaining: 50.6s\n453:\tlearn: 0.2837384\ttotal: 2m 36s\tremaining: 50.3s\n454:\tlearn: 0.2834290\ttotal: 2m 36s\tremaining: 50s\n455:\tlearn: 0.2829692\ttotal: 2m 37s\tremaining: 49.6s\n456:\tlearn: 0.2825713\ttotal: 2m 37s\tremaining: 49.3s\n457:\tlearn: 0.2822362\ttotal: 2m 37s\tremaining: 48.9s\n458:\tlearn: 0.2812295\ttotal: 2m 38s\tremaining: 48.6s\n459:\tlearn: 0.2808798\ttotal: 2m 38s\tremaining: 48.2s\n460:\tlearn: 0.2803331\ttotal: 2m 38s\tremaining: 47.9s\n461:\tlearn: 0.2802359\ttotal: 2m 39s\tremaining: 47.5s\n462:\tlearn: 0.2800592\ttotal: 2m 39s\tremaining: 47.2s\n463:\tlearn: 0.2800336\ttotal: 2m 39s\tremaining: 46.9s\n464:\tlearn: 0.2798490\ttotal: 2m 40s\tremaining: 46.5s\n465:\tlearn: 0.2793900\ttotal: 2m 40s\tremaining: 46.2s\n466:\tlearn: 0.2793703\ttotal: 2m 40s\tremaining: 45.8s\n467:\tlearn: 0.2792885\ttotal: 2m 41s\tremaining: 45.5s\n468:\tlearn: 0.2790619\ttotal: 2m 41s\tremaining: 45.1s\n469:\tlearn: 0.2788069\ttotal: 2m 41s\tremaining: 44.8s\n470:\tlearn: 0.2783902\ttotal: 2m 42s\tremaining: 44.4s\n471:\tlearn: 0.2782675\ttotal: 2m 42s\tremaining: 44.1s\n472:\tlearn: 0.2781574\ttotal: 2m 42s\tremaining: 43.7s\n473:\tlearn: 0.2774642\ttotal: 2m 43s\tremaining: 43.4s\n474:\tlearn: 0.2772297\ttotal: 2m 43s\tremaining: 43.1s\n475:\tlearn: 0.2758034\ttotal: 2m 43s\tremaining: 42.7s\n476:\tlearn: 0.2755064\ttotal: 2m 44s\tremaining: 42.4s\n477:\tlearn: 0.2754494\ttotal: 2m 44s\tremaining: 42s\n478:\tlearn: 0.2753799\ttotal: 2m 44s\tremaining: 41.7s\n479:\tlearn: 0.2750430\ttotal: 2m 45s\tremaining: 41.3s\n480:\tlearn: 0.2744832\ttotal: 2m 45s\tremaining: 41s\n481:\tlearn: 0.2740793\ttotal: 2m 46s\tremaining: 40.6s\n482:\tlearn: 0.2734942\ttotal: 2m 46s\tremaining: 40.3s\n483:\tlearn: 0.2733669\ttotal: 2m 46s\tremaining: 40s\n484:\tlearn: 0.2732087\ttotal: 2m 47s\tremaining: 39.6s\n485:\tlearn: 0.2730029\ttotal: 2m 47s\tremaining: 39.3s\n486:\tlearn: 0.2729662\ttotal: 2m 47s\tremaining: 38.9s\n487:\tlearn: 0.2729187\ttotal: 2m 48s\tremaining: 38.6s\n488:\tlearn: 0.2728182\ttotal: 2m 48s\tremaining: 38.2s\n489:\tlearn: 0.2719792\ttotal: 2m 48s\tremaining: 37.9s\n490:\tlearn: 0.2718101\ttotal: 2m 49s\tremaining: 37.5s\n491:\tlearn: 0.2713048\ttotal: 2m 49s\tremaining: 37.2s\n492:\tlearn: 0.2711569\ttotal: 2m 49s\tremaining: 36.8s\n493:\tlearn: 0.2709705\ttotal: 2m 50s\tremaining: 36.5s\n494:\tlearn: 0.2708388\ttotal: 2m 50s\tremaining: 36.2s\n495:\tlearn: 0.2706840\ttotal: 2m 50s\tremaining: 35.8s\n496:\tlearn: 0.2700707\ttotal: 2m 51s\tremaining: 35.5s\n497:\tlearn: 0.2700274\ttotal: 2m 51s\tremaining: 35.1s\n498:\tlearn: 0.2696832\ttotal: 2m 51s\tremaining: 34.8s\n499:\tlearn: 0.2693403\ttotal: 2m 52s\tremaining: 34.4s\n500:\tlearn: 0.2692086\ttotal: 2m 52s\tremaining: 34.1s\n501:\tlearn: 0.2691679\ttotal: 2m 52s\tremaining: 33.7s\n502:\tlearn: 0.2690834\ttotal: 2m 53s\tremaining: 33.4s\n503:\tlearn: 0.2682299\ttotal: 2m 53s\tremaining: 33s\n504:\tlearn: 0.2680041\ttotal: 2m 53s\tremaining: 32.7s\n505:\tlearn: 0.2678031\ttotal: 2m 54s\tremaining: 32.4s\n506:\tlearn: 0.2676226\ttotal: 2m 54s\tremaining: 32s\n507:\tlearn: 0.2672897\ttotal: 2m 54s\tremaining: 31.7s\n508:\tlearn: 0.2665160\ttotal: 2m 55s\tremaining: 31.3s\n509:\tlearn: 0.2664475\ttotal: 2m 55s\tremaining: 31s\n510:\tlearn: 0.2659229\ttotal: 2m 55s\tremaining: 30.6s\n511:\tlearn: 0.2657717\ttotal: 2m 56s\tremaining: 30.3s\n512:\tlearn: 0.2657127\ttotal: 2m 56s\tremaining: 29.9s\n513:\tlearn: 0.2652917\ttotal: 2m 56s\tremaining: 29.6s\n514:\tlearn: 0.2650497\ttotal: 2m 57s\tremaining: 29.3s\n515:\tlearn: 0.2648162\ttotal: 2m 57s\tremaining: 28.9s\n516:\tlearn: 0.2647303\ttotal: 2m 57s\tremaining: 28.6s\n517:\tlearn: 0.2643964\ttotal: 2m 58s\tremaining: 28.2s\n518:\tlearn: 0.2642491\ttotal: 2m 58s\tremaining: 27.9s\n519:\tlearn: 0.2641123\ttotal: 2m 58s\tremaining: 27.5s\n520:\tlearn: 0.2640384\ttotal: 2m 59s\tremaining: 27.2s\n521:\tlearn: 0.2637328\ttotal: 2m 59s\tremaining: 26.8s\n522:\tlearn: 0.2636436\ttotal: 3m\tremaining: 26.5s\n523:\tlearn: 0.2635306\ttotal: 3m\tremaining: 26.2s\n524:\tlearn: 0.2629361\ttotal: 3m\tremaining: 25.8s\n525:\tlearn: 0.2628147\ttotal: 3m 1s\tremaining: 25.5s\n526:\tlearn: 0.2627438\ttotal: 3m 1s\tremaining: 25.1s\n527:\tlearn: 0.2625615\ttotal: 3m 1s\tremaining: 24.8s\n528:\tlearn: 0.2625184\ttotal: 3m 2s\tremaining: 24.4s\n529:\tlearn: 0.2617325\ttotal: 3m 2s\tremaining: 24.1s\n530:\tlearn: 0.2605765\ttotal: 3m 2s\tremaining: 23.7s\n531:\tlearn: 0.2600192\ttotal: 3m 3s\tremaining: 23.4s\n532:\tlearn: 0.2591940\ttotal: 3m 3s\tremaining: 23.1s\n533:\tlearn: 0.2591157\ttotal: 3m 3s\tremaining: 22.7s\n534:\tlearn: 0.2590686\ttotal: 3m 4s\tremaining: 22.4s\n535:\tlearn: 0.2587803\ttotal: 3m 4s\tremaining: 22s\n536:\tlearn: 0.2580505\ttotal: 3m 4s\tremaining: 21.7s\n537:\tlearn: 0.2577474\ttotal: 3m 5s\tremaining: 21.3s\n538:\tlearn: 0.2575686\ttotal: 3m 5s\tremaining: 21s\n539:\tlearn: 0.2574690\ttotal: 3m 5s\tremaining: 20.6s\n540:\tlearn: 0.2573793\ttotal: 3m 6s\tremaining: 20.3s\n541:\tlearn: 0.2562786\ttotal: 3m 6s\tremaining: 20s\n542:\tlearn: 0.2558502\ttotal: 3m 6s\tremaining: 19.6s\n543:\tlearn: 0.2555583\ttotal: 3m 7s\tremaining: 19.3s\n544:\tlearn: 0.2552056\ttotal: 3m 7s\tremaining: 18.9s\n545:\tlearn: 0.2546534\ttotal: 3m 7s\tremaining: 18.6s\n546:\tlearn: 0.2545257\ttotal: 3m 8s\tremaining: 18.2s\n547:\tlearn: 0.2542931\ttotal: 3m 8s\tremaining: 17.9s\n548:\tlearn: 0.2538141\ttotal: 3m 8s\tremaining: 17.6s\n549:\tlearn: 0.2535280\ttotal: 3m 9s\tremaining: 17.2s\n550:\tlearn: 0.2533926\ttotal: 3m 9s\tremaining: 16.9s\n551:\tlearn: 0.2527633\ttotal: 3m 9s\tremaining: 16.5s\n552:\tlearn: 0.2521430\ttotal: 3m 10s\tremaining: 16.2s\n553:\tlearn: 0.2515867\ttotal: 3m 10s\tremaining: 15.8s\n554:\tlearn: 0.2515121\ttotal: 3m 11s\tremaining: 15.5s\n555:\tlearn: 0.2510259\ttotal: 3m 11s\tremaining: 15.1s\n556:\tlearn: 0.2509391\ttotal: 3m 11s\tremaining: 14.8s\n557:\tlearn: 0.2501308\ttotal: 3m 12s\tremaining: 14.5s\n558:\tlearn: 0.2500585\ttotal: 3m 12s\tremaining: 14.1s\n559:\tlearn: 0.2492849\ttotal: 3m 12s\tremaining: 13.8s\n560:\tlearn: 0.2490244\ttotal: 3m 13s\tremaining: 13.4s\n561:\tlearn: 0.2489667\ttotal: 3m 13s\tremaining: 13.1s\n562:\tlearn: 0.2474794\ttotal: 3m 13s\tremaining: 12.7s\n563:\tlearn: 0.2471788\ttotal: 3m 14s\tremaining: 12.4s\n564:\tlearn: 0.2469181\ttotal: 3m 14s\tremaining: 12s\n565:\tlearn: 0.2467863\ttotal: 3m 14s\tremaining: 11.7s\n566:\tlearn: 0.2466477\ttotal: 3m 15s\tremaining: 11.4s\n567:\tlearn: 0.2466004\ttotal: 3m 15s\tremaining: 11s\n568:\tlearn: 0.2464854\ttotal: 3m 15s\tremaining: 10.7s\n569:\tlearn: 0.2464071\ttotal: 3m 16s\tremaining: 10.3s\n570:\tlearn: 0.2462158\ttotal: 3m 16s\tremaining: 9.98s\n571:\tlearn: 0.2450278\ttotal: 3m 16s\tremaining: 9.63s\n572:\tlearn: 0.2442665\ttotal: 3m 17s\tremaining: 9.29s\n573:\tlearn: 0.2441244\ttotal: 3m 17s\tremaining: 8.95s\n574:\tlearn: 0.2440068\ttotal: 3m 17s\tremaining: 8.6s\n575:\tlearn: 0.2439028\ttotal: 3m 18s\tremaining: 8.26s\n576:\tlearn: 0.2437479\ttotal: 3m 18s\tremaining: 7.91s\n577:\tlearn: 0.2435259\ttotal: 3m 18s\tremaining: 7.57s\n578:\tlearn: 0.2424511\ttotal: 3m 19s\tremaining: 7.23s\n579:\tlearn: 0.2422845\ttotal: 3m 19s\tremaining: 6.88s\n580:\tlearn: 0.2416611\ttotal: 3m 19s\tremaining: 6.54s\n581:\tlearn: 0.2415825\ttotal: 3m 20s\tremaining: 6.19s\n582:\tlearn: 0.2415211\ttotal: 3m 20s\tremaining: 5.85s\n583:\tlearn: 0.2413508\ttotal: 3m 20s\tremaining: 5.5s\n584:\tlearn: 0.2411417\ttotal: 3m 21s\tremaining: 5.16s\n585:\tlearn: 0.2407949\ttotal: 3m 21s\tremaining: 4.82s\n586:\tlearn: 0.2405907\ttotal: 3m 21s\tremaining: 4.47s\n587:\tlearn: 0.2405173\ttotal: 3m 22s\tremaining: 4.13s\n588:\tlearn: 0.2404674\ttotal: 3m 22s\tremaining: 3.78s\n589:\tlearn: 0.2403596\ttotal: 3m 22s\tremaining: 3.44s\n590:\tlearn: 0.2403023\ttotal: 3m 23s\tremaining: 3.1s\n591:\tlearn: 0.2400664\ttotal: 3m 23s\tremaining: 2.75s\n592:\tlearn: 0.2398930\ttotal: 3m 24s\tremaining: 2.41s\n593:\tlearn: 0.2397246\ttotal: 3m 24s\tremaining: 2.06s\n594:\tlearn: 0.2396976\ttotal: 3m 24s\tremaining: 1.72s\n595:\tlearn: 0.2396735\ttotal: 3m 25s\tremaining: 1.38s\n596:\tlearn: 0.2394982\ttotal: 3m 25s\tremaining: 1.03s\n597:\tlearn: 0.2394644\ttotal: 3m 25s\tremaining: 688ms\n598:\tlearn: 0.2394321\ttotal: 3m 26s\tremaining: 344ms\n599:\tlearn: 0.2393792\ttotal: 3m 26s\tremaining: 0us\ncat_fit_done\nmodel_ready\n0:\tlearn: 2.5648191\ttotal: 415ms\tremaining: 4m 8s\n1:\tlearn: 2.5038364\ttotal: 822ms\tremaining: 4m 5s\n2:\tlearn: 2.4321017\ttotal: 1.27s\tremaining: 4m 12s\n3:\tlearn: 2.3763918\ttotal: 1.7s\tremaining: 4m 13s\n4:\tlearn: 2.3329580\ttotal: 2.13s\tremaining: 4m 13s\n5:\tlearn: 2.2922867\ttotal: 2.54s\tremaining: 4m 11s\n6:\tlearn: 2.2453553\ttotal: 2.97s\tremaining: 4m 11s\n7:\tlearn: 2.2089051\ttotal: 3.39s\tremaining: 4m 11s\n8:\tlearn: 2.1643865\ttotal: 3.82s\tremaining: 4m 11s\n9:\tlearn: 2.1283208\ttotal: 4.24s\tremaining: 4m 10s\n10:\tlearn: 2.1072958\ttotal: 4.64s\tremaining: 4m 8s\n11:\tlearn: 2.0822748\ttotal: 5.05s\tremaining: 4m 7s\n12:\tlearn: 2.0587379\ttotal: 5.47s\tremaining: 4m 6s\n13:\tlearn: 2.0319922\ttotal: 5.88s\tremaining: 4m 5s\n14:\tlearn: 2.0058803\ttotal: 6.29s\tremaining: 4m 5s\n15:\tlearn: 1.9786493\ttotal: 6.7s\tremaining: 4m 4s\n16:\tlearn: 1.9572744\ttotal: 7.11s\tremaining: 4m 3s\n17:\tlearn: 1.9416314\ttotal: 7.51s\tremaining: 4m 3s\n18:\tlearn: 1.9040978\ttotal: 7.95s\tremaining: 4m 3s\n19:\tlearn: 1.8853706\ttotal: 8.36s\tremaining: 4m 2s\n20:\tlearn: 1.8576556\ttotal: 8.78s\tremaining: 4m 2s\n21:\tlearn: 1.8395703\ttotal: 9.2s\tremaining: 4m 1s\n22:\tlearn: 1.8254498\ttotal: 9.61s\tremaining: 4m 1s\n23:\tlearn: 1.8026983\ttotal: 10s\tremaining: 4m\n24:\tlearn: 1.7846493\ttotal: 10.4s\tremaining: 4m\n25:\tlearn: 1.7693215\ttotal: 10.8s\tremaining: 3m 59s\n26:\tlearn: 1.7572545\ttotal: 11.2s\tremaining: 3m 58s\n27:\tlearn: 1.7400278\ttotal: 11.7s\tremaining: 3m 58s\n28:\tlearn: 1.7216711\ttotal: 12.1s\tremaining: 3m 57s\n29:\tlearn: 1.6987051\ttotal: 12.5s\tremaining: 3m 57s\n30:\tlearn: 1.6857620\ttotal: 12.9s\tremaining: 3m 57s\n31:\tlearn: 1.6736141\ttotal: 13.3s\tremaining: 3m 56s\n32:\tlearn: 1.6625442\ttotal: 13.7s\tremaining: 3m 55s\n33:\tlearn: 1.6521711\ttotal: 14.1s\tremaining: 3m 55s\n34:\tlearn: 1.6377905\ttotal: 14.5s\tremaining: 3m 54s\n35:\tlearn: 1.6255938\ttotal: 15s\tremaining: 3m 54s\n36:\tlearn: 1.6144416\ttotal: 15.4s\tremaining: 3m 54s\n37:\tlearn: 1.6027289\ttotal: 15.8s\tremaining: 3m 53s\n38:\tlearn: 1.5947518\ttotal: 16.2s\tremaining: 3m 53s\n39:\tlearn: 1.5797840\ttotal: 16.6s\tremaining: 3m 52s\n40:\tlearn: 1.5681386\ttotal: 17s\tremaining: 3m 52s\n41:\tlearn: 1.5608462\ttotal: 17.4s\tremaining: 3m 51s\n42:\tlearn: 1.5439638\ttotal: 17.9s\tremaining: 3m 51s\n43:\tlearn: 1.5302942\ttotal: 18.3s\tremaining: 3m 50s\n44:\tlearn: 1.5219003\ttotal: 18.7s\tremaining: 3m 50s\n45:\tlearn: 1.5097990\ttotal: 19.1s\tremaining: 3m 50s\n46:\tlearn: 1.5045766\ttotal: 19.5s\tremaining: 3m 49s\n47:\tlearn: 1.4926540\ttotal: 19.9s\tremaining: 3m 49s\n48:\tlearn: 1.4865958\ttotal: 20.3s\tremaining: 3m 48s\n49:\tlearn: 1.4792902\ttotal: 20.7s\tremaining: 3m 47s\n50:\tlearn: 1.4681917\ttotal: 21.1s\tremaining: 3m 47s\n51:\tlearn: 1.4578539\ttotal: 21.6s\tremaining: 3m 47s\n52:\tlearn: 1.4538036\ttotal: 22s\tremaining: 3m 46s\n53:\tlearn: 1.4425223\ttotal: 22.4s\tremaining: 3m 46s\n54:\tlearn: 1.4304372\ttotal: 22.8s\tremaining: 3m 45s\n55:\tlearn: 1.4140672\ttotal: 23.2s\tremaining: 3m 45s\n56:\tlearn: 1.4070699\ttotal: 23.6s\tremaining: 3m 44s\n57:\tlearn: 1.3975887\ttotal: 24s\tremaining: 3m 44s\n58:\tlearn: 1.3911584\ttotal: 24.4s\tremaining: 3m 44s\n59:\tlearn: 1.3840993\ttotal: 24.8s\tremaining: 3m 43s\n60:\tlearn: 1.3828585\ttotal: 25.2s\tremaining: 3m 42s\n61:\tlearn: 1.3763943\ttotal: 25.6s\tremaining: 3m 42s\n62:\tlearn: 1.3700105\ttotal: 26s\tremaining: 3m 42s\n63:\tlearn: 1.3621535\ttotal: 26.5s\tremaining: 3m 41s\n64:\tlearn: 1.3453235\ttotal: 26.9s\tremaining: 3m 41s\n65:\tlearn: 1.3391614\ttotal: 27.3s\tremaining: 3m 40s\n66:\tlearn: 1.3322605\ttotal: 27.7s\tremaining: 3m 40s\n67:\tlearn: 1.3197274\ttotal: 28.2s\tremaining: 3m 40s\n68:\tlearn: 1.3131115\ttotal: 28.6s\tremaining: 3m 39s\n69:\tlearn: 1.3083585\ttotal: 29s\tremaining: 3m 39s\n70:\tlearn: 1.3031012\ttotal: 29.4s\tremaining: 3m 38s\n71:\tlearn: 1.2960499\ttotal: 29.8s\tremaining: 3m 38s\n72:\tlearn: 1.2920422\ttotal: 30.2s\tremaining: 3m 37s\n73:\tlearn: 1.2895549\ttotal: 30.6s\tremaining: 3m 37s\n74:\tlearn: 1.2792154\ttotal: 31s\tremaining: 3m 37s\n75:\tlearn: 1.2679962\ttotal: 31.4s\tremaining: 3m 36s\n76:\tlearn: 1.2672576\ttotal: 31.8s\tremaining: 3m 36s\n77:\tlearn: 1.2592876\ttotal: 32.2s\tremaining: 3m 35s\n78:\tlearn: 1.2564329\ttotal: 32.6s\tremaining: 3m 35s\n79:\tlearn: 1.2433803\ttotal: 33.1s\tremaining: 3m 34s\n80:\tlearn: 1.2387979\ttotal: 33.5s\tremaining: 3m 34s\n81:\tlearn: 1.2287959\ttotal: 33.9s\tremaining: 3m 34s\n82:\tlearn: 1.2206494\ttotal: 34.3s\tremaining: 3m 33s\n83:\tlearn: 1.2161542\ttotal: 34.7s\tremaining: 3m 33s\n84:\tlearn: 1.2123109\ttotal: 35.1s\tremaining: 3m 32s\n85:\tlearn: 1.1973203\ttotal: 35.6s\tremaining: 3m 32s\n86:\tlearn: 1.1852181\ttotal: 36s\tremaining: 3m 32s\n87:\tlearn: 1.1789193\ttotal: 36.4s\tremaining: 3m 31s\n88:\tlearn: 1.1772925\ttotal: 36.8s\tremaining: 3m 31s\n89:\tlearn: 1.1715151\ttotal: 37.2s\tremaining: 3m 30s\n90:\tlearn: 1.1607879\ttotal: 37.7s\tremaining: 3m 30s\n91:\tlearn: 1.1553952\ttotal: 38.1s\tremaining: 3m 30s\n92:\tlearn: 1.1515941\ttotal: 38.5s\tremaining: 3m 29s\n93:\tlearn: 1.1406605\ttotal: 38.9s\tremaining: 3m 29s\n94:\tlearn: 1.1298813\ttotal: 39.3s\tremaining: 3m 28s\n95:\tlearn: 1.1199536\ttotal: 39.7s\tremaining: 3m 28s\n96:\tlearn: 1.1126870\ttotal: 40.1s\tremaining: 3m 28s\n97:\tlearn: 1.1055564\ttotal: 40.6s\tremaining: 3m 27s\n98:\tlearn: 1.0966981\ttotal: 41s\tremaining: 3m 27s\n99:\tlearn: 1.0844766\ttotal: 41.4s\tremaining: 3m 27s\n100:\tlearn: 1.0773023\ttotal: 41.8s\tremaining: 3m 26s\n101:\tlearn: 1.0717078\ttotal: 42.3s\tremaining: 3m 26s\n102:\tlearn: 1.0702108\ttotal: 42.7s\tremaining: 3m 25s\n103:\tlearn: 1.0643460\ttotal: 43.1s\tremaining: 3m 25s\n104:\tlearn: 1.0562915\ttotal: 43.5s\tremaining: 3m 25s\n105:\tlearn: 1.0508810\ttotal: 43.9s\tremaining: 3m 24s\n106:\tlearn: 1.0495390\ttotal: 44.3s\tremaining: 3m 24s\n107:\tlearn: 1.0417509\ttotal: 44.7s\tremaining: 3m 23s\n108:\tlearn: 1.0319495\ttotal: 45.2s\tremaining: 3m 23s\n109:\tlearn: 1.0220599\ttotal: 45.6s\tremaining: 3m 23s\n110:\tlearn: 1.0188601\ttotal: 46s\tremaining: 3m 22s\n111:\tlearn: 1.0170613\ttotal: 46.4s\tremaining: 3m 22s\n112:\tlearn: 1.0131022\ttotal: 46.8s\tremaining: 3m 21s\n113:\tlearn: 1.0089758\ttotal: 47.2s\tremaining: 3m 21s\n114:\tlearn: 1.0076024\ttotal: 47.6s\tremaining: 3m 20s\n115:\tlearn: 1.0027937\ttotal: 48s\tremaining: 3m 20s\n116:\tlearn: 0.9952014\ttotal: 48.4s\tremaining: 3m 19s\n117:\tlearn: 0.9813938\ttotal: 48.9s\tremaining: 3m 19s\n118:\tlearn: 0.9781619\ttotal: 49.3s\tremaining: 3m 19s\n119:\tlearn: 0.9743295\ttotal: 49.7s\tremaining: 3m 18s\n120:\tlearn: 0.9704087\ttotal: 50.1s\tremaining: 3m 18s\n121:\tlearn: 0.9679018\ttotal: 50.5s\tremaining: 3m 17s\n122:\tlearn: 0.9590251\ttotal: 50.9s\tremaining: 3m 17s\n123:\tlearn: 0.9566373\ttotal: 51.3s\tremaining: 3m 17s\n124:\tlearn: 0.9499157\ttotal: 51.8s\tremaining: 3m 16s\n125:\tlearn: 0.9463929\ttotal: 52.2s\tremaining: 3m 16s\n126:\tlearn: 0.9434067\ttotal: 52.6s\tremaining: 3m 15s\n127:\tlearn: 0.9349668\ttotal: 53s\tremaining: 3m 15s\n128:\tlearn: 0.9306275\ttotal: 53.4s\tremaining: 3m 14s\n129:\tlearn: 0.9283555\ttotal: 53.8s\tremaining: 3m 14s\n130:\tlearn: 0.9253857\ttotal: 54.2s\tremaining: 3m 14s\n131:\tlearn: 0.9231876\ttotal: 54.6s\tremaining: 3m 13s\n132:\tlearn: 0.9209587\ttotal: 55s\tremaining: 3m 13s\n133:\tlearn: 0.9186874\ttotal: 55.4s\tremaining: 3m 12s\n134:\tlearn: 0.9176317\ttotal: 55.8s\tremaining: 3m 12s\n135:\tlearn: 0.9136519\ttotal: 56.2s\tremaining: 3m 11s\n136:\tlearn: 0.9099486\ttotal: 56.7s\tremaining: 3m 11s\n137:\tlearn: 0.9067545\ttotal: 57.1s\tremaining: 3m 11s\n138:\tlearn: 0.9032727\ttotal: 57.5s\tremaining: 3m 10s\n139:\tlearn: 0.8973930\ttotal: 57.9s\tremaining: 3m 10s\n140:\tlearn: 0.8960886\ttotal: 58.3s\tremaining: 3m 9s\n141:\tlearn: 0.8954124\ttotal: 58.7s\tremaining: 3m 9s\n142:\tlearn: 0.8901991\ttotal: 59.1s\tremaining: 3m 8s\n143:\tlearn: 0.8859035\ttotal: 59.5s\tremaining: 3m 8s\n144:\tlearn: 0.8804452\ttotal: 59.9s\tremaining: 3m 8s\n145:\tlearn: 0.8799862\ttotal: 1m\tremaining: 3m 7s\n146:\tlearn: 0.8763789\ttotal: 1m\tremaining: 3m 7s\n147:\tlearn: 0.8756355\ttotal: 1m 1s\tremaining: 3m 6s\n148:\tlearn: 0.8690054\ttotal: 1m 1s\tremaining: 3m 6s\n149:\tlearn: 0.8623805\ttotal: 1m 2s\tremaining: 3m 6s\n150:\tlearn: 0.8595235\ttotal: 1m 2s\tremaining: 3m 5s\n151:\tlearn: 0.8549971\ttotal: 1m 2s\tremaining: 3m 5s\n152:\tlearn: 0.8466517\ttotal: 1m 3s\tremaining: 3m 4s\n153:\tlearn: 0.8439101\ttotal: 1m 3s\tremaining: 3m 4s\n154:\tlearn: 0.8427766\ttotal: 1m 4s\tremaining: 3m 4s\n155:\tlearn: 0.8418623\ttotal: 1m 4s\tremaining: 3m 3s\n156:\tlearn: 0.8351595\ttotal: 1m 4s\tremaining: 3m 3s\n157:\tlearn: 0.8284617\ttotal: 1m 5s\tremaining: 3m 2s\n158:\tlearn: 0.8233909\ttotal: 1m 5s\tremaining: 3m 2s\n159:\tlearn: 0.8173194\ttotal: 1m 6s\tremaining: 3m 2s\n160:\tlearn: 0.8096515\ttotal: 1m 6s\tremaining: 3m 1s\n161:\tlearn: 0.8071185\ttotal: 1m 7s\tremaining: 3m 1s\n162:\tlearn: 0.8058137\ttotal: 1m 7s\tremaining: 3m\n163:\tlearn: 0.8018290\ttotal: 1m 7s\tremaining: 3m\n164:\tlearn: 0.7973730\ttotal: 1m 8s\tremaining: 3m\n165:\tlearn: 0.7955616\ttotal: 1m 8s\tremaining: 2m 59s\n166:\tlearn: 0.7916293\ttotal: 1m 9s\tremaining: 2m 59s\n167:\tlearn: 0.7902640\ttotal: 1m 9s\tremaining: 2m 58s\n168:\tlearn: 0.7830879\ttotal: 1m 9s\tremaining: 2m 58s\n169:\tlearn: 0.7821653\ttotal: 1m 10s\tremaining: 2m 58s\n170:\tlearn: 0.7764610\ttotal: 1m 10s\tremaining: 2m 57s\n171:\tlearn: 0.7716551\ttotal: 1m 11s\tremaining: 2m 57s\n172:\tlearn: 0.7642542\ttotal: 1m 11s\tremaining: 2m 56s\n173:\tlearn: 0.7619489\ttotal: 1m 12s\tremaining: 2m 56s\n174:\tlearn: 0.7589773\ttotal: 1m 12s\tremaining: 2m 56s\n175:\tlearn: 0.7581867\ttotal: 1m 12s\tremaining: 2m 55s\n176:\tlearn: 0.7526769\ttotal: 1m 13s\tremaining: 2m 55s\n177:\tlearn: 0.7505546\ttotal: 1m 13s\tremaining: 2m 54s\n178:\tlearn: 0.7498950\ttotal: 1m 14s\tremaining: 2m 54s\n179:\tlearn: 0.7482429\ttotal: 1m 14s\tremaining: 2m 53s\n180:\tlearn: 0.7441444\ttotal: 1m 14s\tremaining: 2m 53s\n181:\tlearn: 0.7407380\ttotal: 1m 15s\tremaining: 2m 53s\n182:\tlearn: 0.7393404\ttotal: 1m 15s\tremaining: 2m 52s\n183:\tlearn: 0.7386990\ttotal: 1m 16s\tremaining: 2m 52s\n184:\tlearn: 0.7364447\ttotal: 1m 16s\tremaining: 2m 51s\n185:\tlearn: 0.7358720\ttotal: 1m 17s\tremaining: 2m 51s\n186:\tlearn: 0.7321560\ttotal: 1m 17s\tremaining: 2m 51s\n187:\tlearn: 0.7310195\ttotal: 1m 17s\tremaining: 2m 50s\n188:\tlearn: 0.7293704\ttotal: 1m 18s\tremaining: 2m 50s\n189:\tlearn: 0.7265592\ttotal: 1m 18s\tremaining: 2m 49s\n190:\tlearn: 0.7238360\ttotal: 1m 19s\tremaining: 2m 49s\n191:\tlearn: 0.7182734\ttotal: 1m 19s\tremaining: 2m 48s\n192:\tlearn: 0.7135115\ttotal: 1m 19s\tremaining: 2m 48s\n193:\tlearn: 0.7123568\ttotal: 1m 20s\tremaining: 2m 48s\n194:\tlearn: 0.7087646\ttotal: 1m 20s\tremaining: 2m 47s\n195:\tlearn: 0.7038438\ttotal: 1m 21s\tremaining: 2m 47s\n196:\tlearn: 0.6995093\ttotal: 1m 21s\tremaining: 2m 46s\n197:\tlearn: 0.6966012\ttotal: 1m 22s\tremaining: 2m 46s\n198:\tlearn: 0.6953217\ttotal: 1m 22s\tremaining: 2m 46s\n199:\tlearn: 0.6927908\ttotal: 1m 22s\tremaining: 2m 45s\n200:\tlearn: 0.6912670\ttotal: 1m 23s\tremaining: 2m 45s\n201:\tlearn: 0.6895088\ttotal: 1m 23s\tremaining: 2m 44s\n202:\tlearn: 0.6886361\ttotal: 1m 24s\tremaining: 2m 44s\n203:\tlearn: 0.6846878\ttotal: 1m 24s\tremaining: 2m 44s\n204:\tlearn: 0.6835662\ttotal: 1m 24s\tremaining: 2m 43s\n205:\tlearn: 0.6827112\ttotal: 1m 25s\tremaining: 2m 43s\n206:\tlearn: 0.6784128\ttotal: 1m 25s\tremaining: 2m 42s\n207:\tlearn: 0.6764334\ttotal: 1m 26s\tremaining: 2m 42s\n208:\tlearn: 0.6731166\ttotal: 1m 26s\tremaining: 2m 41s\n209:\tlearn: 0.6691830\ttotal: 1m 26s\tremaining: 2m 41s\n210:\tlearn: 0.6685139\ttotal: 1m 27s\tremaining: 2m 41s\n211:\tlearn: 0.6651621\ttotal: 1m 27s\tremaining: 2m 40s\n212:\tlearn: 0.6633419\ttotal: 1m 28s\tremaining: 2m 40s\n213:\tlearn: 0.6622640\ttotal: 1m 28s\tremaining: 2m 39s\n214:\tlearn: 0.6619042\ttotal: 1m 29s\tremaining: 2m 39s\n215:\tlearn: 0.6579541\ttotal: 1m 29s\tremaining: 2m 39s\n216:\tlearn: 0.6566649\ttotal: 1m 29s\tremaining: 2m 38s\n217:\tlearn: 0.6526837\ttotal: 1m 30s\tremaining: 2m 38s\n218:\tlearn: 0.6500979\ttotal: 1m 30s\tremaining: 2m 37s\n219:\tlearn: 0.6453776\ttotal: 1m 31s\tremaining: 2m 37s\n220:\tlearn: 0.6428626\ttotal: 1m 31s\tremaining: 2m 37s\n221:\tlearn: 0.6415921\ttotal: 1m 31s\tremaining: 2m 36s\n222:\tlearn: 0.6394581\ttotal: 1m 32s\tremaining: 2m 36s\n223:\tlearn: 0.6369407\ttotal: 1m 32s\tremaining: 2m 35s\n224:\tlearn: 0.6358446\ttotal: 1m 33s\tremaining: 2m 35s\n225:\tlearn: 0.6343964\ttotal: 1m 33s\tremaining: 2m 34s\n226:\tlearn: 0.6313361\ttotal: 1m 34s\tremaining: 2m 34s\n227:\tlearn: 0.6310080\ttotal: 1m 34s\tremaining: 2m 34s\n228:\tlearn: 0.6295514\ttotal: 1m 34s\tremaining: 2m 33s\n229:\tlearn: 0.6279279\ttotal: 1m 35s\tremaining: 2m 33s\n230:\tlearn: 0.6276166\ttotal: 1m 35s\tremaining: 2m 32s\n231:\tlearn: 0.6257711\ttotal: 1m 36s\tremaining: 2m 32s\n232:\tlearn: 0.6241432\ttotal: 1m 36s\tremaining: 2m 32s\n233:\tlearn: 0.6195250\ttotal: 1m 37s\tremaining: 2m 31s\n234:\tlearn: 0.6153271\ttotal: 1m 37s\tremaining: 2m 31s\n235:\tlearn: 0.6147105\ttotal: 1m 37s\tremaining: 2m 30s\n236:\tlearn: 0.6143264\ttotal: 1m 38s\tremaining: 2m 30s\n237:\tlearn: 0.6137383\ttotal: 1m 38s\tremaining: 2m 30s\n238:\tlearn: 0.6132389\ttotal: 1m 39s\tremaining: 2m 29s\n239:\tlearn: 0.6123570\ttotal: 1m 39s\tremaining: 2m 29s\n240:\tlearn: 0.6095988\ttotal: 1m 39s\tremaining: 2m 28s\n241:\tlearn: 0.6070383\ttotal: 1m 40s\tremaining: 2m 28s\n242:\tlearn: 0.6066380\ttotal: 1m 40s\tremaining: 2m 27s\n243:\tlearn: 0.6053220\ttotal: 1m 41s\tremaining: 2m 27s\n244:\tlearn: 0.6024010\ttotal: 1m 41s\tremaining: 2m 27s\n245:\tlearn: 0.6015275\ttotal: 1m 41s\tremaining: 2m 26s\n246:\tlearn: 0.6010916\ttotal: 1m 42s\tremaining: 2m 26s\n247:\tlearn: 0.5991144\ttotal: 1m 42s\tremaining: 2m 25s\n248:\tlearn: 0.5987766\ttotal: 1m 43s\tremaining: 2m 25s\n249:\tlearn: 0.5982827\ttotal: 1m 43s\tremaining: 2m 25s\n250:\tlearn: 0.5970059\ttotal: 1m 43s\tremaining: 2m 24s\n251:\tlearn: 0.5962006\ttotal: 1m 44s\tremaining: 2m 24s\n252:\tlearn: 0.5927933\ttotal: 1m 44s\tremaining: 2m 23s\n253:\tlearn: 0.5909080\ttotal: 1m 45s\tremaining: 2m 23s\n254:\tlearn: 0.5895708\ttotal: 1m 45s\tremaining: 2m 22s\n255:\tlearn: 0.5893569\ttotal: 1m 46s\tremaining: 2m 22s\n256:\tlearn: 0.5882930\ttotal: 1m 46s\tremaining: 2m 22s\n257:\tlearn: 0.5870137\ttotal: 1m 46s\tremaining: 2m 21s\n258:\tlearn: 0.5842470\ttotal: 1m 47s\tremaining: 2m 21s\n259:\tlearn: 0.5831467\ttotal: 1m 47s\tremaining: 2m 20s\n260:\tlearn: 0.5817943\ttotal: 1m 48s\tremaining: 2m 20s\n261:\tlearn: 0.5771525\ttotal: 1m 48s\tremaining: 2m 20s\n262:\tlearn: 0.5752960\ttotal: 1m 48s\tremaining: 2m 19s\n263:\tlearn: 0.5749652\ttotal: 1m 49s\tremaining: 2m 19s\n264:\tlearn: 0.5747242\ttotal: 1m 49s\tremaining: 2m 18s\n265:\tlearn: 0.5741101\ttotal: 1m 50s\tremaining: 2m 18s\n266:\tlearn: 0.5719300\ttotal: 1m 50s\tremaining: 2m 17s\n267:\tlearn: 0.5706744\ttotal: 1m 50s\tremaining: 2m 17s\n268:\tlearn: 0.5703367\ttotal: 1m 51s\tremaining: 2m 17s\n269:\tlearn: 0.5692433\ttotal: 1m 51s\tremaining: 2m 16s\n270:\tlearn: 0.5686693\ttotal: 1m 52s\tremaining: 2m 16s\n271:\tlearn: 0.5676087\ttotal: 1m 52s\tremaining: 2m 15s\n272:\tlearn: 0.5661673\ttotal: 1m 53s\tremaining: 2m 15s\n273:\tlearn: 0.5658852\ttotal: 1m 53s\tremaining: 2m 14s\n274:\tlearn: 0.5650526\ttotal: 1m 53s\tremaining: 2m 14s\n275:\tlearn: 0.5639660\ttotal: 1m 54s\tremaining: 2m 14s\n276:\tlearn: 0.5631478\ttotal: 1m 54s\tremaining: 2m 13s\n277:\tlearn: 0.5620572\ttotal: 1m 55s\tremaining: 2m 13s\n278:\tlearn: 0.5594240\ttotal: 1m 55s\tremaining: 2m 12s\n279:\tlearn: 0.5582742\ttotal: 1m 55s\tremaining: 2m 12s\n280:\tlearn: 0.5553688\ttotal: 1m 56s\tremaining: 2m 12s\n281:\tlearn: 0.5526931\ttotal: 1m 56s\tremaining: 2m 11s\n282:\tlearn: 0.5519017\ttotal: 1m 57s\tremaining: 2m 11s\n283:\tlearn: 0.5514242\ttotal: 1m 57s\tremaining: 2m 10s\n284:\tlearn: 0.5506054\ttotal: 1m 57s\tremaining: 2m 10s\n285:\tlearn: 0.5479912\ttotal: 1m 58s\tremaining: 2m 9s\n286:\tlearn: 0.5473304\ttotal: 1m 58s\tremaining: 2m 9s\n287:\tlearn: 0.5465587\ttotal: 1m 59s\tremaining: 2m 9s\n288:\tlearn: 0.5457895\ttotal: 1m 59s\tremaining: 2m 8s\n289:\tlearn: 0.5425642\ttotal: 2m\tremaining: 2m 8s\n290:\tlearn: 0.5408927\ttotal: 2m\tremaining: 2m 7s\n291:\tlearn: 0.5406338\ttotal: 2m\tremaining: 2m 7s\n292:\tlearn: 0.5398340\ttotal: 2m 1s\tremaining: 2m 7s\n293:\tlearn: 0.5342892\ttotal: 2m 1s\tremaining: 2m 6s\n294:\tlearn: 0.5341542\ttotal: 2m 2s\tremaining: 2m 6s\n295:\tlearn: 0.5309893\ttotal: 2m 2s\tremaining: 2m 5s\n296:\tlearn: 0.5298474\ttotal: 2m 2s\tremaining: 2m 5s\n297:\tlearn: 0.5290362\ttotal: 2m 3s\tremaining: 2m 5s\n298:\tlearn: 0.5281766\ttotal: 2m 3s\tremaining: 2m 4s\n299:\tlearn: 0.5260477\ttotal: 2m 4s\tremaining: 2m 4s\n300:\tlearn: 0.5234284\ttotal: 2m 4s\tremaining: 2m 3s\n301:\tlearn: 0.5221480\ttotal: 2m 5s\tremaining: 2m 3s\n302:\tlearn: 0.5205134\ttotal: 2m 5s\tremaining: 2m 2s\n303:\tlearn: 0.5196931\ttotal: 2m 5s\tremaining: 2m 2s\n304:\tlearn: 0.5186787\ttotal: 2m 6s\tremaining: 2m 2s\n305:\tlearn: 0.5169383\ttotal: 2m 6s\tremaining: 2m 1s\n306:\tlearn: 0.5157849\ttotal: 2m 7s\tremaining: 2m 1s\n307:\tlearn: 0.5151798\ttotal: 2m 7s\tremaining: 2m\n308:\tlearn: 0.5116057\ttotal: 2m 7s\tremaining: 2m\n309:\tlearn: 0.5098999\ttotal: 2m 8s\tremaining: 2m\n310:\tlearn: 0.5081929\ttotal: 2m 8s\tremaining: 1m 59s\n311:\tlearn: 0.5074090\ttotal: 2m 9s\tremaining: 1m 59s\n312:\tlearn: 0.5067854\ttotal: 2m 9s\tremaining: 1m 58s\n313:\tlearn: 0.5048971\ttotal: 2m 10s\tremaining: 1m 58s\n314:\tlearn: 0.5039371\ttotal: 2m 10s\tremaining: 1m 58s\n315:\tlearn: 0.5035909\ttotal: 2m 10s\tremaining: 1m 57s\n316:\tlearn: 0.5012632\ttotal: 2m 11s\tremaining: 1m 57s\n317:\tlearn: 0.4989103\ttotal: 2m 11s\tremaining: 1m 56s\n318:\tlearn: 0.4977331\ttotal: 2m 12s\tremaining: 1m 56s\n319:\tlearn: 0.4970392\ttotal: 2m 12s\tremaining: 1m 55s\n320:\tlearn: 0.4969003\ttotal: 2m 12s\tremaining: 1m 55s\n321:\tlearn: 0.4952065\ttotal: 2m 13s\tremaining: 1m 55s\n322:\tlearn: 0.4945195\ttotal: 2m 13s\tremaining: 1m 54s\n323:\tlearn: 0.4940703\ttotal: 2m 14s\tremaining: 1m 54s\n324:\tlearn: 0.4919424\ttotal: 2m 14s\tremaining: 1m 53s\n325:\tlearn: 0.4914073\ttotal: 2m 14s\tremaining: 1m 53s\n326:\tlearn: 0.4901484\ttotal: 2m 15s\tremaining: 1m 53s\n327:\tlearn: 0.4897876\ttotal: 2m 15s\tremaining: 1m 52s\n328:\tlearn: 0.4894165\ttotal: 2m 16s\tremaining: 1m 52s\n329:\tlearn: 0.4874237\ttotal: 2m 16s\tremaining: 1m 51s\n330:\tlearn: 0.4870600\ttotal: 2m 17s\tremaining: 1m 51s\n331:\tlearn: 0.4823821\ttotal: 2m 17s\tremaining: 1m 50s\n332:\tlearn: 0.4821944\ttotal: 2m 17s\tremaining: 1m 50s\n333:\tlearn: 0.4818681\ttotal: 2m 18s\tremaining: 1m 50s\n334:\tlearn: 0.4813525\ttotal: 2m 18s\tremaining: 1m 49s\n335:\tlearn: 0.4812806\ttotal: 2m 19s\tremaining: 1m 49s\n336:\tlearn: 0.4808406\ttotal: 2m 19s\tremaining: 1m 48s\n337:\tlearn: 0.4801665\ttotal: 2m 19s\tremaining: 1m 48s\n338:\tlearn: 0.4795571\ttotal: 2m 20s\tremaining: 1m 48s\n339:\tlearn: 0.4789485\ttotal: 2m 20s\tremaining: 1m 47s\n340:\tlearn: 0.4780481\ttotal: 2m 21s\tremaining: 1m 47s\n341:\tlearn: 0.4774176\ttotal: 2m 21s\tremaining: 1m 46s\n342:\tlearn: 0.4770889\ttotal: 2m 21s\tremaining: 1m 46s\n343:\tlearn: 0.4756898\ttotal: 2m 22s\tremaining: 1m 45s\n344:\tlearn: 0.4751642\ttotal: 2m 22s\tremaining: 1m 45s\n345:\tlearn: 0.4747897\ttotal: 2m 23s\tremaining: 1m 45s\n346:\tlearn: 0.4730598\ttotal: 2m 23s\tremaining: 1m 44s\n347:\tlearn: 0.4715699\ttotal: 2m 24s\tremaining: 1m 44s\n348:\tlearn: 0.4701326\ttotal: 2m 24s\tremaining: 1m 43s\n349:\tlearn: 0.4697643\ttotal: 2m 24s\tremaining: 1m 43s\n350:\tlearn: 0.4680954\ttotal: 2m 25s\tremaining: 1m 43s\n351:\tlearn: 0.4676461\ttotal: 2m 25s\tremaining: 1m 42s\n352:\tlearn: 0.4671658\ttotal: 2m 26s\tremaining: 1m 42s\n353:\tlearn: 0.4668063\ttotal: 2m 26s\tremaining: 1m 41s\n354:\tlearn: 0.4652917\ttotal: 2m 26s\tremaining: 1m 41s\n355:\tlearn: 0.4651157\ttotal: 2m 27s\tremaining: 1m 40s\n356:\tlearn: 0.4646201\ttotal: 2m 27s\tremaining: 1m 40s\n357:\tlearn: 0.4639961\ttotal: 2m 28s\tremaining: 1m 40s\n358:\tlearn: 0.4636363\ttotal: 2m 28s\tremaining: 1m 39s\n359:\tlearn: 0.4631216\ttotal: 2m 28s\tremaining: 1m 39s\n360:\tlearn: 0.4614796\ttotal: 2m 29s\tremaining: 1m 38s\n361:\tlearn: 0.4612668\ttotal: 2m 29s\tremaining: 1m 38s\n362:\tlearn: 0.4609286\ttotal: 2m 30s\tremaining: 1m 38s\n363:\tlearn: 0.4605617\ttotal: 2m 30s\tremaining: 1m 37s\n364:\tlearn: 0.4596303\ttotal: 2m 31s\tremaining: 1m 37s\n365:\tlearn: 0.4593763\ttotal: 2m 31s\tremaining: 1m 36s\n366:\tlearn: 0.4587647\ttotal: 2m 31s\tremaining: 1m 36s\n367:\tlearn: 0.4576831\ttotal: 2m 32s\tremaining: 1m 35s\n368:\tlearn: 0.4574275\ttotal: 2m 32s\tremaining: 1m 35s\n369:\tlearn: 0.4542626\ttotal: 2m 33s\tremaining: 1m 35s\n370:\tlearn: 0.4530335\ttotal: 2m 33s\tremaining: 1m 34s\n371:\tlearn: 0.4516876\ttotal: 2m 33s\tremaining: 1m 34s\n372:\tlearn: 0.4497882\ttotal: 2m 34s\tremaining: 1m 33s\n373:\tlearn: 0.4494141\ttotal: 2m 34s\tremaining: 1m 33s\n374:\tlearn: 0.4491351\ttotal: 2m 35s\tremaining: 1m 33s\n375:\tlearn: 0.4488488\ttotal: 2m 35s\tremaining: 1m 32s\n376:\tlearn: 0.4483145\ttotal: 2m 35s\tremaining: 1m 32s\n377:\tlearn: 0.4482153\ttotal: 2m 36s\tremaining: 1m 31s\n378:\tlearn: 0.4469119\ttotal: 2m 36s\tremaining: 1m 31s\n379:\tlearn: 0.4467781\ttotal: 2m 37s\tremaining: 1m 31s\n380:\tlearn: 0.4465096\ttotal: 2m 37s\tremaining: 1m 30s\n381:\tlearn: 0.4459613\ttotal: 2m 38s\tremaining: 1m 30s\n382:\tlearn: 0.4451937\ttotal: 2m 38s\tremaining: 1m 29s\n383:\tlearn: 0.4448684\ttotal: 2m 38s\tremaining: 1m 29s\n384:\tlearn: 0.4441235\ttotal: 2m 39s\tremaining: 1m 28s\n385:\tlearn: 0.4433018\ttotal: 2m 39s\tremaining: 1m 28s\n386:\tlearn: 0.4430876\ttotal: 2m 40s\tremaining: 1m 28s\n387:\tlearn: 0.4419751\ttotal: 2m 40s\tremaining: 1m 27s\n388:\tlearn: 0.4412217\ttotal: 2m 40s\tremaining: 1m 27s\n389:\tlearn: 0.4404451\ttotal: 2m 41s\tremaining: 1m 26s\n390:\tlearn: 0.4390899\ttotal: 2m 41s\tremaining: 1m 26s\n391:\tlearn: 0.4389696\ttotal: 2m 42s\tremaining: 1m 26s\n392:\tlearn: 0.4385415\ttotal: 2m 42s\tremaining: 1m 25s\n393:\tlearn: 0.4383885\ttotal: 2m 42s\tremaining: 1m 25s\n394:\tlearn: 0.4382260\ttotal: 2m 43s\tremaining: 1m 24s\n395:\tlearn: 0.4379351\ttotal: 2m 43s\tremaining: 1m 24s\n396:\tlearn: 0.4377428\ttotal: 2m 44s\tremaining: 1m 23s\n397:\tlearn: 0.4367751\ttotal: 2m 44s\tremaining: 1m 23s\n398:\tlearn: 0.4362416\ttotal: 2m 45s\tremaining: 1m 23s\n399:\tlearn: 0.4360998\ttotal: 2m 45s\tremaining: 1m 22s\n400:\tlearn: 0.4352866\ttotal: 2m 45s\tremaining: 1m 22s\n401:\tlearn: 0.4346154\ttotal: 2m 46s\tremaining: 1m 21s\n402:\tlearn: 0.4344306\ttotal: 2m 46s\tremaining: 1m 21s\n403:\tlearn: 0.4341834\ttotal: 2m 47s\tremaining: 1m 21s\n404:\tlearn: 0.4339654\ttotal: 2m 47s\tremaining: 1m 20s\n405:\tlearn: 0.4322808\ttotal: 2m 47s\tremaining: 1m 20s\n406:\tlearn: 0.4322266\ttotal: 2m 48s\tremaining: 1m 19s\n407:\tlearn: 0.4311908\ttotal: 2m 48s\tremaining: 1m 19s\n408:\tlearn: 0.4309494\ttotal: 2m 49s\tremaining: 1m 18s\n409:\tlearn: 0.4303149\ttotal: 2m 49s\tremaining: 1m 18s\n410:\tlearn: 0.4301763\ttotal: 2m 49s\tremaining: 1m 18s\n411:\tlearn: 0.4298577\ttotal: 2m 50s\tremaining: 1m 17s\n412:\tlearn: 0.4294257\ttotal: 2m 50s\tremaining: 1m 17s\n413:\tlearn: 0.4289764\ttotal: 2m 51s\tremaining: 1m 16s\n414:\tlearn: 0.4270018\ttotal: 2m 51s\tremaining: 1m 16s\n415:\tlearn: 0.4268407\ttotal: 2m 51s\tremaining: 1m 16s\n416:\tlearn: 0.4265258\ttotal: 2m 52s\tremaining: 1m 15s\n417:\tlearn: 0.4263950\ttotal: 2m 52s\tremaining: 1m 15s\n418:\tlearn: 0.4261841\ttotal: 2m 53s\tremaining: 1m 14s\n419:\tlearn: 0.4256562\ttotal: 2m 53s\tremaining: 1m 14s\n420:\tlearn: 0.4233539\ttotal: 2m 54s\tremaining: 1m 14s\n421:\tlearn: 0.4217384\ttotal: 2m 54s\tremaining: 1m 13s\n422:\tlearn: 0.4214213\ttotal: 2m 54s\tremaining: 1m 13s\n423:\tlearn: 0.4210567\ttotal: 2m 55s\tremaining: 1m 12s\n424:\tlearn: 0.4201703\ttotal: 2m 55s\tremaining: 1m 12s\n425:\tlearn: 0.4196152\ttotal: 2m 56s\tremaining: 1m 11s\n426:\tlearn: 0.4184239\ttotal: 2m 56s\tremaining: 1m 11s\n427:\tlearn: 0.4159723\ttotal: 2m 57s\tremaining: 1m 11s\n428:\tlearn: 0.4155293\ttotal: 2m 57s\tremaining: 1m 10s\n429:\tlearn: 0.4153712\ttotal: 2m 57s\tremaining: 1m 10s\n430:\tlearn: 0.4148895\ttotal: 2m 58s\tremaining: 1m 9s\n431:\tlearn: 0.4141378\ttotal: 2m 58s\tremaining: 1m 9s\n432:\tlearn: 0.4134395\ttotal: 2m 59s\tremaining: 1m 9s\n433:\tlearn: 0.4132448\ttotal: 2m 59s\tremaining: 1m 8s\n434:\tlearn: 0.4131419\ttotal: 2m 59s\tremaining: 1m 8s\n435:\tlearn: 0.4127242\ttotal: 3m\tremaining: 1m 7s\n436:\tlearn: 0.4120046\ttotal: 3m\tremaining: 1m 7s\n437:\tlearn: 0.4117417\ttotal: 3m 1s\tremaining: 1m 6s\n438:\tlearn: 0.4115522\ttotal: 3m 1s\tremaining: 1m 6s\n439:\tlearn: 0.4091896\ttotal: 3m 1s\tremaining: 1m 6s\n440:\tlearn: 0.4084543\ttotal: 3m 2s\tremaining: 1m 5s\n441:\tlearn: 0.4082924\ttotal: 3m 2s\tremaining: 1m 5s\n442:\tlearn: 0.4079491\ttotal: 3m 3s\tremaining: 1m 4s\n443:\tlearn: 0.4069006\ttotal: 3m 3s\tremaining: 1m 4s\n444:\tlearn: 0.4068228\ttotal: 3m 3s\tremaining: 1m 4s\n445:\tlearn: 0.4065065\ttotal: 3m 4s\tremaining: 1m 3s\n446:\tlearn: 0.4063229\ttotal: 3m 4s\tremaining: 1m 3s\n447:\tlearn: 0.4061426\ttotal: 3m 5s\tremaining: 1m 2s\n448:\tlearn: 0.4057318\ttotal: 3m 5s\tremaining: 1m 2s\n449:\tlearn: 0.4056650\ttotal: 3m 6s\tremaining: 1m 2s\n450:\tlearn: 0.4054407\ttotal: 3m 6s\tremaining: 1m 1s\n451:\tlearn: 0.4053187\ttotal: 3m 6s\tremaining: 1m 1s\n452:\tlearn: 0.4051827\ttotal: 3m 7s\tremaining: 1m\n453:\tlearn: 0.4043047\ttotal: 3m 7s\tremaining: 1m\n454:\tlearn: 0.4042115\ttotal: 3m 8s\tremaining: 59.9s\n455:\tlearn: 0.4041564\ttotal: 3m 8s\tremaining: 59.5s\n456:\tlearn: 0.4039692\ttotal: 3m 8s\tremaining: 59.1s\n457:\tlearn: 0.4028530\ttotal: 3m 9s\tremaining: 58.7s\n458:\tlearn: 0.4023710\ttotal: 3m 9s\tremaining: 58.3s\n459:\tlearn: 0.4009733\ttotal: 3m 10s\tremaining: 57.9s\n460:\tlearn: 0.4008487\ttotal: 3m 10s\tremaining: 57.5s\n461:\tlearn: 0.4000698\ttotal: 3m 10s\tremaining: 57s\n462:\tlearn: 0.3986937\ttotal: 3m 11s\tremaining: 56.6s\n463:\tlearn: 0.3979651\ttotal: 3m 11s\tremaining: 56.2s\n464:\tlearn: 0.3978591\ttotal: 3m 12s\tremaining: 55.8s\n465:\tlearn: 0.3978201\ttotal: 3m 12s\tremaining: 55.4s\n466:\tlearn: 0.3972311\ttotal: 3m 13s\tremaining: 55s\n467:\tlearn: 0.3970606\ttotal: 3m 13s\tremaining: 54.6s\n468:\tlearn: 0.3955035\ttotal: 3m 13s\tremaining: 54.1s\n469:\tlearn: 0.3954261\ttotal: 3m 14s\tremaining: 53.7s\n470:\tlearn: 0.3944357\ttotal: 3m 14s\tremaining: 53.3s\n471:\tlearn: 0.3932265\ttotal: 3m 15s\tremaining: 52.9s\n472:\tlearn: 0.3930005\ttotal: 3m 15s\tremaining: 52.5s\n473:\tlearn: 0.3927365\ttotal: 3m 15s\tremaining: 52.1s\n474:\tlearn: 0.3924416\ttotal: 3m 16s\tremaining: 51.7s\n475:\tlearn: 0.3912156\ttotal: 3m 16s\tremaining: 51.3s\n476:\tlearn: 0.3910850\ttotal: 3m 17s\tremaining: 50.8s\n477:\tlearn: 0.3907465\ttotal: 3m 17s\tremaining: 50.4s\n478:\tlearn: 0.3894410\ttotal: 3m 17s\tremaining: 50s\n479:\tlearn: 0.3892335\ttotal: 3m 18s\tremaining: 49.6s\n480:\tlearn: 0.3877580\ttotal: 3m 18s\tremaining: 49.2s\n481:\tlearn: 0.3875411\ttotal: 3m 19s\tremaining: 48.8s\n482:\tlearn: 0.3872759\ttotal: 3m 19s\tremaining: 48.4s\n483:\tlearn: 0.3870998\ttotal: 3m 20s\tremaining: 47.9s\n484:\tlearn: 0.3870629\ttotal: 3m 20s\tremaining: 47.5s\n485:\tlearn: 0.3869600\ttotal: 3m 20s\tremaining: 47.1s\n486:\tlearn: 0.3867935\ttotal: 3m 21s\tremaining: 46.7s\n487:\tlearn: 0.3854916\ttotal: 3m 21s\tremaining: 46.3s\n488:\tlearn: 0.3846691\ttotal: 3m 22s\tremaining: 45.9s\n489:\tlearn: 0.3844225\ttotal: 3m 22s\tremaining: 45.5s\n490:\tlearn: 0.3838671\ttotal: 3m 22s\tremaining: 45s\n491:\tlearn: 0.3830983\ttotal: 3m 23s\tremaining: 44.6s\n492:\tlearn: 0.3826285\ttotal: 3m 23s\tremaining: 44.2s\n493:\tlearn: 0.3825176\ttotal: 3m 24s\tremaining: 43.8s\n494:\tlearn: 0.3823249\ttotal: 3m 24s\tremaining: 43.4s\n495:\tlearn: 0.3819538\ttotal: 3m 24s\tremaining: 43s\n496:\tlearn: 0.3815599\ttotal: 3m 25s\tremaining: 42.6s\n497:\tlearn: 0.3799210\ttotal: 3m 25s\tremaining: 42.1s\n498:\tlearn: 0.3797226\ttotal: 3m 26s\tremaining: 41.7s\n499:\tlearn: 0.3773075\ttotal: 3m 26s\tremaining: 41.3s\n500:\tlearn: 0.3770966\ttotal: 3m 27s\tremaining: 40.9s\n501:\tlearn: 0.3769824\ttotal: 3m 27s\tremaining: 40.5s\n502:\tlearn: 0.3765989\ttotal: 3m 27s\tremaining: 40.1s\n503:\tlearn: 0.3765599\ttotal: 3m 28s\tremaining: 39.7s\n504:\tlearn: 0.3754988\ttotal: 3m 28s\tremaining: 39.3s\n505:\tlearn: 0.3740049\ttotal: 3m 29s\tremaining: 38.8s\n506:\tlearn: 0.3737837\ttotal: 3m 29s\tremaining: 38.4s\n507:\tlearn: 0.3737086\ttotal: 3m 29s\tremaining: 38s\n508:\tlearn: 0.3729445\ttotal: 3m 30s\tremaining: 37.6s\n509:\tlearn: 0.3727686\ttotal: 3m 30s\tremaining: 37.2s\n510:\tlearn: 0.3724061\ttotal: 3m 31s\tremaining: 36.8s\n511:\tlearn: 0.3721674\ttotal: 3m 31s\tremaining: 36.4s\n512:\tlearn: 0.3717637\ttotal: 3m 31s\tremaining: 35.9s\n513:\tlearn: 0.3715981\ttotal: 3m 32s\tremaining: 35.5s\n514:\tlearn: 0.3713501\ttotal: 3m 32s\tremaining: 35.1s\n515:\tlearn: 0.3709832\ttotal: 3m 33s\tremaining: 34.7s\n516:\tlearn: 0.3695514\ttotal: 3m 33s\tremaining: 34.3s\n517:\tlearn: 0.3694688\ttotal: 3m 34s\tremaining: 33.9s\n518:\tlearn: 0.3687837\ttotal: 3m 34s\tremaining: 33.5s\n519:\tlearn: 0.3672530\ttotal: 3m 34s\tremaining: 33.1s\n520:\tlearn: 0.3668544\ttotal: 3m 35s\tremaining: 32.6s\n521:\tlearn: 0.3662394\ttotal: 3m 35s\tremaining: 32.2s\n522:\tlearn: 0.3655948\ttotal: 3m 36s\tremaining: 31.8s\n523:\tlearn: 0.3654613\ttotal: 3m 36s\tremaining: 31.4s\n524:\tlearn: 0.3650128\ttotal: 3m 36s\tremaining: 31s\n525:\tlearn: 0.3646857\ttotal: 3m 37s\tremaining: 30.6s\n526:\tlearn: 0.3645763\ttotal: 3m 37s\tremaining: 30.2s\n527:\tlearn: 0.3638036\ttotal: 3m 38s\tremaining: 29.7s\n528:\tlearn: 0.3630912\ttotal: 3m 38s\tremaining: 29.3s\n529:\tlearn: 0.3629372\ttotal: 3m 38s\tremaining: 28.9s\n530:\tlearn: 0.3628511\ttotal: 3m 39s\tremaining: 28.5s\n531:\tlearn: 0.3627980\ttotal: 3m 39s\tremaining: 28.1s\n532:\tlearn: 0.3622214\ttotal: 3m 40s\tremaining: 27.7s\n533:\tlearn: 0.3619421\ttotal: 3m 40s\tremaining: 27.3s\n534:\tlearn: 0.3605071\ttotal: 3m 41s\tremaining: 26.9s\n535:\tlearn: 0.3590366\ttotal: 3m 41s\tremaining: 26.4s\n536:\tlearn: 0.3588967\ttotal: 3m 41s\tremaining: 26s\n537:\tlearn: 0.3579559\ttotal: 3m 42s\tremaining: 25.6s\n538:\tlearn: 0.3569281\ttotal: 3m 42s\tremaining: 25.2s\n539:\tlearn: 0.3562646\ttotal: 3m 43s\tremaining: 24.8s\n540:\tlearn: 0.3561816\ttotal: 3m 43s\tremaining: 24.4s\n541:\tlearn: 0.3559918\ttotal: 3m 43s\tremaining: 24s\n542:\tlearn: 0.3558923\ttotal: 3m 44s\tremaining: 23.6s\n543:\tlearn: 0.3552547\ttotal: 3m 44s\tremaining: 23.1s\n544:\tlearn: 0.3550726\ttotal: 3m 45s\tremaining: 22.7s\n545:\tlearn: 0.3545369\ttotal: 3m 45s\tremaining: 22.3s\n546:\tlearn: 0.3543400\ttotal: 3m 46s\tremaining: 21.9s\n547:\tlearn: 0.3535210\ttotal: 3m 46s\tremaining: 21.5s\n548:\tlearn: 0.3532088\ttotal: 3m 46s\tremaining: 21.1s\n549:\tlearn: 0.3529641\ttotal: 3m 47s\tremaining: 20.7s\n550:\tlearn: 0.3524838\ttotal: 3m 47s\tremaining: 20.3s\n551:\tlearn: 0.3524030\ttotal: 3m 48s\tremaining: 19.8s\n552:\tlearn: 0.3522971\ttotal: 3m 48s\tremaining: 19.4s\n553:\tlearn: 0.3521170\ttotal: 3m 48s\tremaining: 19s\n554:\tlearn: 0.3520561\ttotal: 3m 49s\tremaining: 18.6s\n555:\tlearn: 0.3515788\ttotal: 3m 49s\tremaining: 18.2s\n556:\tlearn: 0.3515511\ttotal: 3m 50s\tremaining: 17.8s\n557:\tlearn: 0.3507791\ttotal: 3m 50s\tremaining: 17.4s\n558:\tlearn: 0.3506078\ttotal: 3m 50s\tremaining: 16.9s\n559:\tlearn: 0.3505447\ttotal: 3m 51s\tremaining: 16.5s\n560:\tlearn: 0.3501177\ttotal: 3m 51s\tremaining: 16.1s\n561:\tlearn: 0.3497293\ttotal: 3m 52s\tremaining: 15.7s\n562:\tlearn: 0.3491961\ttotal: 3m 52s\tremaining: 15.3s\n563:\tlearn: 0.3489289\ttotal: 3m 53s\tremaining: 14.9s\n564:\tlearn: 0.3486432\ttotal: 3m 53s\tremaining: 14.5s\n565:\tlearn: 0.3484918\ttotal: 3m 53s\tremaining: 14s\n566:\tlearn: 0.3479713\ttotal: 3m 54s\tremaining: 13.6s\n567:\tlearn: 0.3476075\ttotal: 3m 54s\tremaining: 13.2s\n568:\tlearn: 0.3470536\ttotal: 3m 55s\tremaining: 12.8s\n569:\tlearn: 0.3468290\ttotal: 3m 55s\tremaining: 12.4s\n570:\tlearn: 0.3467670\ttotal: 3m 55s\tremaining: 12s\n571:\tlearn: 0.3463876\ttotal: 3m 56s\tremaining: 11.6s\n572:\tlearn: 0.3461972\ttotal: 3m 56s\tremaining: 11.2s\n573:\tlearn: 0.3447959\ttotal: 3m 57s\tremaining: 10.7s\n574:\tlearn: 0.3445967\ttotal: 3m 57s\tremaining: 10.3s\n575:\tlearn: 0.3442978\ttotal: 3m 57s\tremaining: 9.91s\n576:\tlearn: 0.3430185\ttotal: 3m 58s\tremaining: 9.5s\n577:\tlearn: 0.3422883\ttotal: 3m 58s\tremaining: 9.09s\n578:\tlearn: 0.3420880\ttotal: 3m 59s\tremaining: 8.68s\n579:\tlearn: 0.3412275\ttotal: 3m 59s\tremaining: 8.26s\n580:\tlearn: 0.3399256\ttotal: 4m\tremaining: 7.85s\n581:\tlearn: 0.3398300\ttotal: 4m\tremaining: 7.44s\n582:\tlearn: 0.3396044\ttotal: 4m\tremaining: 7.02s\n583:\tlearn: 0.3395244\ttotal: 4m 1s\tremaining: 6.61s\n584:\tlearn: 0.3392522\ttotal: 4m 1s\tremaining: 6.2s\n585:\tlearn: 0.3390438\ttotal: 4m 2s\tremaining: 5.78s\n586:\tlearn: 0.3381880\ttotal: 4m 2s\tremaining: 5.37s\n587:\tlearn: 0.3381330\ttotal: 4m 2s\tremaining: 4.96s\n588:\tlearn: 0.3380380\ttotal: 4m 3s\tremaining: 4.54s\n589:\tlearn: 0.3374438\ttotal: 4m 3s\tremaining: 4.13s\n590:\tlearn: 0.3373935\ttotal: 4m 4s\tremaining: 3.72s\n591:\tlearn: 0.3372769\ttotal: 4m 4s\tremaining: 3.31s\n592:\tlearn: 0.3371485\ttotal: 4m 4s\tremaining: 2.89s\n593:\tlearn: 0.3369599\ttotal: 4m 5s\tremaining: 2.48s\n594:\tlearn: 0.3368966\ttotal: 4m 5s\tremaining: 2.06s\n595:\tlearn: 0.3366342\ttotal: 4m 6s\tremaining: 1.65s\n596:\tlearn: 0.3365027\ttotal: 4m 6s\tremaining: 1.24s\n597:\tlearn: 0.3361674\ttotal: 4m 7s\tremaining: 826ms\n598:\tlearn: 0.3361104\ttotal: 4m 7s\tremaining: 413ms\n599:\tlearn: 0.3356106\ttotal: 4m 7s\tremaining: 0us\ncat_fit_done\nmodel_ready\n0:\tlearn: 2.2506260\ttotal: 209ms\tremaining: 2m 5s\n1:\tlearn: 2.1589307\ttotal: 411ms\tremaining: 2m 2s\n2:\tlearn: 2.0476540\ttotal: 612ms\tremaining: 2m 1s\n3:\tlearn: 1.9516502\ttotal: 819ms\tremaining: 2m 1s\n4:\tlearn: 1.8809358\ttotal: 1.03s\tremaining: 2m 2s\n5:\tlearn: 1.8011935\ttotal: 1.23s\tremaining: 2m 2s\n6:\tlearn: 1.7348468\ttotal: 1.44s\tremaining: 2m 1s\n7:\tlearn: 1.6721042\ttotal: 1.64s\tremaining: 2m 1s\n8:\tlearn: 1.6194923\ttotal: 1.84s\tremaining: 2m 1s\n9:\tlearn: 1.5596671\ttotal: 2.05s\tremaining: 2m\n10:\tlearn: 1.5199248\ttotal: 2.25s\tremaining: 2m\n11:\tlearn: 1.4717071\ttotal: 2.45s\tremaining: 2m\n12:\tlearn: 1.4256280\ttotal: 2.65s\tremaining: 1m 59s\n13:\tlearn: 1.3851558\ttotal: 2.86s\tremaining: 1m 59s\n14:\tlearn: 1.3347288\ttotal: 3.06s\tremaining: 1m 59s\n15:\tlearn: 1.3169267\ttotal: 3.26s\tremaining: 1m 59s\n16:\tlearn: 1.2746216\ttotal: 3.47s\tremaining: 1m 58s\n17:\tlearn: 1.2409079\ttotal: 3.69s\tremaining: 1m 59s\n18:\tlearn: 1.2050129\ttotal: 3.9s\tremaining: 1m 59s\n19:\tlearn: 1.1876706\ttotal: 4.12s\tremaining: 1m 59s\n20:\tlearn: 1.1496206\ttotal: 4.33s\tremaining: 1m 59s\n21:\tlearn: 1.1204288\ttotal: 4.54s\tremaining: 1m 59s\n22:\tlearn: 1.0955550\ttotal: 4.75s\tremaining: 1m 59s\n23:\tlearn: 1.0698794\ttotal: 4.95s\tremaining: 1m 58s\n24:\tlearn: 1.0488125\ttotal: 5.16s\tremaining: 1m 58s\n25:\tlearn: 1.0301973\ttotal: 5.36s\tremaining: 1m 58s\n26:\tlearn: 1.0064837\ttotal: 5.56s\tremaining: 1m 58s\n27:\tlearn: 0.9886198\ttotal: 5.77s\tremaining: 1m 57s\n28:\tlearn: 0.9682630\ttotal: 5.97s\tremaining: 1m 57s\n29:\tlearn: 0.9526430\ttotal: 6.17s\tremaining: 1m 57s\n30:\tlearn: 0.9432175\ttotal: 6.37s\tremaining: 1m 56s\n31:\tlearn: 0.9236934\ttotal: 6.57s\tremaining: 1m 56s\n32:\tlearn: 0.9054769\ttotal: 6.78s\tremaining: 1m 56s\n33:\tlearn: 0.8843354\ttotal: 6.98s\tremaining: 1m 56s\n34:\tlearn: 0.8742535\ttotal: 7.18s\tremaining: 1m 55s\n35:\tlearn: 0.8649240\ttotal: 7.38s\tremaining: 1m 55s\n36:\tlearn: 0.8552210\ttotal: 7.58s\tremaining: 1m 55s\n37:\tlearn: 0.8376556\ttotal: 7.79s\tremaining: 1m 55s\n38:\tlearn: 0.8241692\ttotal: 7.99s\tremaining: 1m 54s\n39:\tlearn: 0.8083164\ttotal: 8.19s\tremaining: 1m 54s\n40:\tlearn: 0.8028887\ttotal: 8.39s\tremaining: 1m 54s\n41:\tlearn: 0.7935474\ttotal: 8.6s\tremaining: 1m 54s\n42:\tlearn: 0.7778102\ttotal: 8.8s\tremaining: 1m 54s\n43:\tlearn: 0.7689594\ttotal: 9s\tremaining: 1m 53s\n44:\tlearn: 0.7558755\ttotal: 9.21s\tremaining: 1m 53s\n45:\tlearn: 0.7408922\ttotal: 9.41s\tremaining: 1m 53s\n46:\tlearn: 0.7288068\ttotal: 9.61s\tremaining: 1m 53s\n47:\tlearn: 0.7193680\ttotal: 9.81s\tremaining: 1m 52s\n48:\tlearn: 0.7135901\ttotal: 10s\tremaining: 1m 52s\n49:\tlearn: 0.7007677\ttotal: 10.2s\tremaining: 1m 52s\n50:\tlearn: 0.6912305\ttotal: 10.4s\tremaining: 1m 52s\n51:\tlearn: 0.6807756\ttotal: 10.6s\tremaining: 1m 52s\n52:\tlearn: 0.6674005\ttotal: 10.8s\tremaining: 1m 51s\n53:\tlearn: 0.6551355\ttotal: 11s\tremaining: 1m 51s\n54:\tlearn: 0.6427054\ttotal: 11.2s\tremaining: 1m 51s\n55:\tlearn: 0.6347769\ttotal: 11.4s\tremaining: 1m 51s\n56:\tlearn: 0.6260493\ttotal: 11.6s\tremaining: 1m 50s\n57:\tlearn: 0.6157610\ttotal: 11.9s\tremaining: 1m 50s\n58:\tlearn: 0.6119758\ttotal: 12.1s\tremaining: 1m 50s\n59:\tlearn: 0.6066272\ttotal: 12.3s\tremaining: 1m 50s\n60:\tlearn: 0.6017512\ttotal: 12.5s\tremaining: 1m 50s\n61:\tlearn: 0.5987131\ttotal: 12.7s\tremaining: 1m 49s\n62:\tlearn: 0.5903768\ttotal: 12.9s\tremaining: 1m 49s\n63:\tlearn: 0.5803322\ttotal: 13.1s\tremaining: 1m 49s\n64:\tlearn: 0.5730808\ttotal: 13.3s\tremaining: 1m 49s\n65:\tlearn: 0.5669820\ttotal: 13.5s\tremaining: 1m 49s\n66:\tlearn: 0.5579924\ttotal: 13.7s\tremaining: 1m 48s\n67:\tlearn: 0.5526454\ttotal: 13.9s\tremaining: 1m 48s\n68:\tlearn: 0.5416520\ttotal: 14.1s\tremaining: 1m 48s\n69:\tlearn: 0.5385475\ttotal: 14.3s\tremaining: 1m 48s\n70:\tlearn: 0.5351955\ttotal: 14.5s\tremaining: 1m 47s\n71:\tlearn: 0.5249635\ttotal: 14.7s\tremaining: 1m 47s\n72:\tlearn: 0.5219493\ttotal: 14.9s\tremaining: 1m 47s\n73:\tlearn: 0.5126561\ttotal: 15.1s\tremaining: 1m 47s\n74:\tlearn: 0.4994706\ttotal: 15.3s\tremaining: 1m 47s\n75:\tlearn: 0.4915526\ttotal: 15.5s\tremaining: 1m 47s\n76:\tlearn: 0.4859081\ttotal: 15.7s\tremaining: 1m 46s\n77:\tlearn: 0.4771967\ttotal: 15.9s\tremaining: 1m 46s\n78:\tlearn: 0.4735010\ttotal: 16.1s\tremaining: 1m 46s\n79:\tlearn: 0.4676264\ttotal: 16.3s\tremaining: 1m 46s\n80:\tlearn: 0.4617035\ttotal: 16.5s\tremaining: 1m 45s\n81:\tlearn: 0.4514350\ttotal: 16.7s\tremaining: 1m 45s\n82:\tlearn: 0.4383621\ttotal: 17s\tremaining: 1m 45s\n83:\tlearn: 0.4337346\ttotal: 17.2s\tremaining: 1m 45s\n84:\tlearn: 0.4303317\ttotal: 17.4s\tremaining: 1m 45s\n85:\tlearn: 0.4273749\ttotal: 17.6s\tremaining: 1m 45s\n86:\tlearn: 0.4233278\ttotal: 17.8s\tremaining: 1m 44s\n87:\tlearn: 0.4203787\ttotal: 18s\tremaining: 1m 44s\n88:\tlearn: 0.4116164\ttotal: 18.2s\tremaining: 1m 44s\n89:\tlearn: 0.4092313\ttotal: 18.4s\tremaining: 1m 44s\n90:\tlearn: 0.4031774\ttotal: 18.6s\tremaining: 1m 44s\n91:\tlearn: 0.3994329\ttotal: 18.8s\tremaining: 1m 43s\n92:\tlearn: 0.3971129\ttotal: 19s\tremaining: 1m 43s\n93:\tlearn: 0.3929667\ttotal: 19.2s\tremaining: 1m 43s\n94:\tlearn: 0.3879536\ttotal: 19.4s\tremaining: 1m 43s\n95:\tlearn: 0.3816475\ttotal: 19.6s\tremaining: 1m 43s\n96:\tlearn: 0.3743139\ttotal: 19.8s\tremaining: 1m 42s\n97:\tlearn: 0.3700794\ttotal: 20s\tremaining: 1m 42s\n98:\tlearn: 0.3659409\ttotal: 20.2s\tremaining: 1m 42s\n99:\tlearn: 0.3600683\ttotal: 20.5s\tremaining: 1m 42s\n100:\tlearn: 0.3562549\ttotal: 20.7s\tremaining: 1m 42s\n101:\tlearn: 0.3530217\ttotal: 20.9s\tremaining: 1m 41s\n102:\tlearn: 0.3471414\ttotal: 21.1s\tremaining: 1m 41s\n103:\tlearn: 0.3387566\ttotal: 21.3s\tremaining: 1m 41s\n104:\tlearn: 0.3317658\ttotal: 21.5s\tremaining: 1m 41s\n105:\tlearn: 0.3270361\ttotal: 21.7s\tremaining: 1m 41s\n106:\tlearn: 0.3220480\ttotal: 21.9s\tremaining: 1m 40s\n107:\tlearn: 0.3171759\ttotal: 22.1s\tremaining: 1m 40s\n108:\tlearn: 0.3120218\ttotal: 22.3s\tremaining: 1m 40s\n109:\tlearn: 0.3091221\ttotal: 22.5s\tremaining: 1m 40s\n110:\tlearn: 0.3050174\ttotal: 22.7s\tremaining: 1m 40s\n111:\tlearn: 0.3015453\ttotal: 22.9s\tremaining: 1m 39s\n112:\tlearn: 0.2992973\ttotal: 23.2s\tremaining: 1m 39s\n113:\tlearn: 0.2976384\ttotal: 23.4s\tremaining: 1m 39s\n114:\tlearn: 0.2934008\ttotal: 23.6s\tremaining: 1m 39s\n115:\tlearn: 0.2911648\ttotal: 23.8s\tremaining: 1m 39s\n116:\tlearn: 0.2875012\ttotal: 24s\tremaining: 1m 38s\n117:\tlearn: 0.2855640\ttotal: 24.2s\tremaining: 1m 38s\n118:\tlearn: 0.2838820\ttotal: 24.4s\tremaining: 1m 38s\n119:\tlearn: 0.2801307\ttotal: 24.6s\tremaining: 1m 38s\n120:\tlearn: 0.2778583\ttotal: 24.8s\tremaining: 1m 38s\n121:\tlearn: 0.2740386\ttotal: 25s\tremaining: 1m 38s\n122:\tlearn: 0.2719781\ttotal: 25.2s\tremaining: 1m 37s\n123:\tlearn: 0.2709062\ttotal: 25.4s\tremaining: 1m 37s\n124:\tlearn: 0.2686899\ttotal: 25.6s\tremaining: 1m 37s\n125:\tlearn: 0.2675580\ttotal: 25.8s\tremaining: 1m 37s\n126:\tlearn: 0.2664179\ttotal: 26s\tremaining: 1m 36s\n127:\tlearn: 0.2641130\ttotal: 26.2s\tremaining: 1m 36s\n128:\tlearn: 0.2616212\ttotal: 26.4s\tremaining: 1m 36s\n129:\tlearn: 0.2587719\ttotal: 26.7s\tremaining: 1m 36s\n130:\tlearn: 0.2571417\ttotal: 26.9s\tremaining: 1m 36s\n131:\tlearn: 0.2564262\ttotal: 27.1s\tremaining: 1m 36s\n132:\tlearn: 0.2559340\ttotal: 27.3s\tremaining: 1m 35s\n133:\tlearn: 0.2546091\ttotal: 27.5s\tremaining: 1m 35s\n134:\tlearn: 0.2533959\ttotal: 27.7s\tremaining: 1m 35s\n135:\tlearn: 0.2505453\ttotal: 27.9s\tremaining: 1m 35s\n136:\tlearn: 0.2495433\ttotal: 28.1s\tremaining: 1m 34s\n137:\tlearn: 0.2484348\ttotal: 28.3s\tremaining: 1m 34s\n138:\tlearn: 0.2474885\ttotal: 28.5s\tremaining: 1m 34s\n139:\tlearn: 0.2466532\ttotal: 28.7s\tremaining: 1m 34s\n140:\tlearn: 0.2456841\ttotal: 28.9s\tremaining: 1m 34s\n141:\tlearn: 0.2421322\ttotal: 29.1s\tremaining: 1m 33s\n142:\tlearn: 0.2403696\ttotal: 29.3s\tremaining: 1m 33s\n143:\tlearn: 0.2397970\ttotal: 29.5s\tremaining: 1m 33s\n144:\tlearn: 0.2390130\ttotal: 29.7s\tremaining: 1m 33s\n145:\tlearn: 0.2381502\ttotal: 29.9s\tremaining: 1m 33s\n146:\tlearn: 0.2376089\ttotal: 30.1s\tremaining: 1m 32s\n147:\tlearn: 0.2356425\ttotal: 30.3s\tremaining: 1m 32s\n148:\tlearn: 0.2341868\ttotal: 30.6s\tremaining: 1m 32s\n149:\tlearn: 0.2332077\ttotal: 30.8s\tremaining: 1m 32s\n150:\tlearn: 0.2304755\ttotal: 31s\tremaining: 1m 32s\n151:\tlearn: 0.2292106\ttotal: 31.2s\tremaining: 1m 31s\n152:\tlearn: 0.2286279\ttotal: 31.4s\tremaining: 1m 31s\n153:\tlearn: 0.2283523\ttotal: 31.6s\tremaining: 1m 31s\n154:\tlearn: 0.2280182\ttotal: 31.8s\tremaining: 1m 31s\n155:\tlearn: 0.2266123\ttotal: 32s\tremaining: 1m 31s\n156:\tlearn: 0.2258440\ttotal: 32.2s\tremaining: 1m 30s\n157:\tlearn: 0.2254287\ttotal: 32.4s\tremaining: 1m 30s\n158:\tlearn: 0.2237092\ttotal: 32.6s\tremaining: 1m 30s\n159:\tlearn: 0.2230990\ttotal: 32.8s\tremaining: 1m 30s\n160:\tlearn: 0.2226226\ttotal: 33s\tremaining: 1m 29s\n161:\tlearn: 0.2201999\ttotal: 33.2s\tremaining: 1m 29s\n162:\tlearn: 0.2195612\ttotal: 33.4s\tremaining: 1m 29s\n163:\tlearn: 0.2193819\ttotal: 33.6s\tremaining: 1m 29s\n164:\tlearn: 0.2178272\ttotal: 33.8s\tremaining: 1m 29s\n165:\tlearn: 0.2160695\ttotal: 34s\tremaining: 1m 28s\n166:\tlearn: 0.2148836\ttotal: 34.2s\tremaining: 1m 28s\n167:\tlearn: 0.2142666\ttotal: 34.4s\tremaining: 1m 28s\n168:\tlearn: 0.2138044\ttotal: 34.6s\tremaining: 1m 28s\n169:\tlearn: 0.2131106\ttotal: 34.8s\tremaining: 1m 28s\n170:\tlearn: 0.2126046\ttotal: 35s\tremaining: 1m 27s\n171:\tlearn: 0.2120375\ttotal: 35.2s\tremaining: 1m 27s\n172:\tlearn: 0.2117305\ttotal: 35.5s\tremaining: 1m 27s\n173:\tlearn: 0.2100360\ttotal: 35.7s\tremaining: 1m 27s\n174:\tlearn: 0.2090625\ttotal: 35.9s\tremaining: 1m 27s\n175:\tlearn: 0.2088632\ttotal: 36.1s\tremaining: 1m 26s\n176:\tlearn: 0.2080837\ttotal: 36.3s\tremaining: 1m 26s\n177:\tlearn: 0.2076971\ttotal: 36.5s\tremaining: 1m 26s\n178:\tlearn: 0.2074295\ttotal: 36.7s\tremaining: 1m 26s\n179:\tlearn: 0.2066320\ttotal: 36.9s\tremaining: 1m 26s\n180:\tlearn: 0.2060583\ttotal: 37.1s\tremaining: 1m 25s\n181:\tlearn: 0.2040238\ttotal: 37.3s\tremaining: 1m 25s\n182:\tlearn: 0.2034205\ttotal: 37.5s\tremaining: 1m 25s\n183:\tlearn: 0.2023504\ttotal: 37.7s\tremaining: 1m 25s\n184:\tlearn: 0.2019026\ttotal: 37.9s\tremaining: 1m 25s\n185:\tlearn: 0.1997878\ttotal: 38.2s\tremaining: 1m 24s\n186:\tlearn: 0.1995539\ttotal: 38.4s\tremaining: 1m 24s\n187:\tlearn: 0.1992592\ttotal: 38.6s\tremaining: 1m 24s\n188:\tlearn: 0.1991787\ttotal: 38.8s\tremaining: 1m 24s\n189:\tlearn: 0.1988399\ttotal: 39s\tremaining: 1m 24s\n190:\tlearn: 0.1978661\ttotal: 39.2s\tremaining: 1m 23s\n191:\tlearn: 0.1974416\ttotal: 39.4s\tremaining: 1m 23s\n192:\tlearn: 0.1972065\ttotal: 39.6s\tremaining: 1m 23s\n193:\tlearn: 0.1965779\ttotal: 39.8s\tremaining: 1m 23s\n194:\tlearn: 0.1953943\ttotal: 40s\tremaining: 1m 23s\n195:\tlearn: 0.1951991\ttotal: 40.2s\tremaining: 1m 22s\n196:\tlearn: 0.1949988\ttotal: 40.4s\tremaining: 1m 22s\n197:\tlearn: 0.1945721\ttotal: 40.6s\tremaining: 1m 22s\n198:\tlearn: 0.1941406\ttotal: 40.8s\tremaining: 1m 22s\n199:\tlearn: 0.1939527\ttotal: 41s\tremaining: 1m 21s\n200:\tlearn: 0.1936534\ttotal: 41.2s\tremaining: 1m 21s\n201:\tlearn: 0.1934039\ttotal: 41.4s\tremaining: 1m 21s\n202:\tlearn: 0.1932396\ttotal: 41.6s\tremaining: 1m 21s\n203:\tlearn: 0.1906993\ttotal: 41.8s\tremaining: 1m 21s\n204:\tlearn: 0.1904040\ttotal: 42s\tremaining: 1m 20s\n205:\tlearn: 0.1900712\ttotal: 42.2s\tremaining: 1m 20s\n206:\tlearn: 0.1897502\ttotal: 42.4s\tremaining: 1m 20s\n207:\tlearn: 0.1895013\ttotal: 42.6s\tremaining: 1m 20s\n208:\tlearn: 0.1891029\ttotal: 42.8s\tremaining: 1m 20s\n209:\tlearn: 0.1888968\ttotal: 43s\tremaining: 1m 19s\n210:\tlearn: 0.1876636\ttotal: 43.2s\tremaining: 1m 19s\n211:\tlearn: 0.1874345\ttotal: 43.4s\tremaining: 1m 19s\n212:\tlearn: 0.1844680\ttotal: 43.6s\tremaining: 1m 19s\n213:\tlearn: 0.1838951\ttotal: 43.9s\tremaining: 1m 19s\n214:\tlearn: 0.1834528\ttotal: 44.1s\tremaining: 1m 18s\n215:\tlearn: 0.1828904\ttotal: 44.3s\tremaining: 1m 18s\n216:\tlearn: 0.1817038\ttotal: 44.5s\tremaining: 1m 18s\n217:\tlearn: 0.1803038\ttotal: 44.7s\tremaining: 1m 18s\n218:\tlearn: 0.1797579\ttotal: 44.9s\tremaining: 1m 18s\n219:\tlearn: 0.1790639\ttotal: 45.1s\tremaining: 1m 17s\n220:\tlearn: 0.1777214\ttotal: 45.4s\tremaining: 1m 17s\n221:\tlearn: 0.1768118\ttotal: 45.6s\tremaining: 1m 17s\n222:\tlearn: 0.1759217\ttotal: 45.8s\tremaining: 1m 17s\n223:\tlearn: 0.1757486\ttotal: 46s\tremaining: 1m 17s\n224:\tlearn: 0.1755227\ttotal: 46.2s\tremaining: 1m 17s\n225:\tlearn: 0.1754374\ttotal: 46.4s\tremaining: 1m 16s\n226:\tlearn: 0.1747404\ttotal: 46.7s\tremaining: 1m 16s\n227:\tlearn: 0.1737355\ttotal: 46.9s\tremaining: 1m 16s\n228:\tlearn: 0.1735173\ttotal: 47.1s\tremaining: 1m 16s\n229:\tlearn: 0.1732873\ttotal: 47.3s\tremaining: 1m 16s\n230:\tlearn: 0.1729242\ttotal: 47.5s\tremaining: 1m 15s\n231:\tlearn: 0.1725594\ttotal: 47.7s\tremaining: 1m 15s\n232:\tlearn: 0.1721190\ttotal: 47.9s\tremaining: 1m 15s\n233:\tlearn: 0.1715371\ttotal: 48.1s\tremaining: 1m 15s\n234:\tlearn: 0.1713398\ttotal: 48.3s\tremaining: 1m 15s\n235:\tlearn: 0.1711653\ttotal: 48.5s\tremaining: 1m 14s\n236:\tlearn: 0.1708651\ttotal: 48.7s\tremaining: 1m 14s\n237:\tlearn: 0.1705767\ttotal: 48.9s\tremaining: 1m 14s\n238:\tlearn: 0.1698798\ttotal: 49.1s\tremaining: 1m 14s\n239:\tlearn: 0.1697341\ttotal: 49.3s\tremaining: 1m 13s\n240:\tlearn: 0.1694672\ttotal: 49.5s\tremaining: 1m 13s\n241:\tlearn: 0.1691426\ttotal: 49.7s\tremaining: 1m 13s\n242:\tlearn: 0.1685896\ttotal: 49.9s\tremaining: 1m 13s\n243:\tlearn: 0.1680681\ttotal: 50.1s\tremaining: 1m 13s\n244:\tlearn: 0.1679615\ttotal: 50.3s\tremaining: 1m 12s\n245:\tlearn: 0.1676536\ttotal: 50.5s\tremaining: 1m 12s\n246:\tlearn: 0.1670425\ttotal: 50.8s\tremaining: 1m 12s\n247:\tlearn: 0.1668560\ttotal: 51s\tremaining: 1m 12s\n248:\tlearn: 0.1660905\ttotal: 51.2s\tremaining: 1m 12s\n249:\tlearn: 0.1659156\ttotal: 51.4s\tremaining: 1m 11s\n250:\tlearn: 0.1657948\ttotal: 51.6s\tremaining: 1m 11s\n251:\tlearn: 0.1645682\ttotal: 51.8s\tremaining: 1m 11s\n252:\tlearn: 0.1643673\ttotal: 52s\tremaining: 1m 11s\n253:\tlearn: 0.1641990\ttotal: 52.2s\tremaining: 1m 11s\n254:\tlearn: 0.1640479\ttotal: 52.4s\tremaining: 1m 10s\n255:\tlearn: 0.1639797\ttotal: 52.6s\tremaining: 1m 10s\n256:\tlearn: 0.1637424\ttotal: 52.8s\tremaining: 1m 10s\n257:\tlearn: 0.1636068\ttotal: 53s\tremaining: 1m 10s\n258:\tlearn: 0.1634615\ttotal: 53.2s\tremaining: 1m 10s\n259:\tlearn: 0.1621346\ttotal: 53.4s\tremaining: 1m 9s\n260:\tlearn: 0.1619758\ttotal: 53.6s\tremaining: 1m 9s\n261:\tlearn: 0.1616629\ttotal: 53.8s\tremaining: 1m 9s\n262:\tlearn: 0.1606170\ttotal: 54s\tremaining: 1m 9s\n263:\tlearn: 0.1605437\ttotal: 54.2s\tremaining: 1m 9s\n264:\tlearn: 0.1604946\ttotal: 54.4s\tremaining: 1m 8s\n265:\tlearn: 0.1600891\ttotal: 54.6s\tremaining: 1m 8s\n266:\tlearn: 0.1600332\ttotal: 54.8s\tremaining: 1m 8s\n267:\tlearn: 0.1599541\ttotal: 55s\tremaining: 1m 8s\n268:\tlearn: 0.1596602\ttotal: 55.2s\tremaining: 1m 7s\n269:\tlearn: 0.1595639\ttotal: 55.5s\tremaining: 1m 7s\n270:\tlearn: 0.1594723\ttotal: 55.7s\tremaining: 1m 7s\n271:\tlearn: 0.1593324\ttotal: 55.9s\tremaining: 1m 7s\n272:\tlearn: 0.1592851\ttotal: 56.1s\tremaining: 1m 7s\n273:\tlearn: 0.1589851\ttotal: 56.3s\tremaining: 1m 6s\n274:\tlearn: 0.1584428\ttotal: 56.5s\tremaining: 1m 6s\n275:\tlearn: 0.1583668\ttotal: 56.7s\tremaining: 1m 6s\n276:\tlearn: 0.1571387\ttotal: 56.9s\tremaining: 1m 6s\n277:\tlearn: 0.1556855\ttotal: 57.1s\tremaining: 1m 6s\n278:\tlearn: 0.1554767\ttotal: 57.3s\tremaining: 1m 5s\n279:\tlearn: 0.1552837\ttotal: 57.5s\tremaining: 1m 5s\n280:\tlearn: 0.1549678\ttotal: 57.7s\tremaining: 1m 5s\n281:\tlearn: 0.1539530\ttotal: 57.9s\tremaining: 1m 5s\n282:\tlearn: 0.1536250\ttotal: 58.1s\tremaining: 1m 5s\n283:\tlearn: 0.1533778\ttotal: 58.3s\tremaining: 1m 4s\n284:\tlearn: 0.1531849\ttotal: 58.5s\tremaining: 1m 4s\n285:\tlearn: 0.1531115\ttotal: 58.7s\tremaining: 1m 4s\n286:\tlearn: 0.1527854\ttotal: 58.9s\tremaining: 1m 4s\n287:\tlearn: 0.1525877\ttotal: 59.1s\tremaining: 1m 4s\n288:\tlearn: 0.1522540\ttotal: 59.4s\tremaining: 1m 3s\n289:\tlearn: 0.1521721\ttotal: 59.6s\tremaining: 1m 3s\n290:\tlearn: 0.1520487\ttotal: 59.8s\tremaining: 1m 3s\n291:\tlearn: 0.1519315\ttotal: 60s\tremaining: 1m 3s\n292:\tlearn: 0.1495760\ttotal: 1m\tremaining: 1m 3s\n293:\tlearn: 0.1490649\ttotal: 1m\tremaining: 1m 2s\n294:\tlearn: 0.1489431\ttotal: 1m\tremaining: 1m 2s\n295:\tlearn: 0.1487918\ttotal: 1m\tremaining: 1m 2s\n296:\tlearn: 0.1486984\ttotal: 1m\tremaining: 1m 2s\n297:\tlearn: 0.1482980\ttotal: 1m 1s\tremaining: 1m 2s\n298:\tlearn: 0.1480544\ttotal: 1m 1s\tremaining: 1m 1s\n299:\tlearn: 0.1479778\ttotal: 1m 1s\tremaining: 1m 1s\n300:\tlearn: 0.1478343\ttotal: 1m 1s\tremaining: 1m 1s\n301:\tlearn: 0.1464950\ttotal: 1m 2s\tremaining: 1m 1s\n302:\tlearn: 0.1463890\ttotal: 1m 2s\tremaining: 1m\n303:\tlearn: 0.1462758\ttotal: 1m 2s\tremaining: 1m\n304:\tlearn: 0.1462166\ttotal: 1m 2s\tremaining: 1m\n305:\tlearn: 0.1461495\ttotal: 1m 2s\tremaining: 1m\n306:\tlearn: 0.1460419\ttotal: 1m 3s\tremaining: 1m\n307:\tlearn: 0.1458745\ttotal: 1m 3s\tremaining: 60s\n308:\tlearn: 0.1457524\ttotal: 1m 3s\tremaining: 59.8s\n309:\tlearn: 0.1456471\ttotal: 1m 3s\tremaining: 59.6s\n310:\tlearn: 0.1455432\ttotal: 1m 3s\tremaining: 59.3s\n311:\tlearn: 0.1453331\ttotal: 1m 4s\tremaining: 59.1s\n312:\tlearn: 0.1453005\ttotal: 1m 4s\tremaining: 58.9s\n313:\tlearn: 0.1451904\ttotal: 1m 4s\tremaining: 58.7s\n314:\tlearn: 0.1450344\ttotal: 1m 4s\tremaining: 58.5s\n315:\tlearn: 0.1449719\ttotal: 1m 4s\tremaining: 58.3s\n316:\tlearn: 0.1448539\ttotal: 1m 5s\tremaining: 58.1s\n317:\tlearn: 0.1447406\ttotal: 1m 5s\tremaining: 57.9s\n318:\tlearn: 0.1447065\ttotal: 1m 5s\tremaining: 57.7s\n319:\tlearn: 0.1446217\ttotal: 1m 5s\tremaining: 57.5s\n320:\tlearn: 0.1445015\ttotal: 1m 5s\tremaining: 57.3s\n321:\tlearn: 0.1444520\ttotal: 1m 6s\tremaining: 57.1s\n322:\tlearn: 0.1442664\ttotal: 1m 6s\tremaining: 56.9s\n323:\tlearn: 0.1442153\ttotal: 1m 6s\tremaining: 56.7s\n324:\tlearn: 0.1441236\ttotal: 1m 6s\tremaining: 56.5s\n325:\tlearn: 0.1439513\ttotal: 1m 6s\tremaining: 56.3s\n326:\tlearn: 0.1438577\ttotal: 1m 7s\tremaining: 56s\n327:\tlearn: 0.1433683\ttotal: 1m 7s\tremaining: 55.9s\n328:\tlearn: 0.1433154\ttotal: 1m 7s\tremaining: 55.6s\n329:\tlearn: 0.1431301\ttotal: 1m 7s\tremaining: 55.4s\n330:\tlearn: 0.1430370\ttotal: 1m 7s\tremaining: 55.2s\n331:\tlearn: 0.1429335\ttotal: 1m 8s\tremaining: 55s\n332:\tlearn: 0.1428419\ttotal: 1m 8s\tremaining: 54.8s\n333:\tlearn: 0.1426597\ttotal: 1m 8s\tremaining: 54.6s\n334:\tlearn: 0.1425480\ttotal: 1m 8s\tremaining: 54.4s\n335:\tlearn: 0.1424877\ttotal: 1m 8s\tremaining: 54.2s\n336:\tlearn: 0.1424159\ttotal: 1m 9s\tremaining: 54s\n337:\tlearn: 0.1423591\ttotal: 1m 9s\tremaining: 53.8s\n338:\tlearn: 0.1422140\ttotal: 1m 9s\tremaining: 53.6s\n339:\tlearn: 0.1421374\ttotal: 1m 9s\tremaining: 53.4s\n340:\tlearn: 0.1420863\ttotal: 1m 10s\tremaining: 53.2s\n341:\tlearn: 0.1419508\ttotal: 1m 10s\tremaining: 53s\n342:\tlearn: 0.1419084\ttotal: 1m 10s\tremaining: 52.8s\n343:\tlearn: 0.1417989\ttotal: 1m 10s\tremaining: 52.6s\n344:\tlearn: 0.1417500\ttotal: 1m 10s\tremaining: 52.4s\n345:\tlearn: 0.1416666\ttotal: 1m 11s\tremaining: 52.2s\n346:\tlearn: 0.1410129\ttotal: 1m 11s\tremaining: 51.9s\n347:\tlearn: 0.1408567\ttotal: 1m 11s\tremaining: 51.7s\n348:\tlearn: 0.1406704\ttotal: 1m 11s\tremaining: 51.5s\n349:\tlearn: 0.1405793\ttotal: 1m 11s\tremaining: 51.3s\n350:\tlearn: 0.1404946\ttotal: 1m 12s\tremaining: 51.1s\n351:\tlearn: 0.1404777\ttotal: 1m 12s\tremaining: 50.9s\n352:\tlearn: 0.1401282\ttotal: 1m 12s\tremaining: 50.7s\n353:\tlearn: 0.1400939\ttotal: 1m 12s\tremaining: 50.5s\n354:\tlearn: 0.1395090\ttotal: 1m 12s\tremaining: 50.3s\n355:\tlearn: 0.1394827\ttotal: 1m 13s\tremaining: 50.1s\n356:\tlearn: 0.1393492\ttotal: 1m 13s\tremaining: 49.9s\n357:\tlearn: 0.1392940\ttotal: 1m 13s\tremaining: 49.7s\n358:\tlearn: 0.1392821\ttotal: 1m 13s\tremaining: 49.5s\n359:\tlearn: 0.1392624\ttotal: 1m 13s\tremaining: 49.3s\n360:\tlearn: 0.1392123\ttotal: 1m 14s\tremaining: 49.1s\n361:\tlearn: 0.1391682\ttotal: 1m 14s\tremaining: 48.9s\n362:\tlearn: 0.1390326\ttotal: 1m 14s\tremaining: 48.6s\n363:\tlearn: 0.1388263\ttotal: 1m 14s\tremaining: 48.4s\n364:\tlearn: 0.1388015\ttotal: 1m 14s\tremaining: 48.2s\n365:\tlearn: 0.1387645\ttotal: 1m 15s\tremaining: 48s\n366:\tlearn: 0.1385926\ttotal: 1m 15s\tremaining: 47.8s\n367:\tlearn: 0.1385449\ttotal: 1m 15s\tremaining: 47.6s\n368:\tlearn: 0.1384566\ttotal: 1m 15s\tremaining: 47.4s\n369:\tlearn: 0.1383116\ttotal: 1m 15s\tremaining: 47.2s\n370:\tlearn: 0.1382049\ttotal: 1m 16s\tremaining: 47s\n371:\tlearn: 0.1381480\ttotal: 1m 16s\tremaining: 46.8s\n372:\tlearn: 0.1380187\ttotal: 1m 16s\tremaining: 46.6s\n373:\tlearn: 0.1379885\ttotal: 1m 16s\tremaining: 46.4s\n374:\tlearn: 0.1379023\ttotal: 1m 16s\tremaining: 46.2s\n375:\tlearn: 0.1378027\ttotal: 1m 17s\tremaining: 46s\n376:\tlearn: 0.1377600\ttotal: 1m 17s\tremaining: 45.8s\n377:\tlearn: 0.1377210\ttotal: 1m 17s\tremaining: 45.6s\n378:\tlearn: 0.1367543\ttotal: 1m 17s\tremaining: 45.4s\n379:\tlearn: 0.1366834\ttotal: 1m 17s\tremaining: 45.2s\n380:\tlearn: 0.1366255\ttotal: 1m 18s\tremaining: 45s\n381:\tlearn: 0.1364395\ttotal: 1m 18s\tremaining: 44.7s\n382:\tlearn: 0.1363779\ttotal: 1m 18s\tremaining: 44.5s\n383:\tlearn: 0.1361814\ttotal: 1m 18s\tremaining: 44.3s\n384:\tlearn: 0.1358734\ttotal: 1m 19s\tremaining: 44.1s\n385:\tlearn: 0.1343164\ttotal: 1m 19s\tremaining: 43.9s\n386:\tlearn: 0.1342440\ttotal: 1m 19s\tremaining: 43.7s\n387:\tlearn: 0.1341953\ttotal: 1m 19s\tremaining: 43.5s\n388:\tlearn: 0.1340568\ttotal: 1m 19s\tremaining: 43.3s\n389:\tlearn: 0.1333313\ttotal: 1m 20s\tremaining: 43.1s\n390:\tlearn: 0.1326815\ttotal: 1m 20s\tremaining: 42.9s\n391:\tlearn: 0.1322054\ttotal: 1m 20s\tremaining: 42.7s\n392:\tlearn: 0.1316628\ttotal: 1m 20s\tremaining: 42.5s\n393:\tlearn: 0.1315747\ttotal: 1m 20s\tremaining: 42.3s\n394:\tlearn: 0.1312932\ttotal: 1m 21s\tremaining: 42.1s\n395:\tlearn: 0.1310575\ttotal: 1m 21s\tremaining: 41.9s\n396:\tlearn: 0.1289311\ttotal: 1m 21s\tremaining: 41.7s\n397:\tlearn: 0.1286430\ttotal: 1m 21s\tremaining: 41.5s\n398:\tlearn: 0.1281665\ttotal: 1m 21s\tremaining: 41.3s\n399:\tlearn: 0.1277885\ttotal: 1m 22s\tremaining: 41.1s\n400:\tlearn: 0.1274592\ttotal: 1m 22s\tremaining: 40.9s\n401:\tlearn: 0.1261860\ttotal: 1m 22s\tremaining: 40.7s\n402:\tlearn: 0.1261448\ttotal: 1m 22s\tremaining: 40.5s\n403:\tlearn: 0.1260978\ttotal: 1m 22s\tremaining: 40.3s\n404:\tlearn: 0.1259756\ttotal: 1m 23s\tremaining: 40.1s\n405:\tlearn: 0.1255227\ttotal: 1m 23s\tremaining: 39.8s\n406:\tlearn: 0.1254084\ttotal: 1m 23s\tremaining: 39.6s\n407:\tlearn: 0.1248353\ttotal: 1m 23s\tremaining: 39.4s\n408:\tlearn: 0.1240866\ttotal: 1m 24s\tremaining: 39.2s\n409:\tlearn: 0.1230506\ttotal: 1m 24s\tremaining: 39s\n410:\tlearn: 0.1228741\ttotal: 1m 24s\tremaining: 38.8s\n411:\tlearn: 0.1225281\ttotal: 1m 24s\tremaining: 38.6s\n412:\tlearn: 0.1224576\ttotal: 1m 24s\tremaining: 38.4s\n413:\tlearn: 0.1223771\ttotal: 1m 25s\tremaining: 38.2s\n414:\tlearn: 0.1223088\ttotal: 1m 25s\tremaining: 38s\n415:\tlearn: 0.1222188\ttotal: 1m 25s\tremaining: 37.8s\n416:\tlearn: 0.1221242\ttotal: 1m 25s\tremaining: 37.6s\n417:\tlearn: 0.1219106\ttotal: 1m 25s\tremaining: 37.4s\n418:\tlearn: 0.1216520\ttotal: 1m 26s\tremaining: 37.2s\n419:\tlearn: 0.1215230\ttotal: 1m 26s\tremaining: 37s\n420:\tlearn: 0.1213154\ttotal: 1m 26s\tremaining: 36.8s\n421:\tlearn: 0.1182204\ttotal: 1m 26s\tremaining: 36.6s\n422:\tlearn: 0.1181473\ttotal: 1m 26s\tremaining: 36.4s\n423:\tlearn: 0.1180967\ttotal: 1m 27s\tremaining: 36.2s\n424:\tlearn: 0.1180361\ttotal: 1m 27s\tremaining: 36s\n425:\tlearn: 0.1178327\ttotal: 1m 27s\tremaining: 35.8s\n426:\tlearn: 0.1177816\ttotal: 1m 27s\tremaining: 35.5s\n427:\tlearn: 0.1177048\ttotal: 1m 27s\tremaining: 35.3s\n428:\tlearn: 0.1176401\ttotal: 1m 28s\tremaining: 35.1s\n429:\tlearn: 0.1175805\ttotal: 1m 28s\tremaining: 34.9s\n430:\tlearn: 0.1175157\ttotal: 1m 28s\tremaining: 34.7s\n431:\tlearn: 0.1174780\ttotal: 1m 28s\tremaining: 34.5s\n432:\tlearn: 0.1174496\ttotal: 1m 28s\tremaining: 34.3s\n433:\tlearn: 0.1173879\ttotal: 1m 29s\tremaining: 34.1s\n434:\tlearn: 0.1173706\ttotal: 1m 29s\tremaining: 33.9s\n435:\tlearn: 0.1173194\ttotal: 1m 29s\tremaining: 33.7s\n436:\tlearn: 0.1172841\ttotal: 1m 29s\tremaining: 33.5s\n437:\tlearn: 0.1172132\ttotal: 1m 29s\tremaining: 33.3s\n438:\tlearn: 0.1171528\ttotal: 1m 30s\tremaining: 33.1s\n439:\tlearn: 0.1169651\ttotal: 1m 30s\tremaining: 32.9s\n440:\tlearn: 0.1169129\ttotal: 1m 30s\tremaining: 32.7s\n441:\tlearn: 0.1167941\ttotal: 1m 30s\tremaining: 32.5s\n442:\tlearn: 0.1166249\ttotal: 1m 31s\tremaining: 32.3s\n443:\tlearn: 0.1165173\ttotal: 1m 31s\tremaining: 32s\n444:\tlearn: 0.1164003\ttotal: 1m 31s\tremaining: 31.8s\n445:\tlearn: 0.1163506\ttotal: 1m 31s\tremaining: 31.6s\n446:\tlearn: 0.1163178\ttotal: 1m 31s\tremaining: 31.4s\n447:\tlearn: 0.1162892\ttotal: 1m 32s\tremaining: 31.2s\n448:\tlearn: 0.1162346\ttotal: 1m 32s\tremaining: 31s\n449:\tlearn: 0.1161737\ttotal: 1m 32s\tremaining: 30.8s\n450:\tlearn: 0.1156150\ttotal: 1m 32s\tremaining: 30.6s\n451:\tlearn: 0.1155973\ttotal: 1m 32s\tremaining: 30.4s\n452:\tlearn: 0.1155446\ttotal: 1m 33s\tremaining: 30.2s\n453:\tlearn: 0.1154784\ttotal: 1m 33s\tremaining: 30s\n454:\tlearn: 0.1154369\ttotal: 1m 33s\tremaining: 29.8s\n455:\tlearn: 0.1154183\ttotal: 1m 33s\tremaining: 29.6s\n456:\tlearn: 0.1153838\ttotal: 1m 33s\tremaining: 29.4s\n457:\tlearn: 0.1152822\ttotal: 1m 34s\tremaining: 29.2s\n458:\tlearn: 0.1152194\ttotal: 1m 34s\tremaining: 29s\n459:\tlearn: 0.1151337\ttotal: 1m 34s\tremaining: 28.8s\n460:\tlearn: 0.1149859\ttotal: 1m 34s\tremaining: 28.6s\n461:\tlearn: 0.1146545\ttotal: 1m 34s\tremaining: 28.3s\n462:\tlearn: 0.1141760\ttotal: 1m 35s\tremaining: 28.1s\n463:\tlearn: 0.1141198\ttotal: 1m 35s\tremaining: 27.9s\n464:\tlearn: 0.1139446\ttotal: 1m 35s\tremaining: 27.7s\n465:\tlearn: 0.1137649\ttotal: 1m 35s\tremaining: 27.5s\n466:\tlearn: 0.1136363\ttotal: 1m 35s\tremaining: 27.3s\n467:\tlearn: 0.1135788\ttotal: 1m 36s\tremaining: 27.1s\n468:\tlearn: 0.1135127\ttotal: 1m 36s\tremaining: 26.9s\n469:\tlearn: 0.1134618\ttotal: 1m 36s\tremaining: 26.7s\n470:\tlearn: 0.1128433\ttotal: 1m 36s\tremaining: 26.5s\n471:\tlearn: 0.1127266\ttotal: 1m 36s\tremaining: 26.3s\n472:\tlearn: 0.1126455\ttotal: 1m 37s\tremaining: 26.1s\n473:\tlearn: 0.1126121\ttotal: 1m 37s\tremaining: 25.9s\n474:\tlearn: 0.1125258\ttotal: 1m 37s\tremaining: 25.7s\n475:\tlearn: 0.1124561\ttotal: 1m 37s\tremaining: 25.5s\n476:\tlearn: 0.1124028\ttotal: 1m 38s\tremaining: 25.3s\n477:\tlearn: 0.1123170\ttotal: 1m 38s\tremaining: 25.1s\n478:\tlearn: 0.1122920\ttotal: 1m 38s\tremaining: 24.9s\n479:\tlearn: 0.1122348\ttotal: 1m 38s\tremaining: 24.7s\n480:\tlearn: 0.1121773\ttotal: 1m 38s\tremaining: 24.5s\n481:\tlearn: 0.1121020\ttotal: 1m 39s\tremaining: 24.3s\n482:\tlearn: 0.1120527\ttotal: 1m 39s\tremaining: 24.1s\n483:\tlearn: 0.1120296\ttotal: 1m 39s\tremaining: 23.8s\n484:\tlearn: 0.1119371\ttotal: 1m 39s\tremaining: 23.6s\n485:\tlearn: 0.1119043\ttotal: 1m 39s\tremaining: 23.4s\n486:\tlearn: 0.1118858\ttotal: 1m 40s\tremaining: 23.2s\n487:\tlearn: 0.1118504\ttotal: 1m 40s\tremaining: 23s\n488:\tlearn: 0.1117862\ttotal: 1m 40s\tremaining: 22.8s\n489:\tlearn: 0.1097460\ttotal: 1m 40s\tremaining: 22.6s\n490:\tlearn: 0.1084684\ttotal: 1m 40s\tremaining: 22.4s\n491:\tlearn: 0.1084340\ttotal: 1m 41s\tremaining: 22.2s\n492:\tlearn: 0.1083926\ttotal: 1m 41s\tremaining: 22s\n493:\tlearn: 0.1083840\ttotal: 1m 41s\tremaining: 21.8s\n494:\tlearn: 0.1083328\ttotal: 1m 41s\tremaining: 21.6s\n495:\tlearn: 0.1083034\ttotal: 1m 41s\tremaining: 21.4s\n496:\tlearn: 0.1078665\ttotal: 1m 42s\tremaining: 21.2s\n497:\tlearn: 0.1078377\ttotal: 1m 42s\tremaining: 21s\n498:\tlearn: 0.1077344\ttotal: 1m 42s\tremaining: 20.8s\n499:\tlearn: 0.1077061\ttotal: 1m 42s\tremaining: 20.6s\n500:\tlearn: 0.1076573\ttotal: 1m 43s\tremaining: 20.4s\n501:\tlearn: 0.1076319\ttotal: 1m 43s\tremaining: 20.1s\n502:\tlearn: 0.1075657\ttotal: 1m 43s\tremaining: 19.9s\n503:\tlearn: 0.1075316\ttotal: 1m 43s\tremaining: 19.7s\n504:\tlearn: 0.1074959\ttotal: 1m 43s\tremaining: 19.5s\n505:\tlearn: 0.1074746\ttotal: 1m 44s\tremaining: 19.3s\n506:\tlearn: 0.1074609\ttotal: 1m 44s\tremaining: 19.1s\n507:\tlearn: 0.1071592\ttotal: 1m 44s\tremaining: 18.9s\n508:\tlearn: 0.1070941\ttotal: 1m 44s\tremaining: 18.7s\n509:\tlearn: 0.1070746\ttotal: 1m 44s\tremaining: 18.5s\n510:\tlearn: 0.1070362\ttotal: 1m 45s\tremaining: 18.3s\n511:\tlearn: 0.1069700\ttotal: 1m 45s\tremaining: 18.1s\n512:\tlearn: 0.1069114\ttotal: 1m 45s\tremaining: 17.9s\n513:\tlearn: 0.1068056\ttotal: 1m 45s\tremaining: 17.7s\n514:\tlearn: 0.1067179\ttotal: 1m 45s\tremaining: 17.5s\n515:\tlearn: 0.1062449\ttotal: 1m 46s\tremaining: 17.3s\n516:\tlearn: 0.1061532\ttotal: 1m 46s\tremaining: 17.1s\n517:\tlearn: 0.1060536\ttotal: 1m 46s\tremaining: 16.9s\n518:\tlearn: 0.1059726\ttotal: 1m 46s\tremaining: 16.7s\n519:\tlearn: 0.1059557\ttotal: 1m 46s\tremaining: 16.4s\n520:\tlearn: 0.1058888\ttotal: 1m 47s\tremaining: 16.2s\n521:\tlearn: 0.1056803\ttotal: 1m 47s\tremaining: 16s\n522:\tlearn: 0.1056660\ttotal: 1m 47s\tremaining: 15.8s\n523:\tlearn: 0.1056435\ttotal: 1m 47s\tremaining: 15.6s\n524:\tlearn: 0.1055982\ttotal: 1m 47s\tremaining: 15.4s\n525:\tlearn: 0.1055725\ttotal: 1m 48s\tremaining: 15.2s\n526:\tlearn: 0.1055286\ttotal: 1m 48s\tremaining: 15s\n527:\tlearn: 0.1054845\ttotal: 1m 48s\tremaining: 14.8s\n528:\tlearn: 0.1054034\ttotal: 1m 48s\tremaining: 14.6s\n529:\tlearn: 0.1053649\ttotal: 1m 48s\tremaining: 14.4s\n530:\tlearn: 0.1053264\ttotal: 1m 49s\tremaining: 14.2s\n531:\tlearn: 0.1052492\ttotal: 1m 49s\tremaining: 14s\n532:\tlearn: 0.1051446\ttotal: 1m 49s\tremaining: 13.8s\n533:\tlearn: 0.1051176\ttotal: 1m 49s\tremaining: 13.6s\n534:\tlearn: 0.1048809\ttotal: 1m 50s\tremaining: 13.4s\n535:\tlearn: 0.1048544\ttotal: 1m 50s\tremaining: 13.2s\n536:\tlearn: 0.1048053\ttotal: 1m 50s\tremaining: 13s\n537:\tlearn: 0.1047992\ttotal: 1m 50s\tremaining: 12.7s\n538:\tlearn: 0.1047801\ttotal: 1m 50s\tremaining: 12.5s\n539:\tlearn: 0.1047509\ttotal: 1m 51s\tremaining: 12.3s\n540:\tlearn: 0.1047228\ttotal: 1m 51s\tremaining: 12.1s\n541:\tlearn: 0.1042345\ttotal: 1m 51s\tremaining: 11.9s\n542:\tlearn: 0.1042193\ttotal: 1m 51s\tremaining: 11.7s\n543:\tlearn: 0.1042004\ttotal: 1m 51s\tremaining: 11.5s\n544:\tlearn: 0.1040876\ttotal: 1m 52s\tremaining: 11.3s\n545:\tlearn: 0.1040484\ttotal: 1m 52s\tremaining: 11.1s\n546:\tlearn: 0.1040102\ttotal: 1m 52s\tremaining: 10.9s\n547:\tlearn: 0.1039941\ttotal: 1m 52s\tremaining: 10.7s\n548:\tlearn: 0.1039129\ttotal: 1m 52s\tremaining: 10.5s\n549:\tlearn: 0.1039005\ttotal: 1m 53s\tremaining: 10.3s\n550:\tlearn: 0.1038874\ttotal: 1m 53s\tremaining: 10.1s\n551:\tlearn: 0.1038459\ttotal: 1m 53s\tremaining: 9.87s\n552:\tlearn: 0.1037628\ttotal: 1m 53s\tremaining: 9.66s\n553:\tlearn: 0.1037403\ttotal: 1m 53s\tremaining: 9.46s\n554:\tlearn: 0.1036048\ttotal: 1m 54s\tremaining: 9.25s\n555:\tlearn: 0.1035621\ttotal: 1m 54s\tremaining: 9.05s\n556:\tlearn: 0.1035338\ttotal: 1m 54s\tremaining: 8.84s\n557:\tlearn: 0.1035015\ttotal: 1m 54s\tremaining: 8.63s\n558:\tlearn: 0.1032274\ttotal: 1m 54s\tremaining: 8.43s\n559:\tlearn: 0.1031899\ttotal: 1m 55s\tremaining: 8.22s\n560:\tlearn: 0.1031302\ttotal: 1m 55s\tremaining: 8.02s\n561:\tlearn: 0.1031164\ttotal: 1m 55s\tremaining: 7.81s\n562:\tlearn: 0.1030684\ttotal: 1m 55s\tremaining: 7.61s\n563:\tlearn: 0.1030232\ttotal: 1m 55s\tremaining: 7.4s\n564:\tlearn: 0.1029987\ttotal: 1m 56s\tremaining: 7.2s\n565:\tlearn: 0.1029303\ttotal: 1m 56s\tremaining: 6.99s\n566:\tlearn: 0.1029179\ttotal: 1m 56s\tremaining: 6.78s\n567:\tlearn: 0.1028762\ttotal: 1m 56s\tremaining: 6.58s\n568:\tlearn: 0.1028445\ttotal: 1m 56s\tremaining: 6.37s\n569:\tlearn: 0.1028125\ttotal: 1m 57s\tremaining: 6.17s\n570:\tlearn: 0.1027824\ttotal: 1m 57s\tremaining: 5.96s\n571:\tlearn: 0.1027630\ttotal: 1m 57s\tremaining: 5.76s\n572:\tlearn: 0.1027406\ttotal: 1m 57s\tremaining: 5.55s\n573:\tlearn: 0.1027118\ttotal: 1m 58s\tremaining: 5.34s\n574:\tlearn: 0.1027030\ttotal: 1m 58s\tremaining: 5.14s\n575:\tlearn: 0.1026800\ttotal: 1m 58s\tremaining: 4.93s\n576:\tlearn: 0.1026068\ttotal: 1m 58s\tremaining: 4.73s\n577:\tlearn: 0.1019281\ttotal: 1m 58s\tremaining: 4.52s\n578:\tlearn: 0.1015928\ttotal: 1m 59s\tremaining: 4.32s\n579:\tlearn: 0.1009403\ttotal: 1m 59s\tremaining: 4.11s\n580:\tlearn: 0.1009118\ttotal: 1m 59s\tremaining: 3.91s\n581:\tlearn: 0.1008154\ttotal: 1m 59s\tremaining: 3.7s\n582:\tlearn: 0.1007856\ttotal: 1m 59s\tremaining: 3.5s\n583:\tlearn: 0.1007546\ttotal: 2m\tremaining: 3.29s\n584:\tlearn: 0.1007342\ttotal: 2m\tremaining: 3.08s\n585:\tlearn: 0.1007082\ttotal: 2m\tremaining: 2.88s\n586:\tlearn: 0.1006971\ttotal: 2m\tremaining: 2.67s\n587:\tlearn: 0.1006699\ttotal: 2m\tremaining: 2.47s\n588:\tlearn: 0.1006616\ttotal: 2m 1s\tremaining: 2.26s\n589:\tlearn: 0.1006267\ttotal: 2m 1s\tremaining: 2.06s\n590:\tlearn: 0.1005922\ttotal: 2m 1s\tremaining: 1.85s\n591:\tlearn: 0.1005167\ttotal: 2m 1s\tremaining: 1.64s\n592:\tlearn: 0.1004180\ttotal: 2m 1s\tremaining: 1.44s\n593:\tlearn: 0.1003778\ttotal: 2m 2s\tremaining: 1.23s\n594:\tlearn: 0.1003580\ttotal: 2m 2s\tremaining: 1.03s\n595:\tlearn: 0.1003531\ttotal: 2m 2s\tremaining: 822ms\n596:\tlearn: 0.1000087\ttotal: 2m 2s\tremaining: 617ms\n597:\tlearn: 0.0999584\ttotal: 2m 2s\tremaining: 411ms\n598:\tlearn: 0.0998717\ttotal: 2m 3s\tremaining: 206ms\n599:\tlearn: 0.0998605\ttotal: 2m 3s\tremaining: 0us\ncat_fit_done\nmodel_ready\n0:\tlearn: 2.5191069\ttotal: 433ms\tremaining: 4m 19s\n1:\tlearn: 2.4464416\ttotal: 874ms\tremaining: 4m 21s\n2:\tlearn: 2.3803294\ttotal: 1.32s\tremaining: 4m 23s\n3:\tlearn: 2.3238917\ttotal: 1.76s\tremaining: 4m 22s\n4:\tlearn: 2.2681825\ttotal: 2.19s\tremaining: 4m 20s\n5:\tlearn: 2.2062820\ttotal: 2.63s\tremaining: 4m 20s\n6:\tlearn: 2.1498864\ttotal: 3.07s\tremaining: 4m 20s\n7:\tlearn: 2.1142400\ttotal: 3.51s\tremaining: 4m 19s\n8:\tlearn: 2.0552543\ttotal: 3.96s\tremaining: 4m 20s\n9:\tlearn: 2.0114530\ttotal: 4.42s\tremaining: 4m 21s\n10:\tlearn: 1.9880733\ttotal: 4.85s\tremaining: 4m 19s\n11:\tlearn: 1.9562918\ttotal: 5.3s\tremaining: 4m 19s\n12:\tlearn: 1.9413305\ttotal: 5.72s\tremaining: 4m 18s\n13:\tlearn: 1.9131748\ttotal: 6.15s\tremaining: 4m 17s\n14:\tlearn: 1.8802487\ttotal: 6.61s\tremaining: 4m 17s\n15:\tlearn: 1.8506737\ttotal: 7.05s\tremaining: 4m 17s\n16:\tlearn: 1.8268939\ttotal: 7.48s\tremaining: 4m 16s\n17:\tlearn: 1.8043638\ttotal: 7.92s\tremaining: 4m 16s\n18:\tlearn: 1.7700668\ttotal: 8.37s\tremaining: 4m 16s\n19:\tlearn: 1.7534629\ttotal: 8.8s\tremaining: 4m 15s\n20:\tlearn: 1.7304801\ttotal: 9.23s\tremaining: 4m 14s\n21:\tlearn: 1.7117966\ttotal: 9.66s\tremaining: 4m 13s\n22:\tlearn: 1.7016442\ttotal: 10.1s\tremaining: 4m 13s\n23:\tlearn: 1.6751750\ttotal: 10.5s\tremaining: 4m 12s\n24:\tlearn: 1.6604631\ttotal: 10.9s\tremaining: 4m 11s\n25:\tlearn: 1.6464034\ttotal: 11.4s\tremaining: 4m 11s\n26:\tlearn: 1.6285787\ttotal: 11.8s\tremaining: 4m 10s\n27:\tlearn: 1.6028676\ttotal: 12.3s\tremaining: 4m 10s\n28:\tlearn: 1.5869784\ttotal: 12.7s\tremaining: 4m 9s\n29:\tlearn: 1.5694430\ttotal: 13.1s\tremaining: 4m 9s\n30:\tlearn: 1.5602553\ttotal: 13.6s\tremaining: 4m 8s\n31:\tlearn: 1.5370607\ttotal: 14s\tremaining: 4m 8s\n32:\tlearn: 1.5292997\ttotal: 14.4s\tremaining: 4m 8s\n33:\tlearn: 1.5144420\ttotal: 14.9s\tremaining: 4m 7s\n34:\tlearn: 1.5013159\ttotal: 15.3s\tremaining: 4m 6s\n35:\tlearn: 1.4836992\ttotal: 15.7s\tremaining: 4m 6s\n36:\tlearn: 1.4668939\ttotal: 16.2s\tremaining: 4m 6s\n37:\tlearn: 1.4483825\ttotal: 16.6s\tremaining: 4m 5s\n38:\tlearn: 1.4415227\ttotal: 17s\tremaining: 4m 4s\n39:\tlearn: 1.4284549\ttotal: 17.5s\tremaining: 4m 4s\n40:\tlearn: 1.4163195\ttotal: 17.9s\tremaining: 4m 3s\n41:\tlearn: 1.4092746\ttotal: 18.3s\tremaining: 4m 3s\n42:\tlearn: 1.3997422\ttotal: 18.7s\tremaining: 4m 2s\n43:\tlearn: 1.3858276\ttotal: 19.2s\tremaining: 4m 2s\n44:\tlearn: 1.3755078\ttotal: 19.6s\tremaining: 4m 1s\n45:\tlearn: 1.3693875\ttotal: 20s\tremaining: 4m 1s\n46:\tlearn: 1.3553051\ttotal: 20.5s\tremaining: 4m\n47:\tlearn: 1.3488425\ttotal: 20.9s\tremaining: 4m\n48:\tlearn: 1.3341726\ttotal: 21.3s\tremaining: 3m 59s\n49:\tlearn: 1.3211855\ttotal: 21.7s\tremaining: 3m 59s\n50:\tlearn: 1.3124139\ttotal: 22.2s\tremaining: 3m 58s\n51:\tlearn: 1.3044193\ttotal: 22.6s\tremaining: 3m 58s\n52:\tlearn: 1.2998552\ttotal: 23s\tremaining: 3m 57s\n53:\tlearn: 1.2960713\ttotal: 23.4s\tremaining: 3m 57s\n54:\tlearn: 1.2855898\ttotal: 23.9s\tremaining: 3m 56s\n55:\tlearn: 1.2739753\ttotal: 24.3s\tremaining: 3m 56s\n56:\tlearn: 1.2639535\ttotal: 24.7s\tremaining: 3m 55s\n57:\tlearn: 1.2584943\ttotal: 25.2s\tremaining: 3m 55s\n58:\tlearn: 1.2496446\ttotal: 25.6s\tremaining: 3m 54s\n59:\tlearn: 1.2445457\ttotal: 26s\tremaining: 3m 54s\n60:\tlearn: 1.2401258\ttotal: 26.4s\tremaining: 3m 53s\n61:\tlearn: 1.2319666\ttotal: 26.9s\tremaining: 3m 53s\n62:\tlearn: 1.2252925\ttotal: 27.3s\tremaining: 3m 52s\n63:\tlearn: 1.2221781\ttotal: 27.7s\tremaining: 3m 52s\n64:\tlearn: 1.2212719\ttotal: 28.1s\tremaining: 3m 51s\n65:\tlearn: 1.2127992\ttotal: 28.6s\tremaining: 3m 51s\n66:\tlearn: 1.2010782\ttotal: 29s\tremaining: 3m 50s\n67:\tlearn: 1.1933524\ttotal: 29.4s\tremaining: 3m 50s\n68:\tlearn: 1.1898337\ttotal: 29.9s\tremaining: 3m 49s\n69:\tlearn: 1.1807036\ttotal: 30.3s\tremaining: 3m 49s\n70:\tlearn: 1.1697385\ttotal: 30.7s\tremaining: 3m 48s\n71:\tlearn: 1.1654421\ttotal: 31.2s\tremaining: 3m 48s\n72:\tlearn: 1.1595741\ttotal: 31.6s\tremaining: 3m 47s\n73:\tlearn: 1.1536453\ttotal: 32s\tremaining: 3m 47s\n74:\tlearn: 1.1462188\ttotal: 32.4s\tremaining: 3m 47s\n75:\tlearn: 1.1354240\ttotal: 32.9s\tremaining: 3m 46s\n76:\tlearn: 1.1307608\ttotal: 33.3s\tremaining: 3m 46s\n77:\tlearn: 1.1253510\ttotal: 33.7s\tremaining: 3m 45s\n78:\tlearn: 1.1187557\ttotal: 34.1s\tremaining: 3m 45s\n79:\tlearn: 1.1155448\ttotal: 34.6s\tremaining: 3m 44s\n80:\tlearn: 1.1023568\ttotal: 35s\tremaining: 3m 44s\n81:\tlearn: 1.0927216\ttotal: 35.5s\tremaining: 3m 43s\n82:\tlearn: 1.0900348\ttotal: 35.9s\tremaining: 3m 43s\n83:\tlearn: 1.0838047\ttotal: 36.3s\tremaining: 3m 42s\n84:\tlearn: 1.0800709\ttotal: 36.7s\tremaining: 3m 42s\n85:\tlearn: 1.0727409\ttotal: 37.2s\tremaining: 3m 42s\n86:\tlearn: 1.0604259\ttotal: 37.6s\tremaining: 3m 41s\n87:\tlearn: 1.0478603\ttotal: 38.1s\tremaining: 3m 41s\n88:\tlearn: 1.0420318\ttotal: 38.5s\tremaining: 3m 41s\n89:\tlearn: 1.0378416\ttotal: 38.9s\tremaining: 3m 40s\n90:\tlearn: 1.0300475\ttotal: 39.4s\tremaining: 3m 40s\n91:\tlearn: 1.0193996\ttotal: 39.8s\tremaining: 3m 39s\n92:\tlearn: 1.0152475\ttotal: 40.3s\tremaining: 3m 39s\n93:\tlearn: 1.0126322\ttotal: 40.7s\tremaining: 3m 38s\n94:\tlearn: 1.0093616\ttotal: 41.1s\tremaining: 3m 38s\n95:\tlearn: 1.0069271\ttotal: 41.5s\tremaining: 3m 37s\n96:\tlearn: 0.9978796\ttotal: 42s\tremaining: 3m 37s\n97:\tlearn: 0.9879376\ttotal: 42.4s\tremaining: 3m 37s\n98:\tlearn: 0.9759833\ttotal: 42.9s\tremaining: 3m 36s\n99:\tlearn: 0.9661615\ttotal: 43.3s\tremaining: 3m 36s\n100:\tlearn: 0.9501716\ttotal: 43.8s\tremaining: 3m 36s\n101:\tlearn: 0.9422429\ttotal: 44.2s\tremaining: 3m 35s\n102:\tlearn: 0.9358907\ttotal: 44.7s\tremaining: 3m 35s\n103:\tlearn: 0.9329180\ttotal: 45.1s\tremaining: 3m 35s\n104:\tlearn: 0.9210576\ttotal: 45.5s\tremaining: 3m 34s\n105:\tlearn: 0.9181805\ttotal: 46s\tremaining: 3m 34s\n106:\tlearn: 0.9163172\ttotal: 46.4s\tremaining: 3m 33s\n107:\tlearn: 0.9149839\ttotal: 46.8s\tremaining: 3m 33s\n108:\tlearn: 0.9070789\ttotal: 47.2s\tremaining: 3m 32s\n109:\tlearn: 0.8984088\ttotal: 47.7s\tremaining: 3m 32s\n110:\tlearn: 0.8968719\ttotal: 48.1s\tremaining: 3m 31s\n111:\tlearn: 0.8926341\ttotal: 48.5s\tremaining: 3m 31s\n112:\tlearn: 0.8896041\ttotal: 49s\tremaining: 3m 31s\n113:\tlearn: 0.8864609\ttotal: 49.4s\tremaining: 3m 30s\n114:\tlearn: 0.8841885\ttotal: 49.8s\tremaining: 3m 30s\n115:\tlearn: 0.8771248\ttotal: 50.3s\tremaining: 3m 29s\n116:\tlearn: 0.8720374\ttotal: 50.7s\tremaining: 3m 29s\n117:\tlearn: 0.8571223\ttotal: 51.2s\tremaining: 3m 28s\n118:\tlearn: 0.8482386\ttotal: 51.6s\tremaining: 3m 28s\n119:\tlearn: 0.8373430\ttotal: 52.1s\tremaining: 3m 28s\n120:\tlearn: 0.8231554\ttotal: 52.6s\tremaining: 3m 28s\n121:\tlearn: 0.8158694\ttotal: 53s\tremaining: 3m 27s\n122:\tlearn: 0.8096256\ttotal: 53.5s\tremaining: 3m 27s\n123:\tlearn: 0.8047861\ttotal: 53.9s\tremaining: 3m 26s\n124:\tlearn: 0.8031996\ttotal: 54.3s\tremaining: 3m 26s\n125:\tlearn: 0.7977613\ttotal: 54.8s\tremaining: 3m 25s\n126:\tlearn: 0.7887070\ttotal: 55.2s\tremaining: 3m 25s\n127:\tlearn: 0.7856730\ttotal: 55.6s\tremaining: 3m 25s\n128:\tlearn: 0.7835075\ttotal: 56.1s\tremaining: 3m 24s\n129:\tlearn: 0.7825530\ttotal: 56.5s\tremaining: 3m 24s\n130:\tlearn: 0.7804072\ttotal: 56.9s\tremaining: 3m 23s\n131:\tlearn: 0.7728069\ttotal: 57.4s\tremaining: 3m 23s\n132:\tlearn: 0.7658600\ttotal: 57.8s\tremaining: 3m 22s\n133:\tlearn: 0.7618958\ttotal: 58.2s\tremaining: 3m 22s\n134:\tlearn: 0.7553996\ttotal: 58.7s\tremaining: 3m 22s\n135:\tlearn: 0.7469838\ttotal: 59.1s\tremaining: 3m 21s\n136:\tlearn: 0.7459679\ttotal: 59.6s\tremaining: 3m 21s\n137:\tlearn: 0.7422363\ttotal: 60s\tremaining: 3m 20s\n138:\tlearn: 0.7410715\ttotal: 1m\tremaining: 3m 20s\n139:\tlearn: 0.7387924\ttotal: 1m\tremaining: 3m 19s\n140:\tlearn: 0.7331021\ttotal: 1m 1s\tremaining: 3m 19s\n141:\tlearn: 0.7305012\ttotal: 1m 1s\tremaining: 3m 19s\n142:\tlearn: 0.7287899\ttotal: 1m 2s\tremaining: 3m 18s\n143:\tlearn: 0.7222803\ttotal: 1m 2s\tremaining: 3m 18s\n144:\tlearn: 0.7205783\ttotal: 1m 3s\tremaining: 3m 17s\n145:\tlearn: 0.7183687\ttotal: 1m 3s\tremaining: 3m 17s\n146:\tlearn: 0.7134407\ttotal: 1m 3s\tremaining: 3m 16s\n147:\tlearn: 0.7119395\ttotal: 1m 4s\tremaining: 3m 16s\n148:\tlearn: 0.7092002\ttotal: 1m 4s\tremaining: 3m 15s\n149:\tlearn: 0.7050861\ttotal: 1m 5s\tremaining: 3m 15s\n150:\tlearn: 0.6982600\ttotal: 1m 5s\tremaining: 3m 15s\n151:\tlearn: 0.6939248\ttotal: 1m 6s\tremaining: 3m 14s\n152:\tlearn: 0.6906162\ttotal: 1m 6s\tremaining: 3m 14s\n153:\tlearn: 0.6839076\ttotal: 1m 6s\tremaining: 3m 13s\n154:\tlearn: 0.6801375\ttotal: 1m 7s\tremaining: 3m 13s\n155:\tlearn: 0.6777855\ttotal: 1m 7s\tremaining: 3m 12s\n156:\tlearn: 0.6760576\ttotal: 1m 8s\tremaining: 3m 12s\n157:\tlearn: 0.6741762\ttotal: 1m 8s\tremaining: 3m 12s\n158:\tlearn: 0.6693514\ttotal: 1m 9s\tremaining: 3m 11s\n159:\tlearn: 0.6645399\ttotal: 1m 9s\tremaining: 3m 11s\n160:\tlearn: 0.6599664\ttotal: 1m 10s\tremaining: 3m 10s\n161:\tlearn: 0.6582264\ttotal: 1m 10s\tremaining: 3m 10s\n162:\tlearn: 0.6502458\ttotal: 1m 10s\tremaining: 3m 10s\n163:\tlearn: 0.6483975\ttotal: 1m 11s\tremaining: 3m 9s\n164:\tlearn: 0.6478779\ttotal: 1m 11s\tremaining: 3m 9s\n165:\tlearn: 0.6469335\ttotal: 1m 12s\tremaining: 3m 8s\n166:\tlearn: 0.6455613\ttotal: 1m 12s\tremaining: 3m 8s\n167:\tlearn: 0.6440333\ttotal: 1m 13s\tremaining: 3m 7s\n168:\tlearn: 0.6413556\ttotal: 1m 13s\tremaining: 3m 7s\n169:\tlearn: 0.6383284\ttotal: 1m 13s\tremaining: 3m 6s\n170:\tlearn: 0.6352073\ttotal: 1m 14s\tremaining: 3m 6s\n171:\tlearn: 0.6344848\ttotal: 1m 14s\tremaining: 3m 5s\n172:\tlearn: 0.6289239\ttotal: 1m 15s\tremaining: 3m 5s\n173:\tlearn: 0.6258054\ttotal: 1m 15s\tremaining: 3m 5s\n174:\tlearn: 0.6201874\ttotal: 1m 16s\tremaining: 3m 4s\n175:\tlearn: 0.6196552\ttotal: 1m 16s\tremaining: 3m 4s\n176:\tlearn: 0.6142432\ttotal: 1m 16s\tremaining: 3m 3s\n177:\tlearn: 0.6115005\ttotal: 1m 17s\tremaining: 3m 3s\n178:\tlearn: 0.6063052\ttotal: 1m 17s\tremaining: 3m 3s\n179:\tlearn: 0.6053679\ttotal: 1m 18s\tremaining: 3m 2s\n180:\tlearn: 0.6043241\ttotal: 1m 18s\tremaining: 3m 2s\n181:\tlearn: 0.6030501\ttotal: 1m 19s\tremaining: 3m 1s\n182:\tlearn: 0.6009339\ttotal: 1m 19s\tremaining: 3m 1s\n183:\tlearn: 0.5999104\ttotal: 1m 19s\tremaining: 3m\n184:\tlearn: 0.5941989\ttotal: 1m 20s\tremaining: 3m\n185:\tlearn: 0.5931739\ttotal: 1m 20s\tremaining: 2m 59s\n186:\tlearn: 0.5867698\ttotal: 1m 21s\tremaining: 2m 59s\n187:\tlearn: 0.5851377\ttotal: 1m 21s\tremaining: 2m 59s\n188:\tlearn: 0.5841608\ttotal: 1m 22s\tremaining: 2m 58s\n189:\tlearn: 0.5823821\ttotal: 1m 22s\tremaining: 2m 58s\n190:\tlearn: 0.5808998\ttotal: 1m 22s\tremaining: 2m 57s\n191:\tlearn: 0.5801372\ttotal: 1m 23s\tremaining: 2m 57s\n192:\tlearn: 0.5790806\ttotal: 1m 23s\tremaining: 2m 56s\n193:\tlearn: 0.5772252\ttotal: 1m 24s\tremaining: 2m 56s\n194:\tlearn: 0.5763183\ttotal: 1m 24s\tremaining: 2m 55s\n195:\tlearn: 0.5694511\ttotal: 1m 25s\tremaining: 2m 55s\n196:\tlearn: 0.5636539\ttotal: 1m 25s\tremaining: 2m 55s\n197:\tlearn: 0.5629361\ttotal: 1m 26s\tremaining: 2m 54s\n198:\tlearn: 0.5610542\ttotal: 1m 26s\tremaining: 2m 54s\n199:\tlearn: 0.5606566\ttotal: 1m 26s\tremaining: 2m 53s\n200:\tlearn: 0.5585762\ttotal: 1m 27s\tremaining: 2m 53s\n201:\tlearn: 0.5550140\ttotal: 1m 27s\tremaining: 2m 52s\n202:\tlearn: 0.5541736\ttotal: 1m 28s\tremaining: 2m 52s\n203:\tlearn: 0.5473373\ttotal: 1m 28s\tremaining: 2m 52s\n204:\tlearn: 0.5467064\ttotal: 1m 29s\tremaining: 2m 51s\n205:\tlearn: 0.5451562\ttotal: 1m 29s\tremaining: 2m 51s\n206:\tlearn: 0.5392287\ttotal: 1m 29s\tremaining: 2m 50s\n207:\tlearn: 0.5379134\ttotal: 1m 30s\tremaining: 2m 50s\n208:\tlearn: 0.5368400\ttotal: 1m 30s\tremaining: 2m 49s\n209:\tlearn: 0.5363523\ttotal: 1m 31s\tremaining: 2m 49s\n210:\tlearn: 0.5336183\ttotal: 1m 31s\tremaining: 2m 48s\n211:\tlearn: 0.5303000\ttotal: 1m 32s\tremaining: 2m 48s\n212:\tlearn: 0.5286735\ttotal: 1m 32s\tremaining: 2m 48s\n213:\tlearn: 0.5258287\ttotal: 1m 32s\tremaining: 2m 47s\n214:\tlearn: 0.5253668\ttotal: 1m 33s\tremaining: 2m 47s\n215:\tlearn: 0.5221845\ttotal: 1m 33s\tremaining: 2m 46s\n216:\tlearn: 0.5193615\ttotal: 1m 34s\tremaining: 2m 46s\n217:\tlearn: 0.5160578\ttotal: 1m 34s\tremaining: 2m 45s\n218:\tlearn: 0.5131439\ttotal: 1m 35s\tremaining: 2m 45s\n219:\tlearn: 0.5118876\ttotal: 1m 35s\tremaining: 2m 45s\n220:\tlearn: 0.5114226\ttotal: 1m 35s\tremaining: 2m 44s\n221:\tlearn: 0.5098627\ttotal: 1m 36s\tremaining: 2m 44s\n222:\tlearn: 0.5082331\ttotal: 1m 36s\tremaining: 2m 43s\n223:\tlearn: 0.5066001\ttotal: 1m 37s\tremaining: 2m 43s\n224:\tlearn: 0.5056038\ttotal: 1m 37s\tremaining: 2m 42s\n225:\tlearn: 0.5019520\ttotal: 1m 38s\tremaining: 2m 42s\n226:\tlearn: 0.5010076\ttotal: 1m 38s\tremaining: 2m 41s\n227:\tlearn: 0.5001079\ttotal: 1m 39s\tremaining: 2m 41s\n228:\tlearn: 0.4956789\ttotal: 1m 39s\tremaining: 2m 41s\n229:\tlearn: 0.4953317\ttotal: 1m 39s\tremaining: 2m 40s\n230:\tlearn: 0.4949875\ttotal: 1m 40s\tremaining: 2m 40s\n231:\tlearn: 0.4937911\ttotal: 1m 40s\tremaining: 2m 39s\n232:\tlearn: 0.4917629\ttotal: 1m 41s\tremaining: 2m 39s\n233:\tlearn: 0.4910751\ttotal: 1m 41s\tremaining: 2m 38s\n234:\tlearn: 0.4900207\ttotal: 1m 42s\tremaining: 2m 38s\n235:\tlearn: 0.4895486\ttotal: 1m 42s\tremaining: 2m 38s\n236:\tlearn: 0.4881613\ttotal: 1m 42s\tremaining: 2m 37s\n237:\tlearn: 0.4873250\ttotal: 1m 43s\tremaining: 2m 37s\n238:\tlearn: 0.4862950\ttotal: 1m 43s\tremaining: 2m 36s\n239:\tlearn: 0.4846042\ttotal: 1m 44s\tremaining: 2m 36s\n240:\tlearn: 0.4840357\ttotal: 1m 44s\tremaining: 2m 35s\n241:\tlearn: 0.4832858\ttotal: 1m 45s\tremaining: 2m 35s\n242:\tlearn: 0.4810348\ttotal: 1m 45s\tremaining: 2m 35s\n243:\tlearn: 0.4806517\ttotal: 1m 45s\tremaining: 2m 34s\n244:\tlearn: 0.4796475\ttotal: 1m 46s\tremaining: 2m 34s\n245:\tlearn: 0.4788779\ttotal: 1m 46s\tremaining: 2m 33s\n246:\tlearn: 0.4764298\ttotal: 1m 47s\tremaining: 2m 33s\n247:\tlearn: 0.4758069\ttotal: 1m 47s\tremaining: 2m 32s\n248:\tlearn: 0.4753672\ttotal: 1m 48s\tremaining: 2m 32s\n249:\tlearn: 0.4708157\ttotal: 1m 48s\tremaining: 2m 31s\n250:\tlearn: 0.4680773\ttotal: 1m 48s\tremaining: 2m 31s\n251:\tlearn: 0.4671253\ttotal: 1m 49s\tremaining: 2m 31s\n252:\tlearn: 0.4668137\ttotal: 1m 49s\tremaining: 2m 30s\n253:\tlearn: 0.4663067\ttotal: 1m 50s\tremaining: 2m 30s\n254:\tlearn: 0.4639353\ttotal: 1m 50s\tremaining: 2m 29s\n255:\tlearn: 0.4635458\ttotal: 1m 51s\tremaining: 2m 29s\n256:\tlearn: 0.4600361\ttotal: 1m 51s\tremaining: 2m 28s\n257:\tlearn: 0.4596841\ttotal: 1m 51s\tremaining: 2m 28s\n258:\tlearn: 0.4569519\ttotal: 1m 52s\tremaining: 2m 28s\n259:\tlearn: 0.4551304\ttotal: 1m 52s\tremaining: 2m 27s\n260:\tlearn: 0.4534298\ttotal: 1m 53s\tremaining: 2m 27s\n261:\tlearn: 0.4527977\ttotal: 1m 53s\tremaining: 2m 26s\n262:\tlearn: 0.4517583\ttotal: 1m 54s\tremaining: 2m 26s\n263:\tlearn: 0.4513748\ttotal: 1m 54s\tremaining: 2m 25s\n264:\tlearn: 0.4495381\ttotal: 1m 55s\tremaining: 2m 25s\n265:\tlearn: 0.4492437\ttotal: 1m 55s\tremaining: 2m 24s\n266:\tlearn: 0.4489254\ttotal: 1m 55s\tremaining: 2m 24s\n267:\tlearn: 0.4475446\ttotal: 1m 56s\tremaining: 2m 24s\n268:\tlearn: 0.4472921\ttotal: 1m 56s\tremaining: 2m 23s\n269:\tlearn: 0.4460206\ttotal: 1m 57s\tremaining: 2m 23s\n270:\tlearn: 0.4457474\ttotal: 1m 57s\tremaining: 2m 22s\n271:\tlearn: 0.4445546\ttotal: 1m 57s\tremaining: 2m 22s\n272:\tlearn: 0.4417549\ttotal: 1m 58s\tremaining: 2m 21s\n273:\tlearn: 0.4406776\ttotal: 1m 58s\tremaining: 2m 21s\n274:\tlearn: 0.4392621\ttotal: 1m 59s\tremaining: 2m 20s\n275:\tlearn: 0.4386417\ttotal: 1m 59s\tremaining: 2m 20s\n276:\tlearn: 0.4355638\ttotal: 2m\tremaining: 2m 20s\n277:\tlearn: 0.4345792\ttotal: 2m\tremaining: 2m 19s\n278:\tlearn: 0.4333300\ttotal: 2m 1s\tremaining: 2m 19s\n279:\tlearn: 0.4327033\ttotal: 2m 1s\tremaining: 2m 18s\n280:\tlearn: 0.4323814\ttotal: 2m 1s\tremaining: 2m 18s\n281:\tlearn: 0.4301468\ttotal: 2m 2s\tremaining: 2m 17s\n282:\tlearn: 0.4294566\ttotal: 2m 2s\tremaining: 2m 17s\n283:\tlearn: 0.4289473\ttotal: 2m 3s\tremaining: 2m 17s\n284:\tlearn: 0.4286875\ttotal: 2m 3s\tremaining: 2m 16s\n285:\tlearn: 0.4244192\ttotal: 2m 4s\tremaining: 2m 16s\n286:\tlearn: 0.4241067\ttotal: 2m 4s\tremaining: 2m 15s\n287:\tlearn: 0.4233397\ttotal: 2m 4s\tremaining: 2m 15s\n288:\tlearn: 0.4231003\ttotal: 2m 5s\tremaining: 2m 14s\n289:\tlearn: 0.4195591\ttotal: 2m 5s\tremaining: 2m 14s\n290:\tlearn: 0.4191334\ttotal: 2m 6s\tremaining: 2m 13s\n291:\tlearn: 0.4182027\ttotal: 2m 6s\tremaining: 2m 13s\n292:\tlearn: 0.4180357\ttotal: 2m 7s\tremaining: 2m 13s\n293:\tlearn: 0.4171529\ttotal: 2m 7s\tremaining: 2m 12s\n294:\tlearn: 0.4165785\ttotal: 2m 7s\tremaining: 2m 12s\n295:\tlearn: 0.4154014\ttotal: 2m 8s\tremaining: 2m 11s\n296:\tlearn: 0.4151293\ttotal: 2m 8s\tremaining: 2m 11s\n297:\tlearn: 0.4142095\ttotal: 2m 9s\tremaining: 2m 10s\n298:\tlearn: 0.4105769\ttotal: 2m 9s\tremaining: 2m 10s\n299:\tlearn: 0.4103036\ttotal: 2m 10s\tremaining: 2m 10s\n300:\tlearn: 0.4078948\ttotal: 2m 10s\tremaining: 2m 9s\n301:\tlearn: 0.4076152\ttotal: 2m 10s\tremaining: 2m 9s\n302:\tlearn: 0.4045947\ttotal: 2m 11s\tremaining: 2m 8s\n303:\tlearn: 0.4034681\ttotal: 2m 11s\tremaining: 2m 8s\n304:\tlearn: 0.4032859\ttotal: 2m 12s\tremaining: 2m 7s\n305:\tlearn: 0.4021938\ttotal: 2m 12s\tremaining: 2m 7s\n306:\tlearn: 0.4015295\ttotal: 2m 13s\tremaining: 2m 7s\n307:\tlearn: 0.4011707\ttotal: 2m 13s\tremaining: 2m 6s\n308:\tlearn: 0.3997424\ttotal: 2m 13s\tremaining: 2m 6s\n309:\tlearn: 0.3994551\ttotal: 2m 14s\tremaining: 2m 5s\n310:\tlearn: 0.3981953\ttotal: 2m 14s\tremaining: 2m 5s\n311:\tlearn: 0.3980203\ttotal: 2m 15s\tremaining: 2m 4s\n312:\tlearn: 0.3977232\ttotal: 2m 15s\tremaining: 2m 4s\n313:\tlearn: 0.3960386\ttotal: 2m 16s\tremaining: 2m 3s\n314:\tlearn: 0.3942419\ttotal: 2m 16s\tremaining: 2m 3s\n315:\tlearn: 0.3937946\ttotal: 2m 17s\tremaining: 2m 3s\n316:\tlearn: 0.3920108\ttotal: 2m 17s\tremaining: 2m 2s\n317:\tlearn: 0.3914642\ttotal: 2m 17s\tremaining: 2m 2s\n318:\tlearn: 0.3911583\ttotal: 2m 18s\tremaining: 2m 1s\n319:\tlearn: 0.3888280\ttotal: 2m 18s\tremaining: 2m 1s\n320:\tlearn: 0.3884714\ttotal: 2m 19s\tremaining: 2m\n321:\tlearn: 0.3882995\ttotal: 2m 19s\tremaining: 2m\n322:\tlearn: 0.3867464\ttotal: 2m 20s\tremaining: 2m\n323:\tlearn: 0.3866405\ttotal: 2m 20s\tremaining: 1m 59s\n324:\tlearn: 0.3864597\ttotal: 2m 20s\tremaining: 1m 59s\n325:\tlearn: 0.3855791\ttotal: 2m 21s\tremaining: 1m 58s\n326:\tlearn: 0.3844535\ttotal: 2m 21s\tremaining: 1m 58s\n327:\tlearn: 0.3829577\ttotal: 2m 22s\tremaining: 1m 57s\n328:\tlearn: 0.3827395\ttotal: 2m 22s\tremaining: 1m 57s\n329:\tlearn: 0.3825679\ttotal: 2m 23s\tremaining: 1m 57s\n330:\tlearn: 0.3818997\ttotal: 2m 23s\tremaining: 1m 56s\n331:\tlearn: 0.3786062\ttotal: 2m 23s\tremaining: 1m 56s\n332:\tlearn: 0.3775545\ttotal: 2m 24s\tremaining: 1m 55s\n333:\tlearn: 0.3772035\ttotal: 2m 24s\tremaining: 1m 55s\n334:\tlearn: 0.3771644\ttotal: 2m 25s\tremaining: 1m 54s\n335:\tlearn: 0.3770675\ttotal: 2m 25s\tremaining: 1m 54s\n336:\tlearn: 0.3760575\ttotal: 2m 26s\tremaining: 1m 53s\n337:\tlearn: 0.3736642\ttotal: 2m 26s\tremaining: 1m 53s\n338:\tlearn: 0.3726498\ttotal: 2m 26s\tremaining: 1m 53s\n339:\tlearn: 0.3719060\ttotal: 2m 27s\tremaining: 1m 52s\n340:\tlearn: 0.3714361\ttotal: 2m 27s\tremaining: 1m 52s\n341:\tlearn: 0.3708472\ttotal: 2m 28s\tremaining: 1m 51s\n342:\tlearn: 0.3704535\ttotal: 2m 28s\tremaining: 1m 51s\n343:\tlearn: 0.3702315\ttotal: 2m 29s\tremaining: 1m 50s\n344:\tlearn: 0.3697764\ttotal: 2m 29s\tremaining: 1m 50s\n345:\tlearn: 0.3687667\ttotal: 2m 29s\tremaining: 1m 50s\n346:\tlearn: 0.3687034\ttotal: 2m 30s\tremaining: 1m 49s\n347:\tlearn: 0.3684714\ttotal: 2m 30s\tremaining: 1m 49s\n348:\tlearn: 0.3682827\ttotal: 2m 31s\tremaining: 1m 48s\n349:\tlearn: 0.3673617\ttotal: 2m 31s\tremaining: 1m 48s\n350:\tlearn: 0.3666201\ttotal: 2m 32s\tremaining: 1m 47s\n351:\tlearn: 0.3652894\ttotal: 2m 32s\tremaining: 1m 47s\n352:\tlearn: 0.3652104\ttotal: 2m 32s\tremaining: 1m 46s\n353:\tlearn: 0.3648376\ttotal: 2m 33s\tremaining: 1m 46s\n354:\tlearn: 0.3643809\ttotal: 2m 33s\tremaining: 1m 46s\n355:\tlearn: 0.3641805\ttotal: 2m 34s\tremaining: 1m 45s\n356:\tlearn: 0.3637522\ttotal: 2m 34s\tremaining: 1m 45s\n357:\tlearn: 0.3621731\ttotal: 2m 35s\tremaining: 1m 44s\n358:\tlearn: 0.3602935\ttotal: 2m 35s\tremaining: 1m 44s\n359:\tlearn: 0.3595626\ttotal: 2m 35s\tremaining: 1m 43s\n360:\tlearn: 0.3592462\ttotal: 2m 36s\tremaining: 1m 43s\n361:\tlearn: 0.3571645\ttotal: 2m 36s\tremaining: 1m 43s\n362:\tlearn: 0.3571061\ttotal: 2m 37s\tremaining: 1m 42s\n363:\tlearn: 0.3567085\ttotal: 2m 37s\tremaining: 1m 42s\n364:\tlearn: 0.3565828\ttotal: 2m 38s\tremaining: 1m 41s\n365:\tlearn: 0.3565272\ttotal: 2m 38s\tremaining: 1m 41s\n366:\tlearn: 0.3545751\ttotal: 2m 38s\tremaining: 1m 40s\n367:\tlearn: 0.3541791\ttotal: 2m 39s\tremaining: 1m 40s\n368:\tlearn: 0.3519980\ttotal: 2m 39s\tremaining: 1m 40s\n369:\tlearn: 0.3517746\ttotal: 2m 40s\tremaining: 1m 39s\n370:\tlearn: 0.3506074\ttotal: 2m 40s\tremaining: 1m 39s\n371:\tlearn: 0.3499950\ttotal: 2m 41s\tremaining: 1m 38s\n372:\tlearn: 0.3497623\ttotal: 2m 41s\tremaining: 1m 38s\n373:\tlearn: 0.3492336\ttotal: 2m 41s\tremaining: 1m 37s\n374:\tlearn: 0.3483464\ttotal: 2m 42s\tremaining: 1m 37s\n375:\tlearn: 0.3477865\ttotal: 2m 42s\tremaining: 1m 36s\n376:\tlearn: 0.3470717\ttotal: 2m 43s\tremaining: 1m 36s\n377:\tlearn: 0.3469900\ttotal: 2m 43s\tremaining: 1m 36s\n378:\tlearn: 0.3465646\ttotal: 2m 44s\tremaining: 1m 35s\n379:\tlearn: 0.3458835\ttotal: 2m 44s\tremaining: 1m 35s\n380:\tlearn: 0.3451726\ttotal: 2m 44s\tremaining: 1m 34s\n381:\tlearn: 0.3450932\ttotal: 2m 45s\tremaining: 1m 34s\n382:\tlearn: 0.3450082\ttotal: 2m 45s\tremaining: 1m 33s\n383:\tlearn: 0.3447948\ttotal: 2m 46s\tremaining: 1m 33s\n384:\tlearn: 0.3445494\ttotal: 2m 46s\tremaining: 1m 33s\n385:\tlearn: 0.3441551\ttotal: 2m 47s\tremaining: 1m 32s\n386:\tlearn: 0.3437882\ttotal: 2m 47s\tremaining: 1m 32s\n387:\tlearn: 0.3430194\ttotal: 2m 47s\tremaining: 1m 31s\n388:\tlearn: 0.3426104\ttotal: 2m 48s\tremaining: 1m 31s\n389:\tlearn: 0.3421788\ttotal: 2m 48s\tremaining: 1m 30s\n390:\tlearn: 0.3413401\ttotal: 2m 49s\tremaining: 1m 30s\n391:\tlearn: 0.3412304\ttotal: 2m 49s\tremaining: 1m 30s\n392:\tlearn: 0.3395573\ttotal: 2m 50s\tremaining: 1m 29s\n393:\tlearn: 0.3393576\ttotal: 2m 50s\tremaining: 1m 29s\n394:\tlearn: 0.3392882\ttotal: 2m 50s\tremaining: 1m 28s\n395:\tlearn: 0.3392255\ttotal: 2m 51s\tremaining: 1m 28s\n396:\tlearn: 0.3389499\ttotal: 2m 51s\tremaining: 1m 27s\n397:\tlearn: 0.3376718\ttotal: 2m 52s\tremaining: 1m 27s\n398:\tlearn: 0.3374398\ttotal: 2m 52s\tremaining: 1m 26s\n399:\tlearn: 0.3356173\ttotal: 2m 53s\tremaining: 1m 26s\n400:\tlearn: 0.3340625\ttotal: 2m 53s\tremaining: 1m 26s\n401:\tlearn: 0.3337291\ttotal: 2m 53s\tremaining: 1m 25s\n402:\tlearn: 0.3336010\ttotal: 2m 54s\tremaining: 1m 25s\n403:\tlearn: 0.3323564\ttotal: 2m 54s\tremaining: 1m 24s\n404:\tlearn: 0.3320854\ttotal: 2m 55s\tremaining: 1m 24s\n405:\tlearn: 0.3310321\ttotal: 2m 55s\tremaining: 1m 23s\n406:\tlearn: 0.3293334\ttotal: 2m 56s\tremaining: 1m 23s\n407:\tlearn: 0.3292844\ttotal: 2m 56s\tremaining: 1m 23s\n408:\tlearn: 0.3292080\ttotal: 2m 56s\tremaining: 1m 22s\n409:\tlearn: 0.3288675\ttotal: 2m 57s\tremaining: 1m 22s\n410:\tlearn: 0.3288322\ttotal: 2m 57s\tremaining: 1m 21s\n411:\tlearn: 0.3286258\ttotal: 2m 58s\tremaining: 1m 21s\n412:\tlearn: 0.3274221\ttotal: 2m 58s\tremaining: 1m 20s\n413:\tlearn: 0.3263383\ttotal: 2m 59s\tremaining: 1m 20s\n414:\tlearn: 0.3258598\ttotal: 2m 59s\tremaining: 1m 20s\n415:\tlearn: 0.3255510\ttotal: 2m 59s\tremaining: 1m 19s\n416:\tlearn: 0.3251844\ttotal: 3m\tremaining: 1m 19s\n417:\tlearn: 0.3245262\ttotal: 3m\tremaining: 1m 18s\n418:\tlearn: 0.3237812\ttotal: 3m 1s\tremaining: 1m 18s\n419:\tlearn: 0.3231276\ttotal: 3m 1s\tremaining: 1m 17s\n420:\tlearn: 0.3224280\ttotal: 3m 2s\tremaining: 1m 17s\n421:\tlearn: 0.3215814\ttotal: 3m 2s\tremaining: 1m 16s\n422:\tlearn: 0.3208300\ttotal: 3m 2s\tremaining: 1m 16s\n423:\tlearn: 0.3191292\ttotal: 3m 3s\tremaining: 1m 16s\n424:\tlearn: 0.3185979\ttotal: 3m 3s\tremaining: 1m 15s\n425:\tlearn: 0.3183555\ttotal: 3m 4s\tremaining: 1m 15s\n426:\tlearn: 0.3151639\ttotal: 3m 4s\tremaining: 1m 14s\n427:\tlearn: 0.3150393\ttotal: 3m 5s\tremaining: 1m 14s\n428:\tlearn: 0.3146811\ttotal: 3m 5s\tremaining: 1m 13s\n429:\tlearn: 0.3144931\ttotal: 3m 6s\tremaining: 1m 13s\n430:\tlearn: 0.3142815\ttotal: 3m 6s\tremaining: 1m 13s\n431:\tlearn: 0.3136018\ttotal: 3m 6s\tremaining: 1m 12s\n432:\tlearn: 0.3134049\ttotal: 3m 7s\tremaining: 1m 12s\n433:\tlearn: 0.3124986\ttotal: 3m 7s\tremaining: 1m 11s\n434:\tlearn: 0.3114124\ttotal: 3m 8s\tremaining: 1m 11s\n435:\tlearn: 0.3110879\ttotal: 3m 8s\tremaining: 1m 10s\n436:\tlearn: 0.3104408\ttotal: 3m 9s\tremaining: 1m 10s\n437:\tlearn: 0.3103854\ttotal: 3m 9s\tremaining: 1m 10s\n438:\tlearn: 0.3098215\ttotal: 3m 9s\tremaining: 1m 9s\n439:\tlearn: 0.3096929\ttotal: 3m 10s\tremaining: 1m 9s\n440:\tlearn: 0.3089739\ttotal: 3m 10s\tremaining: 1m 8s\n441:\tlearn: 0.3087109\ttotal: 3m 11s\tremaining: 1m 8s\n442:\tlearn: 0.3085531\ttotal: 3m 11s\tremaining: 1m 7s\n443:\tlearn: 0.3082945\ttotal: 3m 12s\tremaining: 1m 7s\n444:\tlearn: 0.3081891\ttotal: 3m 12s\tremaining: 1m 7s\n445:\tlearn: 0.3080419\ttotal: 3m 12s\tremaining: 1m 6s\n446:\tlearn: 0.3079027\ttotal: 3m 13s\tremaining: 1m 6s\n447:\tlearn: 0.3073711\ttotal: 3m 13s\tremaining: 1m 5s\n448:\tlearn: 0.3071649\ttotal: 3m 14s\tremaining: 1m 5s\n449:\tlearn: 0.3070906\ttotal: 3m 14s\tremaining: 1m 4s\n450:\tlearn: 0.3064489\ttotal: 3m 15s\tremaining: 1m 4s\n451:\tlearn: 0.3061528\ttotal: 3m 15s\tremaining: 1m 4s\n452:\tlearn: 0.3059230\ttotal: 3m 15s\tremaining: 1m 3s\n453:\tlearn: 0.3057032\ttotal: 3m 16s\tremaining: 1m 3s\n454:\tlearn: 0.3055253\ttotal: 3m 16s\tremaining: 1m 2s\n455:\tlearn: 0.3047524\ttotal: 3m 17s\tremaining: 1m 2s\n456:\tlearn: 0.3044660\ttotal: 3m 17s\tremaining: 1m 1s\n457:\tlearn: 0.3034934\ttotal: 3m 18s\tremaining: 1m 1s\n458:\tlearn: 0.3033057\ttotal: 3m 18s\tremaining: 1m\n459:\tlearn: 0.3028045\ttotal: 3m 18s\tremaining: 1m\n460:\tlearn: 0.3026169\ttotal: 3m 19s\tremaining: 1m\n461:\tlearn: 0.3015036\ttotal: 3m 19s\tremaining: 59.7s\n462:\tlearn: 0.3010581\ttotal: 3m 20s\tremaining: 59.2s\n463:\tlearn: 0.3004354\ttotal: 3m 20s\tremaining: 58.8s\n464:\tlearn: 0.2998332\ttotal: 3m 21s\tremaining: 58.4s\n465:\tlearn: 0.2983779\ttotal: 3m 21s\tremaining: 58s\n466:\tlearn: 0.2981043\ttotal: 3m 21s\tremaining: 57.5s\n467:\tlearn: 0.2978617\ttotal: 3m 22s\tremaining: 57.1s\n468:\tlearn: 0.2977026\ttotal: 3m 22s\tremaining: 56.7s\n469:\tlearn: 0.2973683\ttotal: 3m 23s\tremaining: 56.2s\n470:\tlearn: 0.2972355\ttotal: 3m 23s\tremaining: 55.8s\n471:\tlearn: 0.2967141\ttotal: 3m 24s\tremaining: 55.4s\n472:\tlearn: 0.2962548\ttotal: 3m 24s\tremaining: 54.9s\n473:\tlearn: 0.2960181\ttotal: 3m 24s\tremaining: 54.5s\n474:\tlearn: 0.2938158\ttotal: 3m 25s\tremaining: 54.1s\n475:\tlearn: 0.2937384\ttotal: 3m 25s\tremaining: 53.6s\n476:\tlearn: 0.2936470\ttotal: 3m 26s\tremaining: 53.2s\n477:\tlearn: 0.2935856\ttotal: 3m 26s\tremaining: 52.8s\n478:\tlearn: 0.2935003\ttotal: 3m 27s\tremaining: 52.3s\n479:\tlearn: 0.2931438\ttotal: 3m 27s\tremaining: 51.9s\n480:\tlearn: 0.2928935\ttotal: 3m 27s\tremaining: 51.5s\n481:\tlearn: 0.2928430\ttotal: 3m 28s\tremaining: 51s\n482:\tlearn: 0.2924972\ttotal: 3m 28s\tremaining: 50.6s\n483:\tlearn: 0.2924560\ttotal: 3m 29s\tremaining: 50.2s\n484:\tlearn: 0.2920260\ttotal: 3m 29s\tremaining: 49.7s\n485:\tlearn: 0.2917909\ttotal: 3m 30s\tremaining: 49.3s\n486:\tlearn: 0.2916265\ttotal: 3m 30s\tremaining: 48.9s\n487:\tlearn: 0.2904184\ttotal: 3m 30s\tremaining: 48.4s\n488:\tlearn: 0.2901580\ttotal: 3m 31s\tremaining: 48s\n489:\tlearn: 0.2899695\ttotal: 3m 31s\tremaining: 47.6s\n490:\tlearn: 0.2897501\ttotal: 3m 32s\tremaining: 47.1s\n491:\tlearn: 0.2897178\ttotal: 3m 32s\tremaining: 46.7s\n492:\tlearn: 0.2893807\ttotal: 3m 33s\tremaining: 46.3s\n493:\tlearn: 0.2891061\ttotal: 3m 33s\tremaining: 45.8s\n494:\tlearn: 0.2885039\ttotal: 3m 33s\tremaining: 45.4s\n495:\tlearn: 0.2880962\ttotal: 3m 34s\tremaining: 45s\n496:\tlearn: 0.2875449\ttotal: 3m 34s\tremaining: 44.5s\n497:\tlearn: 0.2859735\ttotal: 3m 35s\tremaining: 44.1s\n498:\tlearn: 0.2858162\ttotal: 3m 35s\tremaining: 43.7s\n499:\tlearn: 0.2852273\ttotal: 3m 36s\tremaining: 43.2s\n500:\tlearn: 0.2850717\ttotal: 3m 36s\tremaining: 42.8s\n501:\tlearn: 0.2848582\ttotal: 3m 37s\tremaining: 42.4s\n502:\tlearn: 0.2847601\ttotal: 3m 37s\tremaining: 41.9s\n503:\tlearn: 0.2844104\ttotal: 3m 37s\tremaining: 41.5s\n504:\tlearn: 0.2840859\ttotal: 3m 38s\tremaining: 41.1s\n505:\tlearn: 0.2833119\ttotal: 3m 38s\tremaining: 40.6s\n506:\tlearn: 0.2831569\ttotal: 3m 39s\tremaining: 40.2s\n507:\tlearn: 0.2831421\ttotal: 3m 39s\tremaining: 39.8s\n508:\tlearn: 0.2830985\ttotal: 3m 39s\tremaining: 39.3s\n509:\tlearn: 0.2829648\ttotal: 3m 40s\tremaining: 38.9s\n510:\tlearn: 0.2827935\ttotal: 3m 40s\tremaining: 38.5s\n511:\tlearn: 0.2826194\ttotal: 3m 41s\tremaining: 38s\n512:\tlearn: 0.2822692\ttotal: 3m 41s\tremaining: 37.6s\n513:\tlearn: 0.2819813\ttotal: 3m 42s\tremaining: 37.2s\n514:\tlearn: 0.2814756\ttotal: 3m 42s\tremaining: 36.7s\n515:\tlearn: 0.2811573\ttotal: 3m 42s\tremaining: 36.3s\n516:\tlearn: 0.2810337\ttotal: 3m 43s\tremaining: 35.9s\n517:\tlearn: 0.2809809\ttotal: 3m 43s\tremaining: 35.4s\n518:\tlearn: 0.2808380\ttotal: 3m 44s\tremaining: 35s\n519:\tlearn: 0.2807254\ttotal: 3m 44s\tremaining: 34.6s\n520:\tlearn: 0.2806727\ttotal: 3m 45s\tremaining: 34.1s\n521:\tlearn: 0.2804849\ttotal: 3m 45s\tremaining: 33.7s\n522:\tlearn: 0.2803999\ttotal: 3m 45s\tremaining: 33.3s\n523:\tlearn: 0.2802915\ttotal: 3m 46s\tremaining: 32.8s\n524:\tlearn: 0.2802616\ttotal: 3m 46s\tremaining: 32.4s\n525:\tlearn: 0.2800676\ttotal: 3m 47s\tremaining: 32s\n526:\tlearn: 0.2798643\ttotal: 3m 47s\tremaining: 31.5s\n527:\tlearn: 0.2797917\ttotal: 3m 48s\tremaining: 31.1s\n528:\tlearn: 0.2795994\ttotal: 3m 48s\tremaining: 30.7s\n529:\tlearn: 0.2794398\ttotal: 3m 48s\tremaining: 30.2s\n530:\tlearn: 0.2789146\ttotal: 3m 49s\tremaining: 29.8s\n531:\tlearn: 0.2787257\ttotal: 3m 49s\tremaining: 29.4s\n532:\tlearn: 0.2776365\ttotal: 3m 50s\tremaining: 28.9s\n533:\tlearn: 0.2775080\ttotal: 3m 50s\tremaining: 28.5s\n534:\tlearn: 0.2772927\ttotal: 3m 51s\tremaining: 28.1s\n535:\tlearn: 0.2771795\ttotal: 3m 51s\tremaining: 27.6s\n536:\tlearn: 0.2766111\ttotal: 3m 51s\tremaining: 27.2s\n537:\tlearn: 0.2764769\ttotal: 3m 52s\tremaining: 26.8s\n538:\tlearn: 0.2763351\ttotal: 3m 52s\tremaining: 26.4s\n539:\tlearn: 0.2761427\ttotal: 3m 53s\tremaining: 25.9s\n540:\tlearn: 0.2760100\ttotal: 3m 53s\tremaining: 25.5s\n541:\tlearn: 0.2759435\ttotal: 3m 54s\tremaining: 25.1s\n542:\tlearn: 0.2757654\ttotal: 3m 54s\tremaining: 24.6s\n543:\tlearn: 0.2753752\ttotal: 3m 54s\tremaining: 24.2s\n544:\tlearn: 0.2742582\ttotal: 3m 55s\tremaining: 23.8s\n545:\tlearn: 0.2741715\ttotal: 3m 55s\tremaining: 23.3s\n546:\tlearn: 0.2740939\ttotal: 3m 56s\tremaining: 22.9s\n547:\tlearn: 0.2740717\ttotal: 3m 56s\tremaining: 22.5s\n548:\tlearn: 0.2736965\ttotal: 3m 57s\tremaining: 22s\n549:\tlearn: 0.2736395\ttotal: 3m 57s\tremaining: 21.6s\n550:\tlearn: 0.2734655\ttotal: 3m 57s\tremaining: 21.2s\n551:\tlearn: 0.2729931\ttotal: 3m 58s\tremaining: 20.7s\n552:\tlearn: 0.2720859\ttotal: 3m 58s\tremaining: 20.3s\n553:\tlearn: 0.2719522\ttotal: 3m 59s\tremaining: 19.9s\n554:\tlearn: 0.2718685\ttotal: 3m 59s\tremaining: 19.4s\n555:\tlearn: 0.2717107\ttotal: 4m\tremaining: 19s\n556:\tlearn: 0.2711715\ttotal: 4m\tremaining: 18.6s\n557:\tlearn: 0.2707787\ttotal: 4m\tremaining: 18.1s\n558:\tlearn: 0.2707088\ttotal: 4m 1s\tremaining: 17.7s\n559:\tlearn: 0.2704125\ttotal: 4m 1s\tremaining: 17.3s\n560:\tlearn: 0.2700412\ttotal: 4m 2s\tremaining: 16.8s\n561:\tlearn: 0.2699074\ttotal: 4m 2s\tremaining: 16.4s\n562:\tlearn: 0.2688290\ttotal: 4m 3s\tremaining: 16s\n563:\tlearn: 0.2683603\ttotal: 4m 3s\tremaining: 15.5s\n564:\tlearn: 0.2682015\ttotal: 4m 3s\tremaining: 15.1s\n565:\tlearn: 0.2680557\ttotal: 4m 4s\tremaining: 14.7s\n566:\tlearn: 0.2673926\ttotal: 4m 4s\tremaining: 14.2s\n567:\tlearn: 0.2673139\ttotal: 4m 5s\tremaining: 13.8s\n568:\tlearn: 0.2671733\ttotal: 4m 5s\tremaining: 13.4s\n569:\tlearn: 0.2668095\ttotal: 4m 6s\tremaining: 13s\n570:\tlearn: 0.2664879\ttotal: 4m 6s\tremaining: 12.5s\n571:\tlearn: 0.2661856\ttotal: 4m 6s\tremaining: 12.1s\n572:\tlearn: 0.2656814\ttotal: 4m 7s\tremaining: 11.7s\n573:\tlearn: 0.2655413\ttotal: 4m 7s\tremaining: 11.2s\n574:\tlearn: 0.2654196\ttotal: 4m 8s\tremaining: 10.8s\n575:\tlearn: 0.2649153\ttotal: 4m 8s\tremaining: 10.4s\n576:\tlearn: 0.2647096\ttotal: 4m 9s\tremaining: 9.93s\n577:\tlearn: 0.2643094\ttotal: 4m 9s\tremaining: 9.5s\n578:\tlearn: 0.2641559\ttotal: 4m 9s\tremaining: 9.06s\n579:\tlearn: 0.2634043\ttotal: 4m 10s\tremaining: 8.63s\n580:\tlearn: 0.2633003\ttotal: 4m 10s\tremaining: 8.2s\n581:\tlearn: 0.2631073\ttotal: 4m 11s\tremaining: 7.77s\n582:\tlearn: 0.2629947\ttotal: 4m 11s\tremaining: 7.34s\n583:\tlearn: 0.2628434\ttotal: 4m 12s\tremaining: 6.91s\n584:\tlearn: 0.2626455\ttotal: 4m 12s\tremaining: 6.47s\n585:\tlearn: 0.2626044\ttotal: 4m 12s\tremaining: 6.04s\n586:\tlearn: 0.2625423\ttotal: 4m 13s\tremaining: 5.61s\n587:\tlearn: 0.2615288\ttotal: 4m 13s\tremaining: 5.18s\n588:\tlearn: 0.2612090\ttotal: 4m 14s\tremaining: 4.75s\n589:\tlearn: 0.2611524\ttotal: 4m 14s\tremaining: 4.32s\n590:\tlearn: 0.2606373\ttotal: 4m 15s\tremaining: 3.88s\n591:\tlearn: 0.2604699\ttotal: 4m 15s\tremaining: 3.45s\n592:\tlearn: 0.2602993\ttotal: 4m 15s\tremaining: 3.02s\n593:\tlearn: 0.2601702\ttotal: 4m 16s\tremaining: 2.59s\n594:\tlearn: 0.2595313\ttotal: 4m 16s\tremaining: 2.16s\n595:\tlearn: 0.2594345\ttotal: 4m 17s\tremaining: 1.73s\n596:\tlearn: 0.2591907\ttotal: 4m 17s\tremaining: 1.29s\n597:\tlearn: 0.2572180\ttotal: 4m 18s\tremaining: 863ms\n598:\tlearn: 0.2569889\ttotal: 4m 18s\tremaining: 432ms\n599:\tlearn: 0.2568957\ttotal: 4m 19s\tremaining: 0us\ncat_fit_done\nmodel_ready\n0:\tlearn: 2.0208883\ttotal: 433ms\tremaining: 4m 19s\n1:\tlearn: 1.9734783\ttotal: 865ms\tremaining: 4m 18s\n2:\tlearn: 1.9270152\ttotal: 1.32s\tremaining: 4m 21s\n3:\tlearn: 1.8785547\ttotal: 1.77s\tremaining: 4m 23s\n4:\tlearn: 1.8482509\ttotal: 2.22s\tremaining: 4m 23s\n5:\tlearn: 1.8179059\ttotal: 2.66s\tremaining: 4m 23s\n6:\tlearn: 1.7908890\ttotal: 3.1s\tremaining: 4m 23s\n7:\tlearn: 1.7658846\ttotal: 3.55s\tremaining: 4m 22s\n8:\tlearn: 1.7358514\ttotal: 4.02s\tremaining: 4m 23s\n9:\tlearn: 1.7088747\ttotal: 4.47s\tremaining: 4m 23s\n10:\tlearn: 1.6921765\ttotal: 4.89s\tremaining: 4m 21s\n11:\tlearn: 1.6776939\ttotal: 5.32s\tremaining: 4m 20s\n12:\tlearn: 1.6598927\ttotal: 5.75s\tremaining: 4m 19s\n13:\tlearn: 1.6405972\ttotal: 6.2s\tremaining: 4m 19s\n14:\tlearn: 1.6272604\ttotal: 6.63s\tremaining: 4m 18s\n15:\tlearn: 1.6136235\ttotal: 7.06s\tremaining: 4m 17s\n16:\tlearn: 1.6038101\ttotal: 7.48s\tremaining: 4m 16s\n17:\tlearn: 1.5922887\ttotal: 7.92s\tremaining: 4m 15s\n18:\tlearn: 1.5820397\ttotal: 8.34s\tremaining: 4m 14s\n19:\tlearn: 1.5713937\ttotal: 8.77s\tremaining: 4m 14s\n20:\tlearn: 1.5510420\ttotal: 9.22s\tremaining: 4m 14s\n21:\tlearn: 1.5424875\ttotal: 9.66s\tremaining: 4m 13s\n22:\tlearn: 1.5285227\ttotal: 10.1s\tremaining: 4m 13s\n23:\tlearn: 1.5080762\ttotal: 10.5s\tremaining: 4m 13s\n24:\tlearn: 1.4953223\ttotal: 11s\tremaining: 4m 12s\n25:\tlearn: 1.4892530\ttotal: 11.4s\tremaining: 4m 11s\n26:\tlearn: 1.4802746\ttotal: 11.8s\tremaining: 4m 11s\n27:\tlearn: 1.4614551\ttotal: 12.3s\tremaining: 4m 11s\n28:\tlearn: 1.4535616\ttotal: 12.7s\tremaining: 4m 10s\n29:\tlearn: 1.4481532\ttotal: 13.2s\tremaining: 4m 10s\n30:\tlearn: 1.4382676\ttotal: 13.6s\tremaining: 4m 9s\n31:\tlearn: 1.4306498\ttotal: 14s\tremaining: 4m 9s\n32:\tlearn: 1.4228734\ttotal: 14.5s\tremaining: 4m 8s\n33:\tlearn: 1.4148840\ttotal: 14.9s\tremaining: 4m 8s\n34:\tlearn: 1.4053508\ttotal: 15.3s\tremaining: 4m 7s\n35:\tlearn: 1.3988015\ttotal: 15.8s\tremaining: 4m 6s\n36:\tlearn: 1.3912429\ttotal: 16.2s\tremaining: 4m 6s\n37:\tlearn: 1.3848875\ttotal: 16.6s\tremaining: 4m 5s\n38:\tlearn: 1.3771101\ttotal: 17.1s\tremaining: 4m 5s\n39:\tlearn: 1.3691186\ttotal: 17.5s\tremaining: 4m 4s\n40:\tlearn: 1.3639883\ttotal: 17.9s\tremaining: 4m 4s\n41:\tlearn: 1.3629664\ttotal: 18.3s\tremaining: 4m 3s\n42:\tlearn: 1.3544733\ttotal: 18.8s\tremaining: 4m 3s\n43:\tlearn: 1.3475844\ttotal: 19.2s\tremaining: 4m 2s\n44:\tlearn: 1.3424371\ttotal: 19.6s\tremaining: 4m 2s\n45:\tlearn: 1.3386278\ttotal: 20.1s\tremaining: 4m 1s\n46:\tlearn: 1.3348090\ttotal: 20.5s\tremaining: 4m 1s\n47:\tlearn: 1.3298269\ttotal: 20.9s\tremaining: 4m\n48:\tlearn: 1.3198254\ttotal: 21.4s\tremaining: 4m\n49:\tlearn: 1.3152318\ttotal: 21.8s\tremaining: 3m 59s\n50:\tlearn: 1.3098378\ttotal: 22.2s\tremaining: 3m 59s\n51:\tlearn: 1.3074821\ttotal: 22.7s\tremaining: 3m 58s\n52:\tlearn: 1.3039563\ttotal: 23.1s\tremaining: 3m 58s\n53:\tlearn: 1.3034754\ttotal: 23.5s\tremaining: 3m 57s\n54:\tlearn: 1.3028228\ttotal: 23.9s\tremaining: 3m 57s\n55:\tlearn: 1.2981937\ttotal: 24.3s\tremaining: 3m 56s\n56:\tlearn: 1.2941782\ttotal: 24.8s\tremaining: 3m 56s\n57:\tlearn: 1.2920176\ttotal: 25.2s\tremaining: 3m 55s\n58:\tlearn: 1.2889246\ttotal: 25.6s\tremaining: 3m 54s\n59:\tlearn: 1.2828933\ttotal: 26.1s\tremaining: 3m 54s\n60:\tlearn: 1.2819680\ttotal: 26.5s\tremaining: 3m 53s\n61:\tlearn: 1.2775515\ttotal: 26.9s\tremaining: 3m 53s\n62:\tlearn: 1.2709353\ttotal: 27.3s\tremaining: 3m 53s\n63:\tlearn: 1.2657119\ttotal: 27.8s\tremaining: 3m 52s\n64:\tlearn: 1.2577486\ttotal: 28.2s\tremaining: 3m 52s\n65:\tlearn: 1.2548231\ttotal: 28.6s\tremaining: 3m 51s\n66:\tlearn: 1.2513515\ttotal: 29.1s\tremaining: 3m 51s\n67:\tlearn: 1.2477213\ttotal: 29.5s\tremaining: 3m 50s\n68:\tlearn: 1.2465229\ttotal: 29.9s\tremaining: 3m 50s\n69:\tlearn: 1.2430759\ttotal: 30.3s\tremaining: 3m 49s\n70:\tlearn: 1.2353044\ttotal: 30.8s\tremaining: 3m 49s\n71:\tlearn: 1.2304933\ttotal: 31.2s\tremaining: 3m 49s\n72:\tlearn: 1.2288303\ttotal: 31.6s\tremaining: 3m 48s\n73:\tlearn: 1.2250456\ttotal: 32.1s\tremaining: 3m 47s\n74:\tlearn: 1.2199514\ttotal: 32.5s\tremaining: 3m 47s\n75:\tlearn: 1.2133252\ttotal: 33s\tremaining: 3m 47s\n76:\tlearn: 1.2069228\ttotal: 33.4s\tremaining: 3m 46s\n77:\tlearn: 1.2042686\ttotal: 33.6s\tremaining: 3m 44s\n78:\tlearn: 1.2020195\ttotal: 34s\tremaining: 3m 44s\n79:\tlearn: 1.1975068\ttotal: 34.4s\tremaining: 3m 43s\n80:\tlearn: 1.1915018\ttotal: 34.9s\tremaining: 3m 43s\n81:\tlearn: 1.1896252\ttotal: 35.3s\tremaining: 3m 42s\n82:\tlearn: 1.1845019\ttotal: 35.7s\tremaining: 3m 42s\n83:\tlearn: 1.1773012\ttotal: 36.2s\tremaining: 3m 42s\n84:\tlearn: 1.1715397\ttotal: 36.6s\tremaining: 3m 41s\n85:\tlearn: 1.1693055\ttotal: 37s\tremaining: 3m 41s\n86:\tlearn: 1.1614875\ttotal: 37.5s\tremaining: 3m 41s\n87:\tlearn: 1.1548170\ttotal: 37.9s\tremaining: 3m 40s\n88:\tlearn: 1.1507425\ttotal: 38.4s\tremaining: 3m 40s\n89:\tlearn: 1.1495038\ttotal: 38.8s\tremaining: 3m 39s\n90:\tlearn: 1.1410929\ttotal: 39.2s\tremaining: 3m 39s\n91:\tlearn: 1.1369113\ttotal: 39.7s\tremaining: 3m 39s\n92:\tlearn: 1.1301557\ttotal: 40.1s\tremaining: 3m 38s\n93:\tlearn: 1.1227365\ttotal: 40.6s\tremaining: 3m 38s\n94:\tlearn: 1.1217657\ttotal: 41s\tremaining: 3m 37s\n95:\tlearn: 1.1202587\ttotal: 41.4s\tremaining: 3m 37s\n96:\tlearn: 1.1152181\ttotal: 41.9s\tremaining: 3m 37s\n97:\tlearn: 1.1105561\ttotal: 42.3s\tremaining: 3m 36s\n98:\tlearn: 1.1089152\ttotal: 42.7s\tremaining: 3m 36s\n99:\tlearn: 1.1056709\ttotal: 43.1s\tremaining: 3m 35s\n100:\tlearn: 1.1043660\ttotal: 43.6s\tremaining: 3m 35s\n101:\tlearn: 1.0966641\ttotal: 44s\tremaining: 3m 34s\n102:\tlearn: 1.0891100\ttotal: 44.5s\tremaining: 3m 34s\n103:\tlearn: 1.0839664\ttotal: 44.9s\tremaining: 3m 34s\n104:\tlearn: 1.0751219\ttotal: 45.4s\tremaining: 3m 33s\n105:\tlearn: 1.0712581\ttotal: 45.8s\tremaining: 3m 33s\n106:\tlearn: 1.0700725\ttotal: 46.2s\tremaining: 3m 33s\n107:\tlearn: 1.0658909\ttotal: 46.7s\tremaining: 3m 32s\n108:\tlearn: 1.0642691\ttotal: 47.1s\tremaining: 3m 32s\n109:\tlearn: 1.0634591\ttotal: 47.5s\tremaining: 3m 31s\n110:\tlearn: 1.0600185\ttotal: 47.9s\tremaining: 3m 31s\n111:\tlearn: 1.0560683\ttotal: 48.4s\tremaining: 3m 30s\n112:\tlearn: 1.0504812\ttotal: 48.8s\tremaining: 3m 30s\n113:\tlearn: 1.0448890\ttotal: 49.3s\tremaining: 3m 30s\n114:\tlearn: 1.0432412\ttotal: 49.7s\tremaining: 3m 29s\n115:\tlearn: 1.0408668\ttotal: 50.1s\tremaining: 3m 29s\n116:\tlearn: 1.0385329\ttotal: 50.5s\tremaining: 3m 28s\n117:\tlearn: 1.0372059\ttotal: 51s\tremaining: 3m 28s\n118:\tlearn: 1.0363323\ttotal: 51.4s\tremaining: 3m 27s\n119:\tlearn: 1.0351281\ttotal: 51.8s\tremaining: 3m 27s\n120:\tlearn: 1.0304288\ttotal: 52.3s\tremaining: 3m 26s\n121:\tlearn: 1.0241726\ttotal: 52.7s\tremaining: 3m 26s\n122:\tlearn: 1.0185723\ttotal: 53.1s\tremaining: 3m 26s\n123:\tlearn: 1.0143009\ttotal: 53.6s\tremaining: 3m 25s\n124:\tlearn: 1.0096020\ttotal: 54s\tremaining: 3m 25s\n125:\tlearn: 1.0078312\ttotal: 54.4s\tremaining: 3m 24s\n126:\tlearn: 1.0036326\ttotal: 54.9s\tremaining: 3m 24s\n127:\tlearn: 0.9991788\ttotal: 55.3s\tremaining: 3m 24s\n128:\tlearn: 0.9954929\ttotal: 55.8s\tremaining: 3m 23s\n129:\tlearn: 0.9939036\ttotal: 56.2s\tremaining: 3m 23s\n130:\tlearn: 0.9880843\ttotal: 56.6s\tremaining: 3m 22s\n131:\tlearn: 0.9830823\ttotal: 57.1s\tremaining: 3m 22s\n132:\tlearn: 0.9800966\ttotal: 57.5s\tremaining: 3m 22s\n133:\tlearn: 0.9782134\ttotal: 58s\tremaining: 3m 21s\n134:\tlearn: 0.9743990\ttotal: 58.4s\tremaining: 3m 21s\n135:\tlearn: 0.9727266\ttotal: 58.8s\tremaining: 3m 20s\n136:\tlearn: 0.9722377\ttotal: 59.2s\tremaining: 3m 20s\n137:\tlearn: 0.9694824\ttotal: 59.7s\tremaining: 3m 19s\n138:\tlearn: 0.9688602\ttotal: 1m\tremaining: 3m 19s\n139:\tlearn: 0.9662977\ttotal: 1m\tremaining: 3m 18s\n140:\tlearn: 0.9626492\ttotal: 1m\tremaining: 3m 18s\n141:\tlearn: 0.9620451\ttotal: 1m 1s\tremaining: 3m 17s\n142:\tlearn: 0.9615422\ttotal: 1m 1s\tremaining: 3m 17s\n143:\tlearn: 0.9609018\ttotal: 1m 2s\tremaining: 3m 17s\n144:\tlearn: 0.9601217\ttotal: 1m 2s\tremaining: 3m 16s\n145:\tlearn: 0.9544204\ttotal: 1m 3s\tremaining: 3m 16s\n146:\tlearn: 0.9480650\ttotal: 1m 3s\tremaining: 3m 15s\n147:\tlearn: 0.9467086\ttotal: 1m 3s\tremaining: 3m 15s\n148:\tlearn: 0.9421561\ttotal: 1m 4s\tremaining: 3m 15s\n149:\tlearn: 0.9381187\ttotal: 1m 4s\tremaining: 3m 14s\n150:\tlearn: 0.9377291\ttotal: 1m 5s\tremaining: 3m 14s\n151:\tlearn: 0.9309692\ttotal: 1m 5s\tremaining: 3m 13s\n152:\tlearn: 0.9275648\ttotal: 1m 6s\tremaining: 3m 13s\n153:\tlearn: 0.9249923\ttotal: 1m 6s\tremaining: 3m 13s\n154:\tlearn: 0.9243027\ttotal: 1m 7s\tremaining: 3m 12s\n155:\tlearn: 0.9200615\ttotal: 1m 7s\tremaining: 3m 12s\n156:\tlearn: 0.9151725\ttotal: 1m 7s\tremaining: 3m 11s\n157:\tlearn: 0.9138434\ttotal: 1m 8s\tremaining: 3m 11s\n158:\tlearn: 0.9124607\ttotal: 1m 8s\tremaining: 3m 10s\n159:\tlearn: 0.9118555\ttotal: 1m 9s\tremaining: 3m 10s\n160:\tlearn: 0.9060880\ttotal: 1m 9s\tremaining: 3m 9s\n161:\tlearn: 0.9045187\ttotal: 1m 10s\tremaining: 3m 9s\n162:\tlearn: 0.9039789\ttotal: 1m 10s\tremaining: 3m 9s\n163:\tlearn: 0.9021634\ttotal: 1m 10s\tremaining: 3m 8s\n164:\tlearn: 0.9002588\ttotal: 1m 11s\tremaining: 3m 8s\n165:\tlearn: 0.8955478\ttotal: 1m 11s\tremaining: 3m 7s\n166:\tlearn: 0.8927725\ttotal: 1m 12s\tremaining: 3m 7s\n167:\tlearn: 0.8901811\ttotal: 1m 12s\tremaining: 3m 6s\n168:\tlearn: 0.8862476\ttotal: 1m 13s\tremaining: 3m 6s\n169:\tlearn: 0.8856175\ttotal: 1m 13s\tremaining: 3m 6s\n170:\tlearn: 0.8844873\ttotal: 1m 13s\tremaining: 3m 5s\n171:\tlearn: 0.8813495\ttotal: 1m 14s\tremaining: 3m 5s\n172:\tlearn: 0.8804326\ttotal: 1m 14s\tremaining: 3m 4s\n173:\tlearn: 0.8743807\ttotal: 1m 15s\tremaining: 3m 4s\n174:\tlearn: 0.8735348\ttotal: 1m 15s\tremaining: 3m 3s\n175:\tlearn: 0.8723284\ttotal: 1m 16s\tremaining: 3m 3s\n176:\tlearn: 0.8693865\ttotal: 1m 16s\tremaining: 3m 3s\n177:\tlearn: 0.8656349\ttotal: 1m 17s\tremaining: 3m 2s\n178:\tlearn: 0.8635536\ttotal: 1m 17s\tremaining: 3m 2s\n179:\tlearn: 0.8592660\ttotal: 1m 17s\tremaining: 3m 1s\n180:\tlearn: 0.8571598\ttotal: 1m 18s\tremaining: 3m 1s\n181:\tlearn: 0.8510960\ttotal: 1m 18s\tremaining: 3m 1s\n182:\tlearn: 0.8477169\ttotal: 1m 19s\tremaining: 3m\n183:\tlearn: 0.8461138\ttotal: 1m 19s\tremaining: 3m\n184:\tlearn: 0.8454924\ttotal: 1m 20s\tremaining: 2m 59s\n185:\tlearn: 0.8400630\ttotal: 1m 20s\tremaining: 2m 59s\n186:\tlearn: 0.8387009\ttotal: 1m 20s\tremaining: 2m 58s\n187:\tlearn: 0.8383555\ttotal: 1m 21s\tremaining: 2m 58s\n188:\tlearn: 0.8330807\ttotal: 1m 21s\tremaining: 2m 58s\n189:\tlearn: 0.8300393\ttotal: 1m 22s\tremaining: 2m 57s\n190:\tlearn: 0.8287233\ttotal: 1m 22s\tremaining: 2m 57s\n191:\tlearn: 0.8276184\ttotal: 1m 23s\tremaining: 2m 56s\n192:\tlearn: 0.8245716\ttotal: 1m 23s\tremaining: 2m 56s\n193:\tlearn: 0.8218452\ttotal: 1m 24s\tremaining: 2m 55s\n194:\tlearn: 0.8215910\ttotal: 1m 24s\tremaining: 2m 55s\n195:\tlearn: 0.8200582\ttotal: 1m 24s\tremaining: 2m 54s\n196:\tlearn: 0.8181379\ttotal: 1m 25s\tremaining: 2m 54s\n197:\tlearn: 0.8169902\ttotal: 1m 25s\tremaining: 2m 54s\n198:\tlearn: 0.8137924\ttotal: 1m 26s\tremaining: 2m 53s\n199:\tlearn: 0.8122924\ttotal: 1m 26s\tremaining: 2m 53s\n200:\tlearn: 0.8101878\ttotal: 1m 27s\tremaining: 2m 52s\n201:\tlearn: 0.8086853\ttotal: 1m 27s\tremaining: 2m 52s\n202:\tlearn: 0.8081460\ttotal: 1m 27s\tremaining: 2m 51s\n203:\tlearn: 0.8068165\ttotal: 1m 28s\tremaining: 2m 51s\n204:\tlearn: 0.8063845\ttotal: 1m 28s\tremaining: 2m 50s\n205:\tlearn: 0.8033236\ttotal: 1m 29s\tremaining: 2m 50s\n206:\tlearn: 0.7991576\ttotal: 1m 29s\tremaining: 2m 50s\n207:\tlearn: 0.7978117\ttotal: 1m 30s\tremaining: 2m 49s\n208:\tlearn: 0.7970433\ttotal: 1m 30s\tremaining: 2m 49s\n209:\tlearn: 0.7961017\ttotal: 1m 30s\tremaining: 2m 48s\n210:\tlearn: 0.7955991\ttotal: 1m 31s\tremaining: 2m 48s\n211:\tlearn: 0.7949838\ttotal: 1m 31s\tremaining: 2m 47s\n212:\tlearn: 0.7937542\ttotal: 1m 32s\tremaining: 2m 47s\n213:\tlearn: 0.7934450\ttotal: 1m 32s\tremaining: 2m 47s\n214:\tlearn: 0.7921225\ttotal: 1m 33s\tremaining: 2m 46s\n215:\tlearn: 0.7917730\ttotal: 1m 33s\tremaining: 2m 46s\n216:\tlearn: 0.7913563\ttotal: 1m 33s\tremaining: 2m 45s\n217:\tlearn: 0.7876131\ttotal: 1m 34s\tremaining: 2m 45s\n218:\tlearn: 0.7863928\ttotal: 1m 34s\tremaining: 2m 44s\n219:\tlearn: 0.7855793\ttotal: 1m 35s\tremaining: 2m 44s\n220:\tlearn: 0.7811486\ttotal: 1m 35s\tremaining: 2m 44s\n221:\tlearn: 0.7795365\ttotal: 1m 36s\tremaining: 2m 43s\n222:\tlearn: 0.7787523\ttotal: 1m 36s\tremaining: 2m 43s\n223:\tlearn: 0.7769833\ttotal: 1m 36s\tremaining: 2m 42s\n224:\tlearn: 0.7743826\ttotal: 1m 37s\tremaining: 2m 42s\n225:\tlearn: 0.7721818\ttotal: 1m 37s\tremaining: 2m 41s\n226:\tlearn: 0.7678670\ttotal: 1m 38s\tremaining: 2m 41s\n227:\tlearn: 0.7648219\ttotal: 1m 38s\tremaining: 2m 41s\n228:\tlearn: 0.7621504\ttotal: 1m 39s\tremaining: 2m 40s\n229:\tlearn: 0.7612810\ttotal: 1m 39s\tremaining: 2m 40s\n230:\tlearn: 0.7603501\ttotal: 1m 40s\tremaining: 2m 39s\n231:\tlearn: 0.7563593\ttotal: 1m 40s\tremaining: 2m 39s\n232:\tlearn: 0.7506391\ttotal: 1m 40s\tremaining: 2m 38s\n233:\tlearn: 0.7495263\ttotal: 1m 41s\tremaining: 2m 38s\n234:\tlearn: 0.7475847\ttotal: 1m 41s\tremaining: 2m 38s\n235:\tlearn: 0.7465409\ttotal: 1m 42s\tremaining: 2m 37s\n236:\tlearn: 0.7436431\ttotal: 1m 42s\tremaining: 2m 37s\n237:\tlearn: 0.7424992\ttotal: 1m 43s\tremaining: 2m 36s\n238:\tlearn: 0.7418077\ttotal: 1m 43s\tremaining: 2m 36s\n239:\tlearn: 0.7410217\ttotal: 1m 43s\tremaining: 2m 35s\n240:\tlearn: 0.7384215\ttotal: 1m 44s\tremaining: 2m 35s\n241:\tlearn: 0.7359957\ttotal: 1m 44s\tremaining: 2m 35s\n242:\tlearn: 0.7352751\ttotal: 1m 45s\tremaining: 2m 34s\n243:\tlearn: 0.7346304\ttotal: 1m 45s\tremaining: 2m 34s\n244:\tlearn: 0.7340252\ttotal: 1m 46s\tremaining: 2m 33s\n245:\tlearn: 0.7313916\ttotal: 1m 46s\tremaining: 2m 33s\n246:\tlearn: 0.7286949\ttotal: 1m 46s\tremaining: 2m 32s\n247:\tlearn: 0.7264143\ttotal: 1m 47s\tremaining: 2m 32s\n248:\tlearn: 0.7244447\ttotal: 1m 47s\tremaining: 2m 32s\n249:\tlearn: 0.7236194\ttotal: 1m 48s\tremaining: 2m 31s\n250:\tlearn: 0.7232744\ttotal: 1m 48s\tremaining: 2m 31s\n251:\tlearn: 0.7223042\ttotal: 1m 49s\tremaining: 2m 30s\n252:\tlearn: 0.7207954\ttotal: 1m 49s\tremaining: 2m 30s\n253:\tlearn: 0.7195762\ttotal: 1m 49s\tremaining: 2m 29s\n254:\tlearn: 0.7163718\ttotal: 1m 50s\tremaining: 2m 29s\n255:\tlearn: 0.7156015\ttotal: 1m 50s\tremaining: 2m 28s\n256:\tlearn: 0.7140409\ttotal: 1m 51s\tremaining: 2m 28s\n257:\tlearn: 0.7136544\ttotal: 1m 51s\tremaining: 2m 28s\n258:\tlearn: 0.7132164\ttotal: 1m 52s\tremaining: 2m 27s\n259:\tlearn: 0.7113921\ttotal: 1m 52s\tremaining: 2m 27s\n260:\tlearn: 0.7094129\ttotal: 1m 53s\tremaining: 2m 26s\n261:\tlearn: 0.7091756\ttotal: 1m 53s\tremaining: 2m 26s\n262:\tlearn: 0.7087109\ttotal: 1m 53s\tremaining: 2m 25s\n263:\tlearn: 0.7078012\ttotal: 1m 54s\tremaining: 2m 25s\n264:\tlearn: 0.7062465\ttotal: 1m 54s\tremaining: 2m 25s\n265:\tlearn: 0.7059754\ttotal: 1m 55s\tremaining: 2m 24s\n266:\tlearn: 0.7037147\ttotal: 1m 55s\tremaining: 2m 24s\n267:\tlearn: 0.7014617\ttotal: 1m 56s\tremaining: 2m 23s\n268:\tlearn: 0.7010844\ttotal: 1m 56s\tremaining: 2m 23s\n269:\tlearn: 0.7003857\ttotal: 1m 56s\tremaining: 2m 22s\n270:\tlearn: 0.6991301\ttotal: 1m 57s\tremaining: 2m 22s\n271:\tlearn: 0.6962023\ttotal: 1m 57s\tremaining: 2m 21s\n272:\tlearn: 0.6953193\ttotal: 1m 58s\tremaining: 2m 21s\n273:\tlearn: 0.6944166\ttotal: 1m 58s\tremaining: 2m 21s\n274:\tlearn: 0.6939984\ttotal: 1m 59s\tremaining: 2m 20s\n275:\tlearn: 0.6904079\ttotal: 1m 59s\tremaining: 2m 20s\n276:\tlearn: 0.6898792\ttotal: 1m 59s\tremaining: 2m 19s\n277:\tlearn: 0.6891388\ttotal: 2m\tremaining: 2m 19s\n278:\tlearn: 0.6865409\ttotal: 2m\tremaining: 2m 18s\n279:\tlearn: 0.6850149\ttotal: 2m 1s\tremaining: 2m 18s\n280:\tlearn: 0.6842228\ttotal: 2m 1s\tremaining: 2m 18s\n281:\tlearn: 0.6838450\ttotal: 2m 2s\tremaining: 2m 17s\n282:\tlearn: 0.6833176\ttotal: 2m 2s\tremaining: 2m 17s\n283:\tlearn: 0.6786415\ttotal: 2m 2s\tremaining: 2m 16s\n284:\tlearn: 0.6771751\ttotal: 2m 3s\tremaining: 2m 16s\n285:\tlearn: 0.6769466\ttotal: 2m 3s\tremaining: 2m 15s\n286:\tlearn: 0.6764018\ttotal: 2m 4s\tremaining: 2m 15s\n287:\tlearn: 0.6755997\ttotal: 2m 4s\tremaining: 2m 15s\n288:\tlearn: 0.6745574\ttotal: 2m 5s\tremaining: 2m 14s\n289:\tlearn: 0.6738607\ttotal: 2m 5s\tremaining: 2m 14s\n290:\tlearn: 0.6734157\ttotal: 2m 5s\tremaining: 2m 13s\n291:\tlearn: 0.6729659\ttotal: 2m 6s\tremaining: 2m 13s\n292:\tlearn: 0.6709500\ttotal: 2m 6s\tremaining: 2m 12s\n293:\tlearn: 0.6706601\ttotal: 2m 7s\tremaining: 2m 12s\n294:\tlearn: 0.6702115\ttotal: 2m 7s\tremaining: 2m 12s\n295:\tlearn: 0.6687643\ttotal: 2m 8s\tremaining: 2m 11s\n296:\tlearn: 0.6682609\ttotal: 2m 8s\tremaining: 2m 11s\n297:\tlearn: 0.6677400\ttotal: 2m 8s\tremaining: 2m 10s\n298:\tlearn: 0.6664635\ttotal: 2m 9s\tremaining: 2m 10s\n299:\tlearn: 0.6643106\ttotal: 2m 9s\tremaining: 2m 9s\n300:\tlearn: 0.6633054\ttotal: 2m 10s\tremaining: 2m 9s\n301:\tlearn: 0.6617230\ttotal: 2m 10s\tremaining: 2m 8s\n302:\tlearn: 0.6601662\ttotal: 2m 11s\tremaining: 2m 8s\n303:\tlearn: 0.6598589\ttotal: 2m 11s\tremaining: 2m 8s\n304:\tlearn: 0.6586500\ttotal: 2m 11s\tremaining: 2m 7s\n305:\tlearn: 0.6583421\ttotal: 2m 12s\tremaining: 2m 7s\n306:\tlearn: 0.6564336\ttotal: 2m 12s\tremaining: 2m 6s\n307:\tlearn: 0.6549936\ttotal: 2m 13s\tremaining: 2m 6s\n308:\tlearn: 0.6535694\ttotal: 2m 13s\tremaining: 2m 5s\n309:\tlearn: 0.6532180\ttotal: 2m 14s\tremaining: 2m 5s\n310:\tlearn: 0.6519622\ttotal: 2m 14s\tremaining: 2m 5s\n311:\tlearn: 0.6489503\ttotal: 2m 15s\tremaining: 2m 4s\n312:\tlearn: 0.6453159\ttotal: 2m 15s\tremaining: 2m 4s\n313:\tlearn: 0.6440908\ttotal: 2m 15s\tremaining: 2m 3s\n314:\tlearn: 0.6425820\ttotal: 2m 16s\tremaining: 2m 3s\n315:\tlearn: 0.6420651\ttotal: 2m 16s\tremaining: 2m 2s\n316:\tlearn: 0.6411083\ttotal: 2m 17s\tremaining: 2m 2s\n317:\tlearn: 0.6400939\ttotal: 2m 17s\tremaining: 2m 2s\n318:\tlearn: 0.6391758\ttotal: 2m 18s\tremaining: 2m 1s\n319:\tlearn: 0.6363717\ttotal: 2m 18s\tremaining: 2m 1s\n320:\tlearn: 0.6353344\ttotal: 2m 18s\tremaining: 2m\n321:\tlearn: 0.6349263\ttotal: 2m 19s\tremaining: 2m\n322:\tlearn: 0.6340587\ttotal: 2m 19s\tremaining: 1m 59s\n323:\tlearn: 0.6332681\ttotal: 2m 20s\tremaining: 1m 59s\n324:\tlearn: 0.6328245\ttotal: 2m 20s\tremaining: 1m 58s\n325:\tlearn: 0.6312590\ttotal: 2m 21s\tremaining: 1m 58s\n326:\tlearn: 0.6306858\ttotal: 2m 21s\tremaining: 1m 58s\n327:\tlearn: 0.6287091\ttotal: 2m 21s\tremaining: 1m 57s\n328:\tlearn: 0.6281634\ttotal: 2m 22s\tremaining: 1m 57s\n329:\tlearn: 0.6276530\ttotal: 2m 22s\tremaining: 1m 56s\n330:\tlearn: 0.6271856\ttotal: 2m 23s\tremaining: 1m 56s\n331:\tlearn: 0.6263329\ttotal: 2m 23s\tremaining: 1m 55s\n332:\tlearn: 0.6256123\ttotal: 2m 24s\tremaining: 1m 55s\n333:\tlearn: 0.6253085\ttotal: 2m 24s\tremaining: 1m 55s\n334:\tlearn: 0.6250616\ttotal: 2m 24s\tremaining: 1m 54s\n335:\tlearn: 0.6246330\ttotal: 2m 25s\tremaining: 1m 54s\n336:\tlearn: 0.6243723\ttotal: 2m 25s\tremaining: 1m 53s\n337:\tlearn: 0.6241649\ttotal: 2m 26s\tremaining: 1m 53s\n338:\tlearn: 0.6238266\ttotal: 2m 26s\tremaining: 1m 52s\n339:\tlearn: 0.6236141\ttotal: 2m 27s\tremaining: 1m 52s\n340:\tlearn: 0.6226627\ttotal: 2m 27s\tremaining: 1m 51s\n341:\tlearn: 0.6224778\ttotal: 2m 27s\tremaining: 1m 51s\n342:\tlearn: 0.6221860\ttotal: 2m 28s\tremaining: 1m 51s\n343:\tlearn: 0.6218985\ttotal: 2m 28s\tremaining: 1m 50s\n344:\tlearn: 0.6216990\ttotal: 2m 29s\tremaining: 1m 50s\n345:\tlearn: 0.6214256\ttotal: 2m 29s\tremaining: 1m 49s\n346:\tlearn: 0.6209160\ttotal: 2m 29s\tremaining: 1m 49s\n347:\tlearn: 0.6201093\ttotal: 2m 30s\tremaining: 1m 48s\n348:\tlearn: 0.6199493\ttotal: 2m 30s\tremaining: 1m 48s\n349:\tlearn: 0.6195967\ttotal: 2m 31s\tremaining: 1m 48s\n350:\tlearn: 0.6184200\ttotal: 2m 31s\tremaining: 1m 47s\n351:\tlearn: 0.6177108\ttotal: 2m 32s\tremaining: 1m 47s\n352:\tlearn: 0.6158553\ttotal: 2m 32s\tremaining: 1m 46s\n353:\tlearn: 0.6155235\ttotal: 2m 32s\tremaining: 1m 46s\n354:\tlearn: 0.6129350\ttotal: 2m 33s\tremaining: 1m 45s\n355:\tlearn: 0.6125725\ttotal: 2m 33s\tremaining: 1m 45s\n356:\tlearn: 0.6121045\ttotal: 2m 34s\tremaining: 1m 45s\n357:\tlearn: 0.6096366\ttotal: 2m 34s\tremaining: 1m 44s\n358:\tlearn: 0.6090213\ttotal: 2m 35s\tremaining: 1m 44s\n359:\tlearn: 0.6087214\ttotal: 2m 35s\tremaining: 1m 43s\n360:\tlearn: 0.6070325\ttotal: 2m 36s\tremaining: 1m 43s\n361:\tlearn: 0.6068008\ttotal: 2m 36s\tremaining: 1m 42s\n362:\tlearn: 0.6066715\ttotal: 2m 36s\tremaining: 1m 42s\n363:\tlearn: 0.6062566\ttotal: 2m 37s\tremaining: 1m 41s\n364:\tlearn: 0.6043186\ttotal: 2m 37s\tremaining: 1m 41s\n365:\tlearn: 0.6035726\ttotal: 2m 38s\tremaining: 1m 41s\n366:\tlearn: 0.6021987\ttotal: 2m 38s\tremaining: 1m 40s\n367:\tlearn: 0.6018556\ttotal: 2m 39s\tremaining: 1m 40s\n368:\tlearn: 0.5996331\ttotal: 2m 39s\tremaining: 1m 39s\n369:\tlearn: 0.5994655\ttotal: 2m 39s\tremaining: 1m 39s\n370:\tlearn: 0.5992994\ttotal: 2m 40s\tremaining: 1m 38s\n371:\tlearn: 0.5990023\ttotal: 2m 40s\tremaining: 1m 38s\n372:\tlearn: 0.5983268\ttotal: 2m 41s\tremaining: 1m 38s\n373:\tlearn: 0.5969963\ttotal: 2m 41s\tremaining: 1m 37s\n374:\tlearn: 0.5945445\ttotal: 2m 42s\tremaining: 1m 37s\n375:\tlearn: 0.5940857\ttotal: 2m 42s\tremaining: 1m 36s\n376:\tlearn: 0.5936239\ttotal: 2m 42s\tremaining: 1m 36s\n377:\tlearn: 0.5928762\ttotal: 2m 43s\tremaining: 1m 35s\n378:\tlearn: 0.5897835\ttotal: 2m 43s\tremaining: 1m 35s\n379:\tlearn: 0.5897077\ttotal: 2m 44s\tremaining: 1m 35s\n380:\tlearn: 0.5887720\ttotal: 2m 44s\tremaining: 1m 34s\n381:\tlearn: 0.5885351\ttotal: 2m 45s\tremaining: 1m 34s\n382:\tlearn: 0.5881498\ttotal: 2m 45s\tremaining: 1m 33s\n383:\tlearn: 0.5880304\ttotal: 2m 45s\tremaining: 1m 33s\n384:\tlearn: 0.5866449\ttotal: 2m 46s\tremaining: 1m 32s\n385:\tlearn: 0.5845151\ttotal: 2m 46s\tremaining: 1m 32s\n386:\tlearn: 0.5819338\ttotal: 2m 47s\tremaining: 1m 32s\n387:\tlearn: 0.5811380\ttotal: 2m 47s\tremaining: 1m 31s\n388:\tlearn: 0.5800105\ttotal: 2m 48s\tremaining: 1m 31s\n389:\tlearn: 0.5795016\ttotal: 2m 48s\tremaining: 1m 30s\n390:\tlearn: 0.5792051\ttotal: 2m 48s\tremaining: 1m 30s\n391:\tlearn: 0.5783477\ttotal: 2m 49s\tremaining: 1m 29s\n392:\tlearn: 0.5781940\ttotal: 2m 49s\tremaining: 1m 29s\n393:\tlearn: 0.5780825\ttotal: 2m 50s\tremaining: 1m 29s\n394:\tlearn: 0.5772693\ttotal: 2m 50s\tremaining: 1m 28s\n395:\tlearn: 0.5771149\ttotal: 2m 51s\tremaining: 1m 28s\n396:\tlearn: 0.5760351\ttotal: 2m 51s\tremaining: 1m 27s\n397:\tlearn: 0.5759225\ttotal: 2m 51s\tremaining: 1m 27s\n398:\tlearn: 0.5750272\ttotal: 2m 52s\tremaining: 1m 26s\n399:\tlearn: 0.5745798\ttotal: 2m 52s\tremaining: 1m 26s\n400:\tlearn: 0.5718904\ttotal: 2m 53s\tremaining: 1m 25s\n401:\tlearn: 0.5698845\ttotal: 2m 53s\tremaining: 1m 25s\n402:\tlearn: 0.5693493\ttotal: 2m 54s\tremaining: 1m 25s\n403:\tlearn: 0.5689778\ttotal: 2m 54s\tremaining: 1m 24s\n404:\tlearn: 0.5687554\ttotal: 2m 54s\tremaining: 1m 24s\n405:\tlearn: 0.5664461\ttotal: 2m 55s\tremaining: 1m 23s\n406:\tlearn: 0.5650986\ttotal: 2m 55s\tremaining: 1m 23s\n407:\tlearn: 0.5632528\ttotal: 2m 56s\tremaining: 1m 22s\n408:\tlearn: 0.5624256\ttotal: 2m 56s\tremaining: 1m 22s\n409:\tlearn: 0.5618007\ttotal: 2m 57s\tremaining: 1m 22s\n410:\tlearn: 0.5606593\ttotal: 2m 57s\tremaining: 1m 21s\n411:\tlearn: 0.5560031\ttotal: 2m 58s\tremaining: 1m 21s\n412:\tlearn: 0.5543386\ttotal: 2m 58s\tremaining: 1m 20s\n413:\tlearn: 0.5532786\ttotal: 2m 59s\tremaining: 1m 20s\n414:\tlearn: 0.5530462\ttotal: 2m 59s\tremaining: 1m 19s\n415:\tlearn: 0.5521038\ttotal: 2m 59s\tremaining: 1m 19s\n416:\tlearn: 0.5513253\ttotal: 3m\tremaining: 1m 19s\n417:\tlearn: 0.5507987\ttotal: 3m\tremaining: 1m 18s\n418:\tlearn: 0.5500425\ttotal: 3m 1s\tremaining: 1m 18s\n419:\tlearn: 0.5499191\ttotal: 3m 1s\tremaining: 1m 17s\n420:\tlearn: 0.5492599\ttotal: 3m 1s\tremaining: 1m 17s\n421:\tlearn: 0.5488956\ttotal: 3m 2s\tremaining: 1m 16s\n422:\tlearn: 0.5487947\ttotal: 3m 2s\tremaining: 1m 16s\n423:\tlearn: 0.5480608\ttotal: 3m 3s\tremaining: 1m 16s\n424:\tlearn: 0.5472434\ttotal: 3m 3s\tremaining: 1m 15s\n425:\tlearn: 0.5470870\ttotal: 3m 4s\tremaining: 1m 15s\n426:\tlearn: 0.5463165\ttotal: 3m 4s\tremaining: 1m 14s\n427:\tlearn: 0.5452355\ttotal: 3m 4s\tremaining: 1m 14s\n428:\tlearn: 0.5449345\ttotal: 3m 5s\tremaining: 1m 13s\n429:\tlearn: 0.5446689\ttotal: 3m 5s\tremaining: 1m 13s\n430:\tlearn: 0.5442142\ttotal: 3m 6s\tremaining: 1m 13s\n431:\tlearn: 0.5438833\ttotal: 3m 6s\tremaining: 1m 12s\n432:\tlearn: 0.5432029\ttotal: 3m 7s\tremaining: 1m 12s\n433:\tlearn: 0.5429965\ttotal: 3m 7s\tremaining: 1m 11s\n434:\tlearn: 0.5427104\ttotal: 3m 8s\tremaining: 1m 11s\n435:\tlearn: 0.5426289\ttotal: 3m 8s\tremaining: 1m 10s\n436:\tlearn: 0.5401037\ttotal: 3m 8s\tremaining: 1m 10s\n437:\tlearn: 0.5394857\ttotal: 3m 9s\tremaining: 1m 10s\n438:\tlearn: 0.5389593\ttotal: 3m 9s\tremaining: 1m 9s\n439:\tlearn: 0.5387475\ttotal: 3m 10s\tremaining: 1m 9s\n440:\tlearn: 0.5385049\ttotal: 3m 10s\tremaining: 1m 8s\n441:\tlearn: 0.5378491\ttotal: 3m 11s\tremaining: 1m 8s\n442:\tlearn: 0.5373340\ttotal: 3m 11s\tremaining: 1m 7s\n443:\tlearn: 0.5372126\ttotal: 3m 11s\tremaining: 1m 7s\n444:\tlearn: 0.5368302\ttotal: 3m 12s\tremaining: 1m 6s\n445:\tlearn: 0.5364362\ttotal: 3m 12s\tremaining: 1m 6s\n446:\tlearn: 0.5354807\ttotal: 3m 13s\tremaining: 1m 6s\n447:\tlearn: 0.5348023\ttotal: 3m 13s\tremaining: 1m 5s\n448:\tlearn: 0.5345220\ttotal: 3m 14s\tremaining: 1m 5s\n449:\tlearn: 0.5338688\ttotal: 3m 14s\tremaining: 1m 4s\n450:\tlearn: 0.5328917\ttotal: 3m 14s\tremaining: 1m 4s\n451:\tlearn: 0.5324746\ttotal: 3m 15s\tremaining: 1m 3s\n452:\tlearn: 0.5313546\ttotal: 3m 15s\tremaining: 1m 3s\n453:\tlearn: 0.5312122\ttotal: 3m 16s\tremaining: 1m 3s\n454:\tlearn: 0.5309744\ttotal: 3m 16s\tremaining: 1m 2s\n455:\tlearn: 0.5308237\ttotal: 3m 17s\tremaining: 1m 2s\n456:\tlearn: 0.5306896\ttotal: 3m 17s\tremaining: 1m 1s\n457:\tlearn: 0.5303264\ttotal: 3m 17s\tremaining: 1m 1s\n458:\tlearn: 0.5290756\ttotal: 3m 18s\tremaining: 1m\n459:\tlearn: 0.5288649\ttotal: 3m 18s\tremaining: 1m\n460:\tlearn: 0.5287854\ttotal: 3m 19s\tremaining: 1m\n461:\tlearn: 0.5278120\ttotal: 3m 19s\tremaining: 59.6s\n462:\tlearn: 0.5276954\ttotal: 3m 19s\tremaining: 59.2s\n463:\tlearn: 0.5275780\ttotal: 3m 20s\tremaining: 58.7s\n464:\tlearn: 0.5264759\ttotal: 3m 20s\tremaining: 58.3s\n465:\tlearn: 0.5262407\ttotal: 3m 21s\tremaining: 57.9s\n466:\tlearn: 0.5251706\ttotal: 3m 21s\tremaining: 57.4s\n467:\tlearn: 0.5249196\ttotal: 3m 22s\tremaining: 57s\n468:\tlearn: 0.5231934\ttotal: 3m 22s\tremaining: 56.6s\n469:\tlearn: 0.5229203\ttotal: 3m 22s\tremaining: 56.1s\n470:\tlearn: 0.5223378\ttotal: 3m 23s\tremaining: 55.7s\n471:\tlearn: 0.5206028\ttotal: 3m 23s\tremaining: 55.3s\n472:\tlearn: 0.5196190\ttotal: 3m 24s\tremaining: 54.9s\n473:\tlearn: 0.5194418\ttotal: 3m 24s\tremaining: 54.4s\n474:\tlearn: 0.5192308\ttotal: 3m 25s\tremaining: 54s\n475:\tlearn: 0.5188632\ttotal: 3m 25s\tremaining: 53.6s\n476:\tlearn: 0.5186188\ttotal: 3m 25s\tremaining: 53.1s\n477:\tlearn: 0.5184468\ttotal: 3m 26s\tremaining: 52.7s\n478:\tlearn: 0.5169479\ttotal: 3m 26s\tremaining: 52.3s\n479:\tlearn: 0.5166511\ttotal: 3m 27s\tremaining: 51.8s\n480:\tlearn: 0.5164630\ttotal: 3m 27s\tremaining: 51.4s\n481:\tlearn: 0.5162731\ttotal: 3m 28s\tremaining: 51s\n482:\tlearn: 0.5161244\ttotal: 3m 28s\tremaining: 50.5s\n483:\tlearn: 0.5160583\ttotal: 3m 28s\tremaining: 50.1s\n484:\tlearn: 0.5159246\ttotal: 3m 29s\tremaining: 49.7s\n485:\tlearn: 0.5157714\ttotal: 3m 29s\tremaining: 49.2s\n486:\tlearn: 0.5151178\ttotal: 3m 30s\tremaining: 48.8s\n487:\tlearn: 0.5148386\ttotal: 3m 30s\tremaining: 48.4s\n488:\tlearn: 0.5142549\ttotal: 3m 31s\tremaining: 47.9s\n489:\tlearn: 0.5140527\ttotal: 3m 31s\tremaining: 47.5s\n490:\tlearn: 0.5126060\ttotal: 3m 31s\tremaining: 47.1s\n491:\tlearn: 0.5119587\ttotal: 3m 32s\tremaining: 46.6s\n492:\tlearn: 0.5118139\ttotal: 3m 32s\tremaining: 46.2s\n493:\tlearn: 0.5115425\ttotal: 3m 33s\tremaining: 45.8s\n494:\tlearn: 0.5114887\ttotal: 3m 33s\tremaining: 45.3s\n495:\tlearn: 0.5114004\ttotal: 3m 34s\tremaining: 44.9s\n496:\tlearn: 0.5107490\ttotal: 3m 34s\tremaining: 44.5s\n497:\tlearn: 0.5106529\ttotal: 3m 34s\tremaining: 44s\n498:\tlearn: 0.5102280\ttotal: 3m 35s\tremaining: 43.6s\n499:\tlearn: 0.5098924\ttotal: 3m 35s\tremaining: 43.2s\n500:\tlearn: 0.5095374\ttotal: 3m 36s\tremaining: 42.7s\n501:\tlearn: 0.5093197\ttotal: 3m 36s\tremaining: 42.3s\n502:\tlearn: 0.5091989\ttotal: 3m 37s\tremaining: 41.9s\n503:\tlearn: 0.5090498\ttotal: 3m 37s\tremaining: 41.4s\n504:\tlearn: 0.5089155\ttotal: 3m 37s\tremaining: 41s\n505:\tlearn: 0.5086455\ttotal: 3m 38s\tremaining: 40.6s\n506:\tlearn: 0.5083341\ttotal: 3m 38s\tremaining: 40.1s\n507:\tlearn: 0.5076872\ttotal: 3m 39s\tremaining: 39.7s\n508:\tlearn: 0.5075594\ttotal: 3m 39s\tremaining: 39.3s\n509:\tlearn: 0.5074314\ttotal: 3m 40s\tremaining: 38.8s\n510:\tlearn: 0.5073354\ttotal: 3m 40s\tremaining: 38.4s\n511:\tlearn: 0.5072852\ttotal: 3m 40s\tremaining: 38s\n512:\tlearn: 0.5071201\ttotal: 3m 41s\tremaining: 37.5s\n513:\tlearn: 0.5067803\ttotal: 3m 41s\tremaining: 37.1s\n514:\tlearn: 0.5064335\ttotal: 3m 42s\tremaining: 36.7s\n515:\tlearn: 0.5063055\ttotal: 3m 42s\tremaining: 36.2s\n516:\tlearn: 0.5062259\ttotal: 3m 43s\tremaining: 35.8s\n517:\tlearn: 0.5057983\ttotal: 3m 43s\tremaining: 35.4s\n518:\tlearn: 0.5048834\ttotal: 3m 43s\tremaining: 34.9s\n519:\tlearn: 0.5042613\ttotal: 3m 44s\tremaining: 34.5s\n520:\tlearn: 0.5029516\ttotal: 3m 44s\tremaining: 34.1s\n521:\tlearn: 0.5028341\ttotal: 3m 45s\tremaining: 33.7s\n522:\tlearn: 0.5026909\ttotal: 3m 45s\tremaining: 33.2s\n523:\tlearn: 0.5025034\ttotal: 3m 46s\tremaining: 32.8s\n524:\tlearn: 0.5022076\ttotal: 3m 46s\tremaining: 32.4s\n525:\tlearn: 0.5016933\ttotal: 3m 46s\tremaining: 31.9s\n526:\tlearn: 0.5015751\ttotal: 3m 47s\tremaining: 31.5s\n527:\tlearn: 0.5009351\ttotal: 3m 47s\tremaining: 31.1s\n528:\tlearn: 0.5008504\ttotal: 3m 48s\tremaining: 30.6s\n529:\tlearn: 0.5007517\ttotal: 3m 48s\tremaining: 30.2s\n530:\tlearn: 0.5006156\ttotal: 3m 49s\tremaining: 29.8s\n531:\tlearn: 0.4996912\ttotal: 3m 49s\tremaining: 29.3s\n532:\tlearn: 0.4994240\ttotal: 3m 49s\tremaining: 28.9s\n533:\tlearn: 0.4989469\ttotal: 3m 50s\tremaining: 28.5s\n534:\tlearn: 0.4986096\ttotal: 3m 50s\tremaining: 28s\n535:\tlearn: 0.4984276\ttotal: 3m 51s\tremaining: 27.6s\n536:\tlearn: 0.4979207\ttotal: 3m 51s\tremaining: 27.2s\n537:\tlearn: 0.4968937\ttotal: 3m 52s\tremaining: 26.7s\n538:\tlearn: 0.4957642\ttotal: 3m 52s\tremaining: 26.3s\n539:\tlearn: 0.4955659\ttotal: 3m 52s\tremaining: 25.9s\n540:\tlearn: 0.4936375\ttotal: 3m 53s\tremaining: 25.5s\n541:\tlearn: 0.4932088\ttotal: 3m 53s\tremaining: 25s\n542:\tlearn: 0.4930405\ttotal: 3m 54s\tremaining: 24.6s\n543:\tlearn: 0.4928130\ttotal: 3m 54s\tremaining: 24.2s\n544:\tlearn: 0.4919203\ttotal: 3m 55s\tremaining: 23.7s\n545:\tlearn: 0.4915440\ttotal: 3m 55s\tremaining: 23.3s\n546:\tlearn: 0.4912301\ttotal: 3m 55s\tremaining: 22.9s\n547:\tlearn: 0.4904788\ttotal: 3m 56s\tremaining: 22.4s\n548:\tlearn: 0.4902482\ttotal: 3m 56s\tremaining: 22s\n549:\tlearn: 0.4893842\ttotal: 3m 57s\tremaining: 21.6s\n550:\tlearn: 0.4886227\ttotal: 3m 57s\tremaining: 21.1s\n551:\tlearn: 0.4885556\ttotal: 3m 58s\tremaining: 20.7s\n552:\tlearn: 0.4868901\ttotal: 3m 58s\tremaining: 20.3s\n553:\tlearn: 0.4867170\ttotal: 3m 58s\tremaining: 19.8s\n554:\tlearn: 0.4864417\ttotal: 3m 59s\tremaining: 19.4s\n555:\tlearn: 0.4860557\ttotal: 3m 59s\tremaining: 19s\n556:\tlearn: 0.4859496\ttotal: 4m\tremaining: 18.5s\n557:\tlearn: 0.4850105\ttotal: 4m\tremaining: 18.1s\n558:\tlearn: 0.4844275\ttotal: 4m 1s\tremaining: 17.7s\n559:\tlearn: 0.4838884\ttotal: 4m 1s\tremaining: 17.3s\n560:\tlearn: 0.4836697\ttotal: 4m 1s\tremaining: 16.8s\n561:\tlearn: 0.4833888\ttotal: 4m 2s\tremaining: 16.4s\n562:\tlearn: 0.4814744\ttotal: 4m 2s\tremaining: 16s\n563:\tlearn: 0.4805572\ttotal: 4m 3s\tremaining: 15.5s\n564:\tlearn: 0.4804913\ttotal: 4m 3s\tremaining: 15.1s\n565:\tlearn: 0.4801215\ttotal: 4m 4s\tremaining: 14.7s\n566:\tlearn: 0.4797360\ttotal: 4m 4s\tremaining: 14.2s\n567:\tlearn: 0.4794660\ttotal: 4m 5s\tremaining: 13.8s\n568:\tlearn: 0.4790247\ttotal: 4m 5s\tremaining: 13.4s\n569:\tlearn: 0.4788540\ttotal: 4m 5s\tremaining: 12.9s\n570:\tlearn: 0.4776574\ttotal: 4m 6s\tremaining: 12.5s\n571:\tlearn: 0.4775045\ttotal: 4m 6s\tremaining: 12.1s\n572:\tlearn: 0.4763939\ttotal: 4m 7s\tremaining: 11.6s\n573:\tlearn: 0.4758508\ttotal: 4m 7s\tremaining: 11.2s\n574:\tlearn: 0.4748683\ttotal: 4m 8s\tremaining: 10.8s\n575:\tlearn: 0.4745254\ttotal: 4m 8s\tremaining: 10.4s\n576:\tlearn: 0.4742076\ttotal: 4m 8s\tremaining: 9.92s\n577:\tlearn: 0.4734766\ttotal: 4m 9s\tremaining: 9.49s\n578:\tlearn: 0.4732105\ttotal: 4m 9s\tremaining: 9.06s\n579:\tlearn: 0.4730603\ttotal: 4m 10s\tremaining: 8.63s\n580:\tlearn: 0.4716233\ttotal: 4m 10s\tremaining: 8.2s\n581:\tlearn: 0.4712130\ttotal: 4m 11s\tremaining: 7.76s\n582:\tlearn: 0.4711020\ttotal: 4m 11s\tremaining: 7.33s\n583:\tlearn: 0.4697528\ttotal: 4m 11s\tremaining: 6.9s\n584:\tlearn: 0.4695689\ttotal: 4m 12s\tremaining: 6.47s\n585:\tlearn: 0.4695248\ttotal: 4m 12s\tremaining: 6.04s\n586:\tlearn: 0.4694737\ttotal: 4m 13s\tremaining: 5.61s\n587:\tlearn: 0.4689961\ttotal: 4m 13s\tremaining: 5.18s\n588:\tlearn: 0.4686296\ttotal: 4m 14s\tremaining: 4.75s\n589:\tlearn: 0.4685771\ttotal: 4m 14s\tremaining: 4.31s\n590:\tlearn: 0.4684821\ttotal: 4m 14s\tremaining: 3.88s\n591:\tlearn: 0.4677946\ttotal: 4m 15s\tremaining: 3.45s\n592:\tlearn: 0.4677026\ttotal: 4m 15s\tremaining: 3.02s\n593:\tlearn: 0.4675892\ttotal: 4m 16s\tremaining: 2.59s\n594:\tlearn: 0.4669074\ttotal: 4m 16s\tremaining: 2.16s\n595:\tlearn: 0.4667748\ttotal: 4m 17s\tremaining: 1.73s\n596:\tlearn: 0.4663472\ttotal: 4m 17s\tremaining: 1.29s\n597:\tlearn: 0.4661572\ttotal: 4m 17s\tremaining: 863ms\n598:\tlearn: 0.4651691\ttotal: 4m 18s\tremaining: 431ms\n599:\tlearn: 0.4650980\ttotal: 4m 18s\tremaining: 0us\ncat_fit_done\nmodel_ready\n0:\tlearn: 2.7768493\ttotal: 201ms\tremaining: 2m\n1:\tlearn: 2.6919520\ttotal: 400ms\tremaining: 1m 59s\n2:\tlearn: 2.5679861\ttotal: 601ms\tremaining: 1m 59s\n3:\tlearn: 2.4794816\ttotal: 804ms\tremaining: 1m 59s\n4:\tlearn: 2.3850175\ttotal: 1.01s\tremaining: 1m 59s\n5:\tlearn: 2.3234777\ttotal: 1.21s\tremaining: 1m 59s\n6:\tlearn: 2.2369275\ttotal: 1.41s\tremaining: 1m 59s\n7:\tlearn: 2.1617552\ttotal: 1.61s\tremaining: 1m 59s\n8:\tlearn: 2.0816229\ttotal: 1.82s\tremaining: 1m 59s\n9:\tlearn: 2.0370223\ttotal: 2.02s\tremaining: 1m 59s\n10:\tlearn: 1.9828879\ttotal: 2.22s\tremaining: 1m 58s\n11:\tlearn: 1.9065055\ttotal: 2.42s\tremaining: 1m 58s\n12:\tlearn: 1.8634167\ttotal: 2.63s\tremaining: 1m 58s\n13:\tlearn: 1.8086494\ttotal: 2.83s\tremaining: 1m 58s\n14:\tlearn: 1.7673139\ttotal: 3.04s\tremaining: 1m 58s\n15:\tlearn: 1.7175475\ttotal: 3.24s\tremaining: 1m 58s\n16:\tlearn: 1.6576023\ttotal: 3.44s\tremaining: 1m 58s\n17:\tlearn: 1.6233585\ttotal: 3.65s\tremaining: 1m 58s\n18:\tlearn: 1.5976344\ttotal: 3.85s\tremaining: 1m 57s\n19:\tlearn: 1.5853500\ttotal: 4.05s\tremaining: 1m 57s\n20:\tlearn: 1.5433193\ttotal: 4.25s\tremaining: 1m 57s\n21:\tlearn: 1.5107871\ttotal: 4.45s\tremaining: 1m 57s\n22:\tlearn: 1.4759161\ttotal: 4.66s\tremaining: 1m 56s\n23:\tlearn: 1.4375743\ttotal: 4.86s\tremaining: 1m 56s\n24:\tlearn: 1.4056369\ttotal: 5.06s\tremaining: 1m 56s\n25:\tlearn: 1.3867546\ttotal: 5.26s\tremaining: 1m 56s\n26:\tlearn: 1.3594093\ttotal: 5.46s\tremaining: 1m 55s\n27:\tlearn: 1.3181636\ttotal: 5.67s\tremaining: 1m 55s\n28:\tlearn: 1.2997031\ttotal: 5.86s\tremaining: 1m 55s\n29:\tlearn: 1.2811519\ttotal: 6.06s\tremaining: 1m 55s\n30:\tlearn: 1.2577573\ttotal: 6.26s\tremaining: 1m 54s\n31:\tlearn: 1.2374858\ttotal: 6.47s\tremaining: 1m 54s\n32:\tlearn: 1.2171015\ttotal: 6.67s\tremaining: 1m 54s\n33:\tlearn: 1.1914795\ttotal: 6.86s\tremaining: 1m 54s\n34:\tlearn: 1.1764588\ttotal: 7.07s\tremaining: 1m 54s\n35:\tlearn: 1.1642642\ttotal: 7.27s\tremaining: 1m 53s\n36:\tlearn: 1.1439871\ttotal: 7.47s\tremaining: 1m 53s\n37:\tlearn: 1.1319416\ttotal: 7.67s\tremaining: 1m 53s\n38:\tlearn: 1.1137619\ttotal: 7.87s\tremaining: 1m 53s\n39:\tlearn: 1.1001355\ttotal: 8.07s\tremaining: 1m 52s\n40:\tlearn: 1.0846349\ttotal: 8.27s\tremaining: 1m 52s\n41:\tlearn: 1.0711508\ttotal: 8.47s\tremaining: 1m 52s\n42:\tlearn: 1.0434658\ttotal: 8.68s\tremaining: 1m 52s\n43:\tlearn: 1.0180563\ttotal: 8.88s\tremaining: 1m 52s\n44:\tlearn: 1.0061886\ttotal: 9.09s\tremaining: 1m 52s\n45:\tlearn: 0.9945865\ttotal: 9.29s\tremaining: 1m 51s\n46:\tlearn: 0.9837944\ttotal: 9.49s\tremaining: 1m 51s\n47:\tlearn: 0.9663819\ttotal: 9.69s\tremaining: 1m 51s\n48:\tlearn: 0.9594329\ttotal: 9.89s\tremaining: 1m 51s\n49:\tlearn: 0.9448582\ttotal: 10.1s\tremaining: 1m 51s\n50:\tlearn: 0.9361413\ttotal: 10.3s\tremaining: 1m 50s\n51:\tlearn: 0.9257036\ttotal: 10.5s\tremaining: 1m 50s\n52:\tlearn: 0.9195509\ttotal: 10.7s\tremaining: 1m 50s\n53:\tlearn: 0.9052920\ttotal: 10.9s\tremaining: 1m 50s\n54:\tlearn: 0.8904410\ttotal: 11.1s\tremaining: 1m 49s\n55:\tlearn: 0.8815756\ttotal: 11.3s\tremaining: 1m 49s\n56:\tlearn: 0.8643608\ttotal: 11.5s\tremaining: 1m 49s\n57:\tlearn: 0.8579663\ttotal: 11.7s\tremaining: 1m 49s\n58:\tlearn: 0.8489995\ttotal: 11.9s\tremaining: 1m 49s\n59:\tlearn: 0.8315135\ttotal: 12.1s\tremaining: 1m 48s\n60:\tlearn: 0.8228161\ttotal: 12.3s\tremaining: 1m 48s\n61:\tlearn: 0.8122201\ttotal: 12.5s\tremaining: 1m 48s\n62:\tlearn: 0.8082439\ttotal: 12.7s\tremaining: 1m 48s\n63:\tlearn: 0.8014806\ttotal: 12.9s\tremaining: 1m 48s\n64:\tlearn: 0.7828418\ttotal: 13.1s\tremaining: 1m 47s\n65:\tlearn: 0.7721627\ttotal: 13.3s\tremaining: 1m 47s\n66:\tlearn: 0.7624135\ttotal: 13.5s\tremaining: 1m 47s\n67:\tlearn: 0.7501603\ttotal: 13.7s\tremaining: 1m 47s\n68:\tlearn: 0.7368246\ttotal: 13.9s\tremaining: 1m 47s\n69:\tlearn: 0.7320288\ttotal: 14.1s\tremaining: 1m 47s\n70:\tlearn: 0.7117138\ttotal: 14.3s\tremaining: 1m 46s\n71:\tlearn: 0.7005649\ttotal: 14.5s\tremaining: 1m 46s\n72:\tlearn: 0.6914481\ttotal: 14.7s\tremaining: 1m 46s\n73:\tlearn: 0.6692718\ttotal: 14.9s\tremaining: 1m 46s\n74:\tlearn: 0.6659615\ttotal: 15.2s\tremaining: 1m 46s\n75:\tlearn: 0.6546847\ttotal: 15.4s\tremaining: 1m 45s\n76:\tlearn: 0.6470894\ttotal: 15.6s\tremaining: 1m 45s\n77:\tlearn: 0.6425708\ttotal: 15.8s\tremaining: 1m 45s\n78:\tlearn: 0.6286569\ttotal: 16s\tremaining: 1m 45s\n79:\tlearn: 0.6104443\ttotal: 16.2s\tremaining: 1m 45s\n80:\tlearn: 0.5993967\ttotal: 16.4s\tremaining: 1m 44s\n81:\tlearn: 0.5913960\ttotal: 16.6s\tremaining: 1m 44s\n82:\tlearn: 0.5845159\ttotal: 16.8s\tremaining: 1m 44s\n83:\tlearn: 0.5688266\ttotal: 17s\tremaining: 1m 44s\n84:\tlearn: 0.5568371\ttotal: 17.2s\tremaining: 1m 44s\n85:\tlearn: 0.5419476\ttotal: 17.4s\tremaining: 1m 44s\n86:\tlearn: 0.5392243\ttotal: 17.6s\tremaining: 1m 43s\n87:\tlearn: 0.5337959\ttotal: 17.8s\tremaining: 1m 43s\n88:\tlearn: 0.5298286\ttotal: 18s\tremaining: 1m 43s\n89:\tlearn: 0.5215292\ttotal: 18.2s\tremaining: 1m 43s\n90:\tlearn: 0.5174360\ttotal: 18.4s\tremaining: 1m 43s\n91:\tlearn: 0.5099519\ttotal: 18.6s\tremaining: 1m 42s\n92:\tlearn: 0.5030839\ttotal: 18.8s\tremaining: 1m 42s\n93:\tlearn: 0.4995452\ttotal: 19s\tremaining: 1m 42s\n94:\tlearn: 0.4934282\ttotal: 19.2s\tremaining: 1m 42s\n95:\tlearn: 0.4832454\ttotal: 19.4s\tremaining: 1m 42s\n96:\tlearn: 0.4739608\ttotal: 19.6s\tremaining: 1m 41s\n97:\tlearn: 0.4643711\ttotal: 19.9s\tremaining: 1m 41s\n98:\tlearn: 0.4583225\ttotal: 20.1s\tremaining: 1m 41s\n99:\tlearn: 0.4531939\ttotal: 20.3s\tremaining: 1m 41s\n100:\tlearn: 0.4448113\ttotal: 20.5s\tremaining: 1m 41s\n101:\tlearn: 0.4413138\ttotal: 20.7s\tremaining: 1m 40s\n102:\tlearn: 0.4368175\ttotal: 20.9s\tremaining: 1m 40s\n103:\tlearn: 0.4318935\ttotal: 21.1s\tremaining: 1m 40s\n104:\tlearn: 0.4272855\ttotal: 21.3s\tremaining: 1m 40s\n105:\tlearn: 0.4228914\ttotal: 21.5s\tremaining: 1m 40s\n106:\tlearn: 0.4186939\ttotal: 21.7s\tremaining: 1m 39s\n107:\tlearn: 0.4166210\ttotal: 21.9s\tremaining: 1m 39s\n108:\tlearn: 0.4108386\ttotal: 22.1s\tremaining: 1m 39s\n109:\tlearn: 0.4084260\ttotal: 22.3s\tremaining: 1m 39s\n110:\tlearn: 0.4065632\ttotal: 22.5s\tremaining: 1m 39s\n111:\tlearn: 0.4045490\ttotal: 22.7s\tremaining: 1m 38s\n112:\tlearn: 0.3980685\ttotal: 22.9s\tremaining: 1m 38s\n113:\tlearn: 0.3944355\ttotal: 23.1s\tremaining: 1m 38s\n114:\tlearn: 0.3912083\ttotal: 23.3s\tremaining: 1m 38s\n115:\tlearn: 0.3889964\ttotal: 23.6s\tremaining: 1m 38s\n116:\tlearn: 0.3845561\ttotal: 23.8s\tremaining: 1m 38s\n117:\tlearn: 0.3781555\ttotal: 24s\tremaining: 1m 37s\n118:\tlearn: 0.3722438\ttotal: 24.2s\tremaining: 1m 37s\n119:\tlearn: 0.3687611\ttotal: 24.4s\tremaining: 1m 37s\n120:\tlearn: 0.3659834\ttotal: 24.6s\tremaining: 1m 37s\n121:\tlearn: 0.3625594\ttotal: 24.8s\tremaining: 1m 37s\n122:\tlearn: 0.3586795\ttotal: 25s\tremaining: 1m 36s\n123:\tlearn: 0.3541205\ttotal: 25.2s\tremaining: 1m 36s\n124:\tlearn: 0.3495768\ttotal: 25.4s\tremaining: 1m 36s\n125:\tlearn: 0.3453433\ttotal: 25.6s\tremaining: 1m 36s\n126:\tlearn: 0.3378079\ttotal: 25.8s\tremaining: 1m 36s\n127:\tlearn: 0.3348538\ttotal: 26s\tremaining: 1m 35s\n128:\tlearn: 0.3308253\ttotal: 26.2s\tremaining: 1m 35s\n129:\tlearn: 0.3295468\ttotal: 26.4s\tremaining: 1m 35s\n130:\tlearn: 0.3279451\ttotal: 26.6s\tremaining: 1m 35s\n131:\tlearn: 0.3242458\ttotal: 26.8s\tremaining: 1m 35s\n132:\tlearn: 0.3223737\ttotal: 27s\tremaining: 1m 34s\n133:\tlearn: 0.3192596\ttotal: 27.2s\tremaining: 1m 34s\n134:\tlearn: 0.3161048\ttotal: 27.4s\tremaining: 1m 34s\n135:\tlearn: 0.3146760\ttotal: 27.6s\tremaining: 1m 34s\n136:\tlearn: 0.3131735\ttotal: 27.8s\tremaining: 1m 34s\n137:\tlearn: 0.3101417\ttotal: 28.1s\tremaining: 1m 33s\n138:\tlearn: 0.3091554\ttotal: 28.3s\tremaining: 1m 33s\n139:\tlearn: 0.3057398\ttotal: 28.5s\tremaining: 1m 33s\n140:\tlearn: 0.3035890\ttotal: 28.7s\tremaining: 1m 33s\n141:\tlearn: 0.2997556\ttotal: 28.9s\tremaining: 1m 33s\n142:\tlearn: 0.2964834\ttotal: 29.1s\tremaining: 1m 32s\n143:\tlearn: 0.2945093\ttotal: 29.3s\tremaining: 1m 32s\n144:\tlearn: 0.2889783\ttotal: 29.5s\tremaining: 1m 32s\n145:\tlearn: 0.2850298\ttotal: 29.7s\tremaining: 1m 32s\n146:\tlearn: 0.2824678\ttotal: 29.9s\tremaining: 1m 32s\n147:\tlearn: 0.2812734\ttotal: 30.1s\tremaining: 1m 31s\n148:\tlearn: 0.2801487\ttotal: 30.3s\tremaining: 1m 31s\n149:\tlearn: 0.2768403\ttotal: 30.5s\tremaining: 1m 31s\n150:\tlearn: 0.2758349\ttotal: 30.7s\tremaining: 1m 31s\n151:\tlearn: 0.2743836\ttotal: 30.9s\tremaining: 1m 31s\n152:\tlearn: 0.2711339\ttotal: 31.1s\tremaining: 1m 30s\n153:\tlearn: 0.2686906\ttotal: 31.3s\tremaining: 1m 30s\n154:\tlearn: 0.2675348\ttotal: 31.5s\tremaining: 1m 30s\n155:\tlearn: 0.2658225\ttotal: 31.7s\tremaining: 1m 30s\n156:\tlearn: 0.2622725\ttotal: 31.9s\tremaining: 1m 30s\n157:\tlearn: 0.2601125\ttotal: 32.1s\tremaining: 1m 29s\n158:\tlearn: 0.2579579\ttotal: 32.3s\tremaining: 1m 29s\n159:\tlearn: 0.2548691\ttotal: 32.5s\tremaining: 1m 29s\n160:\tlearn: 0.2500413\ttotal: 32.8s\tremaining: 1m 29s\n161:\tlearn: 0.2494500\ttotal: 33s\tremaining: 1m 29s\n162:\tlearn: 0.2464696\ttotal: 33.2s\tremaining: 1m 28s\n163:\tlearn: 0.2445398\ttotal: 33.4s\tremaining: 1m 28s\n164:\tlearn: 0.2440884\ttotal: 33.6s\tremaining: 1m 28s\n165:\tlearn: 0.2430525\ttotal: 33.8s\tremaining: 1m 28s\n166:\tlearn: 0.2405620\ttotal: 34s\tremaining: 1m 28s\n167:\tlearn: 0.2395328\ttotal: 34.2s\tremaining: 1m 27s\n168:\tlearn: 0.2387612\ttotal: 34.4s\tremaining: 1m 27s\n169:\tlearn: 0.2369791\ttotal: 34.6s\tremaining: 1m 27s\n170:\tlearn: 0.2347005\ttotal: 34.8s\tremaining: 1m 27s\n171:\tlearn: 0.2327176\ttotal: 35s\tremaining: 1m 27s\n172:\tlearn: 0.2314574\ttotal: 35.2s\tremaining: 1m 26s\n173:\tlearn: 0.2305580\ttotal: 35.4s\tremaining: 1m 26s\n174:\tlearn: 0.2279772\ttotal: 35.6s\tremaining: 1m 26s\n175:\tlearn: 0.2244806\ttotal: 35.8s\tremaining: 1m 26s\n176:\tlearn: 0.2231322\ttotal: 36s\tremaining: 1m 26s\n177:\tlearn: 0.2222272\ttotal: 36.2s\tremaining: 1m 25s\n178:\tlearn: 0.2215666\ttotal: 36.4s\tremaining: 1m 25s\n179:\tlearn: 0.2202097\ttotal: 36.6s\tremaining: 1m 25s\n180:\tlearn: 0.2192244\ttotal: 36.8s\tremaining: 1m 25s\n181:\tlearn: 0.2179346\ttotal: 37s\tremaining: 1m 25s\n182:\tlearn: 0.2171788\ttotal: 37.2s\tremaining: 1m 24s\n183:\tlearn: 0.2166654\ttotal: 37.4s\tremaining: 1m 24s\n184:\tlearn: 0.2155473\ttotal: 37.6s\tremaining: 1m 24s\n185:\tlearn: 0.2147359\ttotal: 37.9s\tremaining: 1m 24s\n186:\tlearn: 0.2140456\ttotal: 38s\tremaining: 1m 24s\n187:\tlearn: 0.2107227\ttotal: 38.3s\tremaining: 1m 23s\n188:\tlearn: 0.2094005\ttotal: 38.5s\tremaining: 1m 23s\n189:\tlearn: 0.2083920\ttotal: 38.7s\tremaining: 1m 23s\n190:\tlearn: 0.2073679\ttotal: 38.9s\tremaining: 1m 23s\n191:\tlearn: 0.2068350\ttotal: 39.1s\tremaining: 1m 23s\n192:\tlearn: 0.2059207\ttotal: 39.3s\tremaining: 1m 22s\n193:\tlearn: 0.2050036\ttotal: 39.5s\tremaining: 1m 22s\n194:\tlearn: 0.2043431\ttotal: 39.7s\tremaining: 1m 22s\n195:\tlearn: 0.2026773\ttotal: 39.9s\tremaining: 1m 22s\n196:\tlearn: 0.2010613\ttotal: 40.1s\tremaining: 1m 22s\n197:\tlearn: 0.1992933\ttotal: 40.3s\tremaining: 1m 21s\n198:\tlearn: 0.1971926\ttotal: 40.5s\tremaining: 1m 21s\n199:\tlearn: 0.1949635\ttotal: 40.7s\tremaining: 1m 21s\n200:\tlearn: 0.1926538\ttotal: 40.9s\tremaining: 1m 21s\n201:\tlearn: 0.1923485\ttotal: 41.1s\tremaining: 1m 21s\n202:\tlearn: 0.1914483\ttotal: 41.3s\tremaining: 1m 20s\n203:\tlearn: 0.1897173\ttotal: 41.5s\tremaining: 1m 20s\n204:\tlearn: 0.1889137\ttotal: 41.7s\tremaining: 1m 20s\n205:\tlearn: 0.1878147\ttotal: 41.9s\tremaining: 1m 20s\n206:\tlearn: 0.1869520\ttotal: 42.1s\tremaining: 1m 20s\n207:\tlearn: 0.1866397\ttotal: 42.4s\tremaining: 1m 19s\n208:\tlearn: 0.1864401\ttotal: 42.6s\tremaining: 1m 19s\n209:\tlearn: 0.1846637\ttotal: 42.8s\tremaining: 1m 19s\n210:\tlearn: 0.1844148\ttotal: 43s\tremaining: 1m 19s\n211:\tlearn: 0.1841441\ttotal: 43.2s\tremaining: 1m 19s\n212:\tlearn: 0.1838281\ttotal: 43.4s\tremaining: 1m 18s\n213:\tlearn: 0.1832154\ttotal: 43.6s\tremaining: 1m 18s\n214:\tlearn: 0.1825736\ttotal: 43.8s\tremaining: 1m 18s\n215:\tlearn: 0.1818783\ttotal: 44s\tremaining: 1m 18s\n216:\tlearn: 0.1811429\ttotal: 44.2s\tremaining: 1m 17s\n217:\tlearn: 0.1808130\ttotal: 44.4s\tremaining: 1m 17s\n218:\tlearn: 0.1802648\ttotal: 44.6s\tremaining: 1m 17s\n219:\tlearn: 0.1783043\ttotal: 44.8s\tremaining: 1m 17s\n220:\tlearn: 0.1776740\ttotal: 45s\tremaining: 1m 17s\n221:\tlearn: 0.1771815\ttotal: 45.2s\tremaining: 1m 16s\n222:\tlearn: 0.1768555\ttotal: 45.4s\tremaining: 1m 16s\n223:\tlearn: 0.1758307\ttotal: 45.6s\tremaining: 1m 16s\n224:\tlearn: 0.1741160\ttotal: 45.8s\tremaining: 1m 16s\n225:\tlearn: 0.1735149\ttotal: 46s\tremaining: 1m 16s\n226:\tlearn: 0.1733489\ttotal: 46.2s\tremaining: 1m 15s\n227:\tlearn: 0.1731901\ttotal: 46.4s\tremaining: 1m 15s\n228:\tlearn: 0.1726551\ttotal: 46.6s\tremaining: 1m 15s\n229:\tlearn: 0.1718946\ttotal: 46.8s\tremaining: 1m 15s\n230:\tlearn: 0.1710965\ttotal: 47s\tremaining: 1m 15s\n231:\tlearn: 0.1708610\ttotal: 47.2s\tremaining: 1m 14s\n232:\tlearn: 0.1707018\ttotal: 47.4s\tremaining: 1m 14s\n233:\tlearn: 0.1703485\ttotal: 47.6s\tremaining: 1m 14s\n234:\tlearn: 0.1697474\ttotal: 47.8s\tremaining: 1m 14s\n235:\tlearn: 0.1691479\ttotal: 48s\tremaining: 1m 14s\n236:\tlearn: 0.1689856\ttotal: 48.2s\tremaining: 1m 13s\n237:\tlearn: 0.1674337\ttotal: 48.4s\tremaining: 1m 13s\n238:\tlearn: 0.1668380\ttotal: 48.6s\tremaining: 1m 13s\n239:\tlearn: 0.1667256\ttotal: 48.8s\tremaining: 1m 13s\n240:\tlearn: 0.1661933\ttotal: 49s\tremaining: 1m 13s\n241:\tlearn: 0.1646146\ttotal: 49.3s\tremaining: 1m 12s\n242:\tlearn: 0.1639476\ttotal: 49.5s\tremaining: 1m 12s\n243:\tlearn: 0.1636614\ttotal: 49.7s\tremaining: 1m 12s\n244:\tlearn: 0.1628560\ttotal: 49.9s\tremaining: 1m 12s\n245:\tlearn: 0.1623733\ttotal: 50.1s\tremaining: 1m 12s\n246:\tlearn: 0.1615282\ttotal: 50.3s\tremaining: 1m 11s\n247:\tlearn: 0.1614660\ttotal: 50.5s\tremaining: 1m 11s\n248:\tlearn: 0.1611790\ttotal: 50.7s\tremaining: 1m 11s\n249:\tlearn: 0.1599935\ttotal: 50.9s\tremaining: 1m 11s\n250:\tlearn: 0.1596373\ttotal: 51.1s\tremaining: 1m 11s\n251:\tlearn: 0.1593235\ttotal: 51.3s\tremaining: 1m 10s\n252:\tlearn: 0.1588198\ttotal: 51.5s\tremaining: 1m 10s\n253:\tlearn: 0.1583239\ttotal: 51.7s\tremaining: 1m 10s\n254:\tlearn: 0.1580585\ttotal: 51.9s\tremaining: 1m 10s\n255:\tlearn: 0.1562760\ttotal: 52.1s\tremaining: 1m 10s\n256:\tlearn: 0.1556860\ttotal: 52.3s\tremaining: 1m 9s\n257:\tlearn: 0.1536126\ttotal: 52.5s\tremaining: 1m 9s\n258:\tlearn: 0.1521107\ttotal: 52.7s\tremaining: 1m 9s\n259:\tlearn: 0.1503825\ttotal: 52.9s\tremaining: 1m 9s\n260:\tlearn: 0.1503279\ttotal: 53.1s\tremaining: 1m 9s\n261:\tlearn: 0.1497768\ttotal: 53.3s\tremaining: 1m 8s\n262:\tlearn: 0.1495993\ttotal: 53.5s\tremaining: 1m 8s\n263:\tlearn: 0.1491799\ttotal: 53.7s\tremaining: 1m 8s\n264:\tlearn: 0.1487776\ttotal: 53.9s\tremaining: 1m 8s\n265:\tlearn: 0.1478322\ttotal: 54.1s\tremaining: 1m 7s\n266:\tlearn: 0.1476144\ttotal: 54.3s\tremaining: 1m 7s\n267:\tlearn: 0.1474770\ttotal: 54.6s\tremaining: 1m 7s\n268:\tlearn: 0.1461057\ttotal: 54.8s\tremaining: 1m 7s\n269:\tlearn: 0.1457790\ttotal: 55s\tremaining: 1m 7s\n270:\tlearn: 0.1456765\ttotal: 55.2s\tremaining: 1m 7s\n271:\tlearn: 0.1437171\ttotal: 55.4s\tremaining: 1m 6s\n272:\tlearn: 0.1436064\ttotal: 55.6s\tremaining: 1m 6s\n273:\tlearn: 0.1430337\ttotal: 55.8s\tremaining: 1m 6s\n274:\tlearn: 0.1427300\ttotal: 56s\tremaining: 1m 6s\n275:\tlearn: 0.1421047\ttotal: 56.2s\tremaining: 1m 5s\n276:\tlearn: 0.1419405\ttotal: 56.4s\tremaining: 1m 5s\n277:\tlearn: 0.1418634\ttotal: 56.6s\tremaining: 1m 5s\n278:\tlearn: 0.1414903\ttotal: 56.8s\tremaining: 1m 5s\n279:\tlearn: 0.1413694\ttotal: 57s\tremaining: 1m 5s\n280:\tlearn: 0.1409972\ttotal: 57.2s\tremaining: 1m 4s\n281:\tlearn: 0.1403794\ttotal: 57.4s\tremaining: 1m 4s\n282:\tlearn: 0.1396168\ttotal: 57.6s\tremaining: 1m 4s\n283:\tlearn: 0.1394692\ttotal: 57.8s\tremaining: 1m 4s\n284:\tlearn: 0.1391709\ttotal: 58s\tremaining: 1m 4s\n285:\tlearn: 0.1388678\ttotal: 58.2s\tremaining: 1m 3s\n286:\tlearn: 0.1385369\ttotal: 58.4s\tremaining: 1m 3s\n287:\tlearn: 0.1380325\ttotal: 58.6s\tremaining: 1m 3s\n288:\tlearn: 0.1375846\ttotal: 58.8s\tremaining: 1m 3s\n289:\tlearn: 0.1371834\ttotal: 59s\tremaining: 1m 3s\n290:\tlearn: 0.1369097\ttotal: 59.2s\tremaining: 1m 2s\n291:\tlearn: 0.1367796\ttotal: 59.5s\tremaining: 1m 2s\n292:\tlearn: 0.1365993\ttotal: 59.7s\tremaining: 1m 2s\n293:\tlearn: 0.1364910\ttotal: 59.9s\tremaining: 1m 2s\n294:\tlearn: 0.1363070\ttotal: 1m\tremaining: 1m 2s\n295:\tlearn: 0.1361215\ttotal: 1m\tremaining: 1m 1s\n296:\tlearn: 0.1356131\ttotal: 1m\tremaining: 1m 1s\n297:\tlearn: 0.1353939\ttotal: 1m\tremaining: 1m 1s\n298:\tlearn: 0.1348602\ttotal: 1m\tremaining: 1m 1s\n299:\tlearn: 0.1339613\ttotal: 1m 1s\tremaining: 1m 1s\n300:\tlearn: 0.1335039\ttotal: 1m 1s\tremaining: 1m\n301:\tlearn: 0.1327051\ttotal: 1m 1s\tremaining: 1m\n302:\tlearn: 0.1325445\ttotal: 1m 1s\tremaining: 1m\n303:\tlearn: 0.1323805\ttotal: 1m 1s\tremaining: 1m\n304:\tlearn: 0.1321955\ttotal: 1m 2s\tremaining: 1m\n305:\tlearn: 0.1320305\ttotal: 1m 2s\tremaining: 59.9s\n306:\tlearn: 0.1317994\ttotal: 1m 2s\tremaining: 59.7s\n307:\tlearn: 0.1314358\ttotal: 1m 2s\tremaining: 59.5s\n308:\tlearn: 0.1310133\ttotal: 1m 2s\tremaining: 59.2s\n309:\tlearn: 0.1306551\ttotal: 1m 3s\tremaining: 59s\n310:\tlearn: 0.1305181\ttotal: 1m 3s\tremaining: 58.8s\n311:\tlearn: 0.1299822\ttotal: 1m 3s\tremaining: 58.6s\n312:\tlearn: 0.1293607\ttotal: 1m 3s\tremaining: 58.4s\n313:\tlearn: 0.1290285\ttotal: 1m 3s\tremaining: 58.2s\n314:\tlearn: 0.1283550\ttotal: 1m 4s\tremaining: 58s\n315:\tlearn: 0.1275282\ttotal: 1m 4s\tremaining: 57.8s\n316:\tlearn: 0.1273178\ttotal: 1m 4s\tremaining: 57.6s\n317:\tlearn: 0.1266929\ttotal: 1m 4s\tremaining: 57.4s\n318:\tlearn: 0.1263941\ttotal: 1m 4s\tremaining: 57.2s\n319:\tlearn: 0.1250795\ttotal: 1m 5s\tremaining: 57s\n320:\tlearn: 0.1248176\ttotal: 1m 5s\tremaining: 56.8s\n321:\tlearn: 0.1242950\ttotal: 1m 5s\tremaining: 56.6s\n322:\tlearn: 0.1242152\ttotal: 1m 5s\tremaining: 56.4s\n323:\tlearn: 0.1239679\ttotal: 1m 5s\tremaining: 56.2s\n324:\tlearn: 0.1238525\ttotal: 1m 6s\tremaining: 56s\n325:\tlearn: 0.1236634\ttotal: 1m 6s\tremaining: 55.8s\n326:\tlearn: 0.1235145\ttotal: 1m 6s\tremaining: 55.6s\n327:\tlearn: 0.1233293\ttotal: 1m 6s\tremaining: 55.4s\n328:\tlearn: 0.1230331\ttotal: 1m 6s\tremaining: 55.2s\n329:\tlearn: 0.1228686\ttotal: 1m 7s\tremaining: 55s\n330:\tlearn: 0.1225555\ttotal: 1m 7s\tremaining: 54.8s\n331:\tlearn: 0.1223829\ttotal: 1m 7s\tremaining: 54.6s\n332:\tlearn: 0.1222978\ttotal: 1m 7s\tremaining: 54.4s\n333:\tlearn: 0.1217895\ttotal: 1m 7s\tremaining: 54.2s\n334:\tlearn: 0.1215380\ttotal: 1m 8s\tremaining: 53.9s\n335:\tlearn: 0.1213356\ttotal: 1m 8s\tremaining: 53.7s\n336:\tlearn: 0.1201837\ttotal: 1m 8s\tremaining: 53.5s\n337:\tlearn: 0.1200977\ttotal: 1m 8s\tremaining: 53.3s\n338:\tlearn: 0.1198231\ttotal: 1m 9s\tremaining: 53.1s\n339:\tlearn: 0.1197596\ttotal: 1m 9s\tremaining: 52.9s\n340:\tlearn: 0.1196466\ttotal: 1m 9s\tremaining: 52.7s\n341:\tlearn: 0.1192750\ttotal: 1m 9s\tremaining: 52.5s\n342:\tlearn: 0.1189533\ttotal: 1m 9s\tremaining: 52.3s\n343:\tlearn: 0.1188871\ttotal: 1m 10s\tremaining: 52.1s\n344:\tlearn: 0.1184877\ttotal: 1m 10s\tremaining: 51.9s\n345:\tlearn: 0.1184008\ttotal: 1m 10s\tremaining: 51.7s\n346:\tlearn: 0.1178852\ttotal: 1m 10s\tremaining: 51.5s\n347:\tlearn: 0.1177198\ttotal: 1m 10s\tremaining: 51.3s\n348:\tlearn: 0.1174106\ttotal: 1m 11s\tremaining: 51.1s\n349:\tlearn: 0.1173512\ttotal: 1m 11s\tremaining: 50.9s\n350:\tlearn: 0.1171735\ttotal: 1m 11s\tremaining: 50.7s\n351:\tlearn: 0.1169612\ttotal: 1m 11s\tremaining: 50.5s\n352:\tlearn: 0.1168349\ttotal: 1m 11s\tremaining: 50.3s\n353:\tlearn: 0.1167527\ttotal: 1m 12s\tremaining: 50.1s\n354:\tlearn: 0.1165174\ttotal: 1m 12s\tremaining: 49.9s\n355:\tlearn: 0.1164227\ttotal: 1m 12s\tremaining: 49.7s\n356:\tlearn: 0.1156751\ttotal: 1m 12s\tremaining: 49.5s\n357:\tlearn: 0.1155468\ttotal: 1m 12s\tremaining: 49.3s\n358:\tlearn: 0.1154264\ttotal: 1m 13s\tremaining: 49.1s\n359:\tlearn: 0.1153109\ttotal: 1m 13s\tremaining: 48.9s\n360:\tlearn: 0.1151695\ttotal: 1m 13s\tremaining: 48.7s\n361:\tlearn: 0.1151055\ttotal: 1m 13s\tremaining: 48.5s\n362:\tlearn: 0.1149775\ttotal: 1m 13s\tremaining: 48.2s\n363:\tlearn: 0.1148922\ttotal: 1m 14s\tremaining: 48s\n364:\tlearn: 0.1146034\ttotal: 1m 14s\tremaining: 47.8s\n365:\tlearn: 0.1143947\ttotal: 1m 14s\tremaining: 47.6s\n366:\tlearn: 0.1141814\ttotal: 1m 14s\tremaining: 47.4s\n367:\tlearn: 0.1135586\ttotal: 1m 14s\tremaining: 47.2s\n368:\tlearn: 0.1133927\ttotal: 1m 15s\tremaining: 47s\n369:\tlearn: 0.1133033\ttotal: 1m 15s\tremaining: 46.8s\n370:\tlearn: 0.1130581\ttotal: 1m 15s\tremaining: 46.6s\n371:\tlearn: 0.1130183\ttotal: 1m 15s\tremaining: 46.4s\n372:\tlearn: 0.1127399\ttotal: 1m 15s\tremaining: 46.2s\n373:\tlearn: 0.1126850\ttotal: 1m 16s\tremaining: 46s\n374:\tlearn: 0.1125778\ttotal: 1m 16s\tremaining: 45.8s\n375:\tlearn: 0.1124386\ttotal: 1m 16s\tremaining: 45.6s\n376:\tlearn: 0.1123763\ttotal: 1m 16s\tremaining: 45.4s\n377:\tlearn: 0.1119951\ttotal: 1m 16s\tremaining: 45.2s\n378:\tlearn: 0.1117544\ttotal: 1m 17s\tremaining: 45s\n379:\tlearn: 0.1114878\ttotal: 1m 17s\tremaining: 44.8s\n380:\tlearn: 0.1113931\ttotal: 1m 17s\tremaining: 44.6s\n381:\tlearn: 0.1113116\ttotal: 1m 17s\tremaining: 44.4s\n382:\tlearn: 0.1112545\ttotal: 1m 17s\tremaining: 44.2s\n383:\tlearn: 0.1112110\ttotal: 1m 18s\tremaining: 44s\n384:\tlearn: 0.1111580\ttotal: 1m 18s\tremaining: 43.8s\n385:\tlearn: 0.1110089\ttotal: 1m 18s\tremaining: 43.6s\n386:\tlearn: 0.1109732\ttotal: 1m 18s\tremaining: 43.4s\n387:\tlearn: 0.1107956\ttotal: 1m 18s\tremaining: 43.1s\n388:\tlearn: 0.1107412\ttotal: 1m 19s\tremaining: 42.9s\n389:\tlearn: 0.1105759\ttotal: 1m 19s\tremaining: 42.7s\n390:\tlearn: 0.1098528\ttotal: 1m 19s\tremaining: 42.5s\n391:\tlearn: 0.1097360\ttotal: 1m 19s\tremaining: 42.3s\n392:\tlearn: 0.1096877\ttotal: 1m 19s\tremaining: 42.1s\n393:\tlearn: 0.1090390\ttotal: 1m 20s\tremaining: 41.9s\n394:\tlearn: 0.1087374\ttotal: 1m 20s\tremaining: 41.7s\n395:\tlearn: 0.1086116\ttotal: 1m 20s\tremaining: 41.5s\n396:\tlearn: 0.1085132\ttotal: 1m 20s\tremaining: 41.3s\n397:\tlearn: 0.1084659\ttotal: 1m 21s\tremaining: 41.1s\n398:\tlearn: 0.1083340\ttotal: 1m 21s\tremaining: 40.9s\n399:\tlearn: 0.1083060\ttotal: 1m 21s\tremaining: 40.7s\n400:\tlearn: 0.1081676\ttotal: 1m 21s\tremaining: 40.5s\n401:\tlearn: 0.1080754\ttotal: 1m 21s\tremaining: 40.3s\n402:\tlearn: 0.1079545\ttotal: 1m 22s\tremaining: 40.1s\n403:\tlearn: 0.1077701\ttotal: 1m 22s\tremaining: 39.9s\n404:\tlearn: 0.1076384\ttotal: 1m 22s\tremaining: 39.7s\n405:\tlearn: 0.1075443\ttotal: 1m 22s\tremaining: 39.5s\n406:\tlearn: 0.1075030\ttotal: 1m 22s\tremaining: 39.3s\n407:\tlearn: 0.1074318\ttotal: 1m 23s\tremaining: 39.1s\n408:\tlearn: 0.1073043\ttotal: 1m 23s\tremaining: 38.9s\n409:\tlearn: 0.1072631\ttotal: 1m 23s\tremaining: 38.7s\n410:\tlearn: 0.1067562\ttotal: 1m 23s\tremaining: 38.5s\n411:\tlearn: 0.1063676\ttotal: 1m 23s\tremaining: 38.3s\n412:\tlearn: 0.1062684\ttotal: 1m 24s\tremaining: 38.1s\n413:\tlearn: 0.1061343\ttotal: 1m 24s\tremaining: 37.9s\n414:\tlearn: 0.1060264\ttotal: 1m 24s\tremaining: 37.6s\n415:\tlearn: 0.1059044\ttotal: 1m 24s\tremaining: 37.4s\n416:\tlearn: 0.1057052\ttotal: 1m 24s\tremaining: 37.2s\n417:\tlearn: 0.1055541\ttotal: 1m 25s\tremaining: 37s\n418:\tlearn: 0.1055153\ttotal: 1m 25s\tremaining: 36.8s\n419:\tlearn: 0.1050361\ttotal: 1m 25s\tremaining: 36.6s\n420:\tlearn: 0.1049611\ttotal: 1m 25s\tremaining: 36.4s\n421:\tlearn: 0.1049248\ttotal: 1m 25s\tremaining: 36.2s\n422:\tlearn: 0.1048335\ttotal: 1m 26s\tremaining: 36s\n423:\tlearn: 0.1047944\ttotal: 1m 26s\tremaining: 35.8s\n424:\tlearn: 0.1046280\ttotal: 1m 26s\tremaining: 35.6s\n425:\tlearn: 0.1045479\ttotal: 1m 26s\tremaining: 35.4s\n426:\tlearn: 0.1041775\ttotal: 1m 26s\tremaining: 35.2s\n427:\tlearn: 0.1041436\ttotal: 1m 27s\tremaining: 35s\n428:\tlearn: 0.1040992\ttotal: 1m 27s\tremaining: 34.8s\n429:\tlearn: 0.1040086\ttotal: 1m 27s\tremaining: 34.6s\n430:\tlearn: 0.1039405\ttotal: 1m 27s\tremaining: 34.4s\n431:\tlearn: 0.1033943\ttotal: 1m 27s\tremaining: 34.2s\n432:\tlearn: 0.1031425\ttotal: 1m 28s\tremaining: 34s\n433:\tlearn: 0.1029864\ttotal: 1m 28s\tremaining: 33.8s\n434:\tlearn: 0.1028411\ttotal: 1m 28s\tremaining: 33.6s\n435:\tlearn: 0.1027791\ttotal: 1m 28s\tremaining: 33.4s\n436:\tlearn: 0.1026481\ttotal: 1m 28s\tremaining: 33.2s\n437:\tlearn: 0.1025932\ttotal: 1m 29s\tremaining: 33s\n438:\tlearn: 0.1025208\ttotal: 1m 29s\tremaining: 32.8s\n439:\tlearn: 0.1023810\ttotal: 1m 29s\tremaining: 32.6s\n440:\tlearn: 0.1022931\ttotal: 1m 29s\tremaining: 32.4s\n441:\tlearn: 0.1022139\ttotal: 1m 29s\tremaining: 32.2s\n442:\tlearn: 0.1021259\ttotal: 1m 30s\tremaining: 32s\n443:\tlearn: 0.1020964\ttotal: 1m 30s\tremaining: 31.8s\n444:\tlearn: 0.1020716\ttotal: 1m 30s\tremaining: 31.6s\n445:\tlearn: 0.1019733\ttotal: 1m 30s\tremaining: 31.4s\n446:\tlearn: 0.1019110\ttotal: 1m 31s\tremaining: 31.1s\n447:\tlearn: 0.1015458\ttotal: 1m 31s\tremaining: 30.9s\n448:\tlearn: 0.1014997\ttotal: 1m 31s\tremaining: 30.7s\n449:\tlearn: 0.1014806\ttotal: 1m 31s\tremaining: 30.5s\n450:\tlearn: 0.1014516\ttotal: 1m 31s\tremaining: 30.3s\n451:\tlearn: 0.1013697\ttotal: 1m 32s\tremaining: 30.1s\n452:\tlearn: 0.1012994\ttotal: 1m 32s\tremaining: 29.9s\n453:\tlearn: 0.1011049\ttotal: 1m 32s\tremaining: 29.7s\n454:\tlearn: 0.1009266\ttotal: 1m 32s\tremaining: 29.5s\n455:\tlearn: 0.1008789\ttotal: 1m 32s\tremaining: 29.3s\n456:\tlearn: 0.1007932\ttotal: 1m 33s\tremaining: 29.1s\n457:\tlearn: 0.1006767\ttotal: 1m 33s\tremaining: 28.9s\n458:\tlearn: 0.1005780\ttotal: 1m 33s\tremaining: 28.7s\n459:\tlearn: 0.1003000\ttotal: 1m 33s\tremaining: 28.5s\n460:\tlearn: 0.1001883\ttotal: 1m 33s\tremaining: 28.3s\n461:\tlearn: 0.1001431\ttotal: 1m 34s\tremaining: 28.1s\n462:\tlearn: 0.0999904\ttotal: 1m 34s\tremaining: 27.9s\n463:\tlearn: 0.0999613\ttotal: 1m 34s\tremaining: 27.7s\n464:\tlearn: 0.0999306\ttotal: 1m 34s\tremaining: 27.5s\n465:\tlearn: 0.0998798\ttotal: 1m 34s\tremaining: 27.3s\n466:\tlearn: 0.0997817\ttotal: 1m 35s\tremaining: 27.1s\n467:\tlearn: 0.0996888\ttotal: 1m 35s\tremaining: 26.9s\n468:\tlearn: 0.0996440\ttotal: 1m 35s\tremaining: 26.7s\n469:\tlearn: 0.0989722\ttotal: 1m 35s\tremaining: 26.5s\n470:\tlearn: 0.0989010\ttotal: 1m 35s\tremaining: 26.3s\n471:\tlearn: 0.0981054\ttotal: 1m 36s\tremaining: 26.1s\n472:\tlearn: 0.0978881\ttotal: 1m 36s\tremaining: 25.9s\n473:\tlearn: 0.0978175\ttotal: 1m 36s\tremaining: 25.6s\n474:\tlearn: 0.0977578\ttotal: 1m 36s\tremaining: 25.4s\n475:\tlearn: 0.0977261\ttotal: 1m 36s\tremaining: 25.2s\n476:\tlearn: 0.0976895\ttotal: 1m 37s\tremaining: 25s\n477:\tlearn: 0.0976473\ttotal: 1m 37s\tremaining: 24.8s\n478:\tlearn: 0.0976047\ttotal: 1m 37s\tremaining: 24.6s\n479:\tlearn: 0.0975555\ttotal: 1m 37s\tremaining: 24.4s\n480:\tlearn: 0.0975093\ttotal: 1m 37s\tremaining: 24.2s\n481:\tlearn: 0.0974249\ttotal: 1m 38s\tremaining: 24s\n482:\tlearn: 0.0973356\ttotal: 1m 38s\tremaining: 23.8s\n483:\tlearn: 0.0972245\ttotal: 1m 38s\tremaining: 23.6s\n484:\tlearn: 0.0971978\ttotal: 1m 38s\tremaining: 23.4s\n485:\tlearn: 0.0970756\ttotal: 1m 38s\tremaining: 23.2s\n486:\tlearn: 0.0970175\ttotal: 1m 39s\tremaining: 23s\n487:\tlearn: 0.0969643\ttotal: 1m 39s\tremaining: 22.8s\n488:\tlearn: 0.0969201\ttotal: 1m 39s\tremaining: 22.6s\n489:\tlearn: 0.0968622\ttotal: 1m 39s\tremaining: 22.4s\n490:\tlearn: 0.0966847\ttotal: 1m 39s\tremaining: 22.2s\n491:\tlearn: 0.0966059\ttotal: 1m 40s\tremaining: 22s\n492:\tlearn: 0.0965160\ttotal: 1m 40s\tremaining: 21.8s\n493:\tlearn: 0.0962960\ttotal: 1m 40s\tremaining: 21.6s\n494:\tlearn: 0.0962660\ttotal: 1m 40s\tremaining: 21.4s\n495:\tlearn: 0.0962475\ttotal: 1m 40s\tremaining: 21.2s\n496:\tlearn: 0.0959755\ttotal: 1m 41s\tremaining: 21s\n497:\tlearn: 0.0959245\ttotal: 1m 41s\tremaining: 20.8s\n498:\tlearn: 0.0958827\ttotal: 1m 41s\tremaining: 20.6s\n499:\tlearn: 0.0958694\ttotal: 1m 41s\tremaining: 20.3s\n500:\tlearn: 0.0958386\ttotal: 1m 41s\tremaining: 20.1s\n501:\tlearn: 0.0958112\ttotal: 1m 42s\tremaining: 19.9s\n502:\tlearn: 0.0957576\ttotal: 1m 42s\tremaining: 19.7s\n503:\tlearn: 0.0957035\ttotal: 1m 42s\tremaining: 19.5s\n504:\tlearn: 0.0956554\ttotal: 1m 42s\tremaining: 19.3s\n505:\tlearn: 0.0951149\ttotal: 1m 42s\tremaining: 19.1s\n506:\tlearn: 0.0950465\ttotal: 1m 43s\tremaining: 18.9s\n507:\tlearn: 0.0949944\ttotal: 1m 43s\tremaining: 18.7s\n508:\tlearn: 0.0949730\ttotal: 1m 43s\tremaining: 18.5s\n509:\tlearn: 0.0949108\ttotal: 1m 43s\tremaining: 18.3s\n510:\tlearn: 0.0948711\ttotal: 1m 43s\tremaining: 18.1s\n511:\tlearn: 0.0948380\ttotal: 1m 44s\tremaining: 17.9s\n512:\tlearn: 0.0947984\ttotal: 1m 44s\tremaining: 17.7s\n513:\tlearn: 0.0946825\ttotal: 1m 44s\tremaining: 17.5s\n514:\tlearn: 0.0946410\ttotal: 1m 44s\tremaining: 17.3s\n515:\tlearn: 0.0944734\ttotal: 1m 44s\tremaining: 17.1s\n516:\tlearn: 0.0944321\ttotal: 1m 45s\tremaining: 16.9s\n517:\tlearn: 0.0944064\ttotal: 1m 45s\tremaining: 16.7s\n518:\tlearn: 0.0943193\ttotal: 1m 45s\tremaining: 16.5s\n519:\tlearn: 0.0942873\ttotal: 1m 45s\tremaining: 16.3s\n520:\tlearn: 0.0938201\ttotal: 1m 46s\tremaining: 16.1s\n521:\tlearn: 0.0937954\ttotal: 1m 46s\tremaining: 15.9s\n522:\tlearn: 0.0937290\ttotal: 1m 46s\tremaining: 15.7s\n523:\tlearn: 0.0937029\ttotal: 1m 46s\tremaining: 15.5s\n524:\tlearn: 0.0936733\ttotal: 1m 46s\tremaining: 15.3s\n525:\tlearn: 0.0936437\ttotal: 1m 47s\tremaining: 15.1s\n526:\tlearn: 0.0935846\ttotal: 1m 47s\tremaining: 14.8s\n527:\tlearn: 0.0935415\ttotal: 1m 47s\tremaining: 14.6s\n528:\tlearn: 0.0934860\ttotal: 1m 47s\tremaining: 14.4s\n529:\tlearn: 0.0933287\ttotal: 1m 47s\tremaining: 14.2s\n530:\tlearn: 0.0932934\ttotal: 1m 48s\tremaining: 14s\n531:\tlearn: 0.0932248\ttotal: 1m 48s\tremaining: 13.8s\n532:\tlearn: 0.0931775\ttotal: 1m 48s\tremaining: 13.6s\n533:\tlearn: 0.0931453\ttotal: 1m 48s\tremaining: 13.4s\n534:\tlearn: 0.0931247\ttotal: 1m 48s\tremaining: 13.2s\n535:\tlearn: 0.0931032\ttotal: 1m 49s\tremaining: 13s\n536:\tlearn: 0.0930611\ttotal: 1m 49s\tremaining: 12.8s\n537:\tlearn: 0.0930371\ttotal: 1m 49s\tremaining: 12.6s\n538:\tlearn: 0.0929762\ttotal: 1m 49s\tremaining: 12.4s\n539:\tlearn: 0.0929386\ttotal: 1m 49s\tremaining: 12.2s\n540:\tlearn: 0.0929140\ttotal: 1m 50s\tremaining: 12s\n541:\tlearn: 0.0928587\ttotal: 1m 50s\tremaining: 11.8s\n542:\tlearn: 0.0922986\ttotal: 1m 50s\tremaining: 11.6s\n543:\tlearn: 0.0921395\ttotal: 1m 50s\tremaining: 11.4s\n544:\tlearn: 0.0920650\ttotal: 1m 50s\tremaining: 11.2s\n545:\tlearn: 0.0920604\ttotal: 1m 51s\tremaining: 11s\n546:\tlearn: 0.0920061\ttotal: 1m 51s\tremaining: 10.8s\n547:\tlearn: 0.0919381\ttotal: 1m 51s\tremaining: 10.6s\n548:\tlearn: 0.0918534\ttotal: 1m 51s\tremaining: 10.4s\n549:\tlearn: 0.0917254\ttotal: 1m 51s\tremaining: 10.2s\n550:\tlearn: 0.0916315\ttotal: 1m 52s\tremaining: 9.96s\n551:\tlearn: 0.0916076\ttotal: 1m 52s\tremaining: 9.76s\n552:\tlearn: 0.0915925\ttotal: 1m 52s\tremaining: 9.56s\n553:\tlearn: 0.0915047\ttotal: 1m 52s\tremaining: 9.35s\n554:\tlearn: 0.0913471\ttotal: 1m 52s\tremaining: 9.15s\n555:\tlearn: 0.0912748\ttotal: 1m 53s\tremaining: 8.95s\n556:\tlearn: 0.0912544\ttotal: 1m 53s\tremaining: 8.74s\n557:\tlearn: 0.0912039\ttotal: 1m 53s\tremaining: 8.54s\n558:\tlearn: 0.0911894\ttotal: 1m 53s\tremaining: 8.34s\n559:\tlearn: 0.0911633\ttotal: 1m 53s\tremaining: 8.13s\n560:\tlearn: 0.0911364\ttotal: 1m 54s\tremaining: 7.93s\n561:\tlearn: 0.0911162\ttotal: 1m 54s\tremaining: 7.73s\n562:\tlearn: 0.0910956\ttotal: 1m 54s\tremaining: 7.52s\n563:\tlearn: 0.0909987\ttotal: 1m 54s\tremaining: 7.32s\n564:\tlearn: 0.0909293\ttotal: 1m 54s\tremaining: 7.12s\n565:\tlearn: 0.0909037\ttotal: 1m 55s\tremaining: 6.91s\n566:\tlearn: 0.0908674\ttotal: 1m 55s\tremaining: 6.71s\n567:\tlearn: 0.0908458\ttotal: 1m 55s\tremaining: 6.51s\n568:\tlearn: 0.0908274\ttotal: 1m 55s\tremaining: 6.3s\n569:\tlearn: 0.0904281\ttotal: 1m 55s\tremaining: 6.1s\n570:\tlearn: 0.0903998\ttotal: 1m 56s\tremaining: 5.9s\n571:\tlearn: 0.0903770\ttotal: 1m 56s\tremaining: 5.69s\n572:\tlearn: 0.0903477\ttotal: 1m 56s\tremaining: 5.49s\n573:\tlearn: 0.0901688\ttotal: 1m 56s\tremaining: 5.29s\n574:\tlearn: 0.0901140\ttotal: 1m 56s\tremaining: 5.08s\n575:\tlearn: 0.0900501\ttotal: 1m 57s\tremaining: 4.88s\n576:\tlearn: 0.0900269\ttotal: 1m 57s\tremaining: 4.68s\n577:\tlearn: 0.0899938\ttotal: 1m 57s\tremaining: 4.47s\n578:\tlearn: 0.0899503\ttotal: 1m 57s\tremaining: 4.27s\n579:\tlearn: 0.0898983\ttotal: 1m 57s\tremaining: 4.07s\n580:\tlearn: 0.0898662\ttotal: 1m 58s\tremaining: 3.87s\n581:\tlearn: 0.0898260\ttotal: 1m 58s\tremaining: 3.66s\n582:\tlearn: 0.0897935\ttotal: 1m 58s\tremaining: 3.46s\n583:\tlearn: 0.0897453\ttotal: 1m 58s\tremaining: 3.25s\n584:\tlearn: 0.0896886\ttotal: 1m 59s\tremaining: 3.05s\n585:\tlearn: 0.0896587\ttotal: 1m 59s\tremaining: 2.85s\n586:\tlearn: 0.0895908\ttotal: 1m 59s\tremaining: 2.64s\n587:\tlearn: 0.0895699\ttotal: 1m 59s\tremaining: 2.44s\n588:\tlearn: 0.0895315\ttotal: 1m 59s\tremaining: 2.24s\n589:\tlearn: 0.0894515\ttotal: 2m\tremaining: 2.03s\n590:\tlearn: 0.0891875\ttotal: 2m\tremaining: 1.83s\n591:\tlearn: 0.0891697\ttotal: 2m\tremaining: 1.63s\n592:\tlearn: 0.0881431\ttotal: 2m\tremaining: 1.42s\n593:\tlearn: 0.0880895\ttotal: 2m\tremaining: 1.22s\n594:\tlearn: 0.0880547\ttotal: 2m 1s\tremaining: 1.02s\n595:\tlearn: 0.0876646\ttotal: 2m 1s\tremaining: 814ms\n596:\tlearn: 0.0876416\ttotal: 2m 1s\tremaining: 610ms\n597:\tlearn: 0.0876147\ttotal: 2m 1s\tremaining: 407ms\n598:\tlearn: 0.0875165\ttotal: 2m 1s\tremaining: 203ms\n599:\tlearn: 0.0874853\ttotal: 2m 2s\tremaining: 0us\ncat_fit_done\nmodel_ready\n0:\tlearn: 2.5853643\ttotal: 434ms\tremaining: 4m 19s\n1:\tlearn: 2.5147764\ttotal: 872ms\tremaining: 4m 20s\n2:\tlearn: 2.4594889\ttotal: 1.33s\tremaining: 4m 24s\n3:\tlearn: 2.4085059\ttotal: 1.78s\tremaining: 4m 26s\n4:\tlearn: 2.3600904\ttotal: 2.25s\tremaining: 4m 27s\n5:\tlearn: 2.3183453\ttotal: 2.69s\tremaining: 4m 26s\n6:\tlearn: 2.2857577\ttotal: 3.12s\tremaining: 4m 24s\n7:\tlearn: 2.2444450\ttotal: 3.57s\tremaining: 4m 24s\n8:\tlearn: 2.2013446\ttotal: 4.04s\tremaining: 4m 25s\n9:\tlearn: 2.1707775\ttotal: 4.48s\tremaining: 4m 24s\n10:\tlearn: 2.1499304\ttotal: 4.92s\tremaining: 4m 23s\n11:\tlearn: 2.1233858\ttotal: 5.37s\tremaining: 4m 23s\n12:\tlearn: 2.0979972\ttotal: 5.81s\tremaining: 4m 22s\n13:\tlearn: 2.0644862\ttotal: 6.26s\tremaining: 4m 22s\n14:\tlearn: 2.0382637\ttotal: 6.71s\tremaining: 4m 21s\n15:\tlearn: 2.0167946\ttotal: 7.15s\tremaining: 4m 20s\n16:\tlearn: 2.0000916\ttotal: 7.58s\tremaining: 4m 19s\n17:\tlearn: 1.9843034\ttotal: 8.02s\tremaining: 4m 19s\n18:\tlearn: 1.9635233\ttotal: 8.46s\tremaining: 4m 18s\n19:\tlearn: 1.9490417\ttotal: 8.89s\tremaining: 4m 17s\n20:\tlearn: 1.9172222\ttotal: 9.37s\tremaining: 4m 18s\n21:\tlearn: 1.9010786\ttotal: 9.82s\tremaining: 4m 18s\n22:\tlearn: 1.8848476\ttotal: 10.3s\tremaining: 4m 17s\n23:\tlearn: 1.8617716\ttotal: 10.7s\tremaining: 4m 17s\n24:\tlearn: 1.8416808\ttotal: 11.2s\tremaining: 4m 16s\n25:\tlearn: 1.8303748\ttotal: 11.6s\tremaining: 4m 16s\n26:\tlearn: 1.8186700\ttotal: 12s\tremaining: 4m 15s\n27:\tlearn: 1.8006591\ttotal: 12.5s\tremaining: 4m 15s\n28:\tlearn: 1.7888397\ttotal: 12.9s\tremaining: 4m 14s\n29:\tlearn: 1.7743591\ttotal: 13.4s\tremaining: 4m 14s\n30:\tlearn: 1.7660579\ttotal: 13.8s\tremaining: 4m 13s\n31:\tlearn: 1.7552756\ttotal: 14.3s\tremaining: 4m 13s\n32:\tlearn: 1.7418264\ttotal: 14.7s\tremaining: 4m 12s\n33:\tlearn: 1.7298561\ttotal: 15.1s\tremaining: 4m 11s\n34:\tlearn: 1.7173591\ttotal: 15.6s\tremaining: 4m 11s\n35:\tlearn: 1.7078457\ttotal: 16s\tremaining: 4m 10s\n36:\tlearn: 1.7014437\ttotal: 16.4s\tremaining: 4m 10s\n37:\tlearn: 1.6868872\ttotal: 16.9s\tremaining: 4m 9s\n38:\tlearn: 1.6793346\ttotal: 17.3s\tremaining: 4m 9s\n39:\tlearn: 1.6669162\ttotal: 17.8s\tremaining: 4m 8s\n40:\tlearn: 1.6567250\ttotal: 18.2s\tremaining: 4m 8s\n41:\tlearn: 1.6482332\ttotal: 18.6s\tremaining: 4m 7s\n42:\tlearn: 1.6356721\ttotal: 19.1s\tremaining: 4m 7s\n43:\tlearn: 1.6285926\ttotal: 19.5s\tremaining: 4m 6s\n44:\tlearn: 1.6204154\ttotal: 19.9s\tremaining: 4m 5s\n45:\tlearn: 1.6183356\ttotal: 20.4s\tremaining: 4m 5s\n46:\tlearn: 1.6090606\ttotal: 20.8s\tremaining: 4m 4s\n47:\tlearn: 1.5997931\ttotal: 21.2s\tremaining: 4m 4s\n48:\tlearn: 1.5921308\ttotal: 21.7s\tremaining: 4m 3s\n49:\tlearn: 1.5810712\ttotal: 22.1s\tremaining: 4m 3s\n50:\tlearn: 1.5754236\ttotal: 22.5s\tremaining: 4m 2s\n51:\tlearn: 1.5680687\ttotal: 23s\tremaining: 4m 2s\n52:\tlearn: 1.5617457\ttotal: 23.4s\tremaining: 4m 1s\n53:\tlearn: 1.5560104\ttotal: 23.8s\tremaining: 4m 1s\n54:\tlearn: 1.5505463\ttotal: 24.3s\tremaining: 4m\n55:\tlearn: 1.5455670\ttotal: 24.7s\tremaining: 3m 59s\n56:\tlearn: 1.5372564\ttotal: 25.1s\tremaining: 3m 59s\n57:\tlearn: 1.5240893\ttotal: 25.6s\tremaining: 3m 59s\n58:\tlearn: 1.5177661\ttotal: 26.1s\tremaining: 3m 59s\n59:\tlearn: 1.5109504\ttotal: 26.5s\tremaining: 3m 58s\n60:\tlearn: 1.5064141\ttotal: 27s\tremaining: 3m 58s\n61:\tlearn: 1.5005715\ttotal: 27.4s\tremaining: 3m 57s\n62:\tlearn: 1.4988203\ttotal: 27.8s\tremaining: 3m 57s\n63:\tlearn: 1.4930632\ttotal: 28.3s\tremaining: 3m 56s\n64:\tlearn: 1.4882906\ttotal: 28.7s\tremaining: 3m 56s\n65:\tlearn: 1.4869929\ttotal: 29.1s\tremaining: 3m 55s\n66:\tlearn: 1.4792974\ttotal: 29.5s\tremaining: 3m 55s\n67:\tlearn: 1.4738898\ttotal: 30s\tremaining: 3m 54s\n68:\tlearn: 1.4668576\ttotal: 30.4s\tremaining: 3m 54s\n69:\tlearn: 1.4579351\ttotal: 30.9s\tremaining: 3m 53s\n70:\tlearn: 1.4513157\ttotal: 31.3s\tremaining: 3m 53s\n71:\tlearn: 1.4420082\ttotal: 31.7s\tremaining: 3m 52s\n72:\tlearn: 1.4415802\ttotal: 32.2s\tremaining: 3m 52s\n73:\tlearn: 1.4373142\ttotal: 32.6s\tremaining: 3m 51s\n74:\tlearn: 1.4307741\ttotal: 33s\tremaining: 3m 51s\n75:\tlearn: 1.4225185\ttotal: 33.5s\tremaining: 3m 50s\n76:\tlearn: 1.4118218\ttotal: 34s\tremaining: 3m 50s\n77:\tlearn: 1.4079648\ttotal: 34.4s\tremaining: 3m 50s\n78:\tlearn: 1.4000295\ttotal: 34.8s\tremaining: 3m 49s\n79:\tlearn: 1.3963875\ttotal: 35.3s\tremaining: 3m 49s\n80:\tlearn: 1.3949528\ttotal: 35.7s\tremaining: 3m 48s\n81:\tlearn: 1.3894168\ttotal: 36.1s\tremaining: 3m 48s\n82:\tlearn: 1.3787914\ttotal: 36.6s\tremaining: 3m 47s\n83:\tlearn: 1.3728357\ttotal: 37s\tremaining: 3m 47s\n84:\tlearn: 1.3668851\ttotal: 37.5s\tremaining: 3m 46s\n85:\tlearn: 1.3614236\ttotal: 37.9s\tremaining: 3m 46s\n86:\tlearn: 1.3517049\ttotal: 38.4s\tremaining: 3m 46s\n87:\tlearn: 1.3461947\ttotal: 38.8s\tremaining: 3m 45s\n88:\tlearn: 1.3384236\ttotal: 39.3s\tremaining: 3m 45s\n89:\tlearn: 1.3330400\ttotal: 39.7s\tremaining: 3m 44s\n90:\tlearn: 1.3272040\ttotal: 40.1s\tremaining: 3m 44s\n91:\tlearn: 1.3220835\ttotal: 40.6s\tremaining: 3m 43s\n92:\tlearn: 1.3139822\ttotal: 41s\tremaining: 3m 43s\n93:\tlearn: 1.3120225\ttotal: 41.4s\tremaining: 3m 43s\n94:\tlearn: 1.3077030\ttotal: 41.9s\tremaining: 3m 42s\n95:\tlearn: 1.3045866\ttotal: 42.3s\tremaining: 3m 42s\n96:\tlearn: 1.2969698\ttotal: 42.7s\tremaining: 3m 41s\n97:\tlearn: 1.2911425\ttotal: 43.2s\tremaining: 3m 41s\n98:\tlearn: 1.2806916\ttotal: 43.6s\tremaining: 3m 40s\n99:\tlearn: 1.2762917\ttotal: 44.1s\tremaining: 3m 40s\n100:\tlearn: 1.2702424\ttotal: 44.5s\tremaining: 3m 39s\n101:\tlearn: 1.2625277\ttotal: 45s\tremaining: 3m 39s\n102:\tlearn: 1.2586930\ttotal: 45.4s\tremaining: 3m 38s\n103:\tlearn: 1.2530582\ttotal: 45.8s\tremaining: 3m 38s\n104:\tlearn: 1.2452826\ttotal: 46.3s\tremaining: 3m 38s\n105:\tlearn: 1.2383174\ttotal: 46.7s\tremaining: 3m 37s\n106:\tlearn: 1.2349537\ttotal: 47.1s\tremaining: 3m 37s\n107:\tlearn: 1.2284427\ttotal: 47.6s\tremaining: 3m 36s\n108:\tlearn: 1.2272826\ttotal: 48s\tremaining: 3m 36s\n109:\tlearn: 1.2174753\ttotal: 48.5s\tremaining: 3m 35s\n110:\tlearn: 1.2157631\ttotal: 48.9s\tremaining: 3m 35s\n111:\tlearn: 1.2093695\ttotal: 49.3s\tremaining: 3m 35s\n112:\tlearn: 1.2004104\ttotal: 49.8s\tremaining: 3m 34s\n113:\tlearn: 1.1938893\ttotal: 50.3s\tremaining: 3m 34s\n114:\tlearn: 1.1883012\ttotal: 50.7s\tremaining: 3m 33s\n115:\tlearn: 1.1872210\ttotal: 51.1s\tremaining: 3m 33s\n116:\tlearn: 1.1790483\ttotal: 51.6s\tremaining: 3m 32s\n117:\tlearn: 1.1740013\ttotal: 52s\tremaining: 3m 32s\n118:\tlearn: 1.1719979\ttotal: 52.4s\tremaining: 3m 31s\n119:\tlearn: 1.1671807\ttotal: 52.9s\tremaining: 3m 31s\n120:\tlearn: 1.1643148\ttotal: 53.3s\tremaining: 3m 31s\n121:\tlearn: 1.1611711\ttotal: 53.8s\tremaining: 3m 30s\n122:\tlearn: 1.1566210\ttotal: 54.2s\tremaining: 3m 30s\n123:\tlearn: 1.1524085\ttotal: 54.6s\tremaining: 3m 29s\n124:\tlearn: 1.1460248\ttotal: 55.1s\tremaining: 3m 29s\n125:\tlearn: 1.1402312\ttotal: 55.5s\tremaining: 3m 28s\n126:\tlearn: 1.1307807\ttotal: 56s\tremaining: 3m 28s\n127:\tlearn: 1.1260463\ttotal: 56.4s\tremaining: 3m 28s\n128:\tlearn: 1.1221057\ttotal: 56.9s\tremaining: 3m 27s\n129:\tlearn: 1.1183841\ttotal: 57.3s\tremaining: 3m 27s\n130:\tlearn: 1.1136212\ttotal: 57.7s\tremaining: 3m 26s\n131:\tlearn: 1.1121703\ttotal: 58.2s\tremaining: 3m 26s\n132:\tlearn: 1.1063298\ttotal: 58.6s\tremaining: 3m 25s\n133:\tlearn: 1.0994099\ttotal: 59.1s\tremaining: 3m 25s\n134:\tlearn: 1.0957357\ttotal: 59.5s\tremaining: 3m 25s\n135:\tlearn: 1.0905508\ttotal: 60s\tremaining: 3m 24s\n136:\tlearn: 1.0867389\ttotal: 1m\tremaining: 3m 24s\n137:\tlearn: 1.0844261\ttotal: 1m\tremaining: 3m 23s\n138:\tlearn: 1.0765043\ttotal: 1m 1s\tremaining: 3m 23s\n139:\tlearn: 1.0702299\ttotal: 1m 1s\tremaining: 3m 22s\n140:\tlearn: 1.0691799\ttotal: 1m 2s\tremaining: 3m 22s\n141:\tlearn: 1.0635362\ttotal: 1m 2s\tremaining: 3m 22s\n142:\tlearn: 1.0606781\ttotal: 1m 3s\tremaining: 3m 21s\n143:\tlearn: 1.0552215\ttotal: 1m 3s\tremaining: 3m 21s\n144:\tlearn: 1.0505271\ttotal: 1m 3s\tremaining: 3m 20s\n145:\tlearn: 1.0472874\ttotal: 1m 4s\tremaining: 3m 20s\n146:\tlearn: 1.0444421\ttotal: 1m 4s\tremaining: 3m 19s\n147:\tlearn: 1.0425980\ttotal: 1m 5s\tremaining: 3m 19s\n148:\tlearn: 1.0345426\ttotal: 1m 5s\tremaining: 3m 19s\n149:\tlearn: 1.0310938\ttotal: 1m 6s\tremaining: 3m 18s\n150:\tlearn: 1.0302688\ttotal: 1m 6s\tremaining: 3m 18s\n151:\tlearn: 1.0278633\ttotal: 1m 7s\tremaining: 3m 17s\n152:\tlearn: 1.0223905\ttotal: 1m 7s\tremaining: 3m 17s\n153:\tlearn: 1.0196854\ttotal: 1m 7s\tremaining: 3m 16s\n154:\tlearn: 1.0155364\ttotal: 1m 8s\tremaining: 3m 16s\n155:\tlearn: 1.0125282\ttotal: 1m 8s\tremaining: 3m 15s\n156:\tlearn: 1.0079240\ttotal: 1m 9s\tremaining: 3m 15s\n157:\tlearn: 1.0047982\ttotal: 1m 9s\tremaining: 3m 15s\n158:\tlearn: 1.0032780\ttotal: 1m 10s\tremaining: 3m 14s\n159:\tlearn: 1.0016615\ttotal: 1m 10s\tremaining: 3m 14s\n160:\tlearn: 0.9993635\ttotal: 1m 11s\tremaining: 3m 13s\n161:\tlearn: 0.9947981\ttotal: 1m 11s\tremaining: 3m 13s\n162:\tlearn: 0.9861396\ttotal: 1m 11s\tremaining: 3m 12s\n163:\tlearn: 0.9814540\ttotal: 1m 12s\tremaining: 3m 12s\n164:\tlearn: 0.9801526\ttotal: 1m 12s\tremaining: 3m 11s\n165:\tlearn: 0.9791332\ttotal: 1m 13s\tremaining: 3m 11s\n166:\tlearn: 0.9759879\ttotal: 1m 13s\tremaining: 3m 11s\n167:\tlearn: 0.9675389\ttotal: 1m 14s\tremaining: 3m 10s\n168:\tlearn: 0.9658477\ttotal: 1m 14s\tremaining: 3m 10s\n169:\tlearn: 0.9625371\ttotal: 1m 15s\tremaining: 3m 9s\n170:\tlearn: 0.9613983\ttotal: 1m 15s\tremaining: 3m 9s\n171:\tlearn: 0.9571039\ttotal: 1m 15s\tremaining: 3m 8s\n172:\tlearn: 0.9554793\ttotal: 1m 16s\tremaining: 3m 8s\n173:\tlearn: 0.9502819\ttotal: 1m 16s\tremaining: 3m 8s\n174:\tlearn: 0.9493575\ttotal: 1m 17s\tremaining: 3m 7s\n175:\tlearn: 0.9471731\ttotal: 1m 17s\tremaining: 3m 7s\n176:\tlearn: 0.9456048\ttotal: 1m 18s\tremaining: 3m 6s\n177:\tlearn: 0.9398977\ttotal: 1m 18s\tremaining: 3m 6s\n178:\tlearn: 0.9388103\ttotal: 1m 18s\tremaining: 3m 5s\n179:\tlearn: 0.9379776\ttotal: 1m 19s\tremaining: 3m 5s\n180:\tlearn: 0.9370778\ttotal: 1m 19s\tremaining: 3m 4s\n181:\tlearn: 0.9327193\ttotal: 1m 20s\tremaining: 3m 4s\n182:\tlearn: 0.9315376\ttotal: 1m 20s\tremaining: 3m 3s\n183:\tlearn: 0.9293084\ttotal: 1m 21s\tremaining: 3m 3s\n184:\tlearn: 0.9254959\ttotal: 1m 21s\tremaining: 3m 3s\n185:\tlearn: 0.9225870\ttotal: 1m 22s\tremaining: 3m 2s\n186:\tlearn: 0.9186240\ttotal: 1m 22s\tremaining: 3m 2s\n187:\tlearn: 0.9139170\ttotal: 1m 22s\tremaining: 3m 1s\n188:\tlearn: 0.9125850\ttotal: 1m 23s\tremaining: 3m 1s\n189:\tlearn: 0.9087278\ttotal: 1m 23s\tremaining: 3m\n190:\tlearn: 0.9057933\ttotal: 1m 24s\tremaining: 3m\n191:\tlearn: 0.9046423\ttotal: 1m 24s\tremaining: 3m\n192:\tlearn: 0.9016761\ttotal: 1m 25s\tremaining: 2m 59s\n193:\tlearn: 0.8993950\ttotal: 1m 25s\tremaining: 2m 59s\n194:\tlearn: 0.8944090\ttotal: 1m 26s\tremaining: 2m 58s\n195:\tlearn: 0.8922818\ttotal: 1m 26s\tremaining: 2m 58s\n196:\tlearn: 0.8873290\ttotal: 1m 26s\tremaining: 2m 57s\n197:\tlearn: 0.8829708\ttotal: 1m 27s\tremaining: 2m 57s\n198:\tlearn: 0.8814984\ttotal: 1m 27s\tremaining: 2m 56s\n199:\tlearn: 0.8777153\ttotal: 1m 28s\tremaining: 2m 56s\n200:\tlearn: 0.8752359\ttotal: 1m 28s\tremaining: 2m 56s\n201:\tlearn: 0.8704402\ttotal: 1m 29s\tremaining: 2m 55s\n202:\tlearn: 0.8686552\ttotal: 1m 29s\tremaining: 2m 55s\n203:\tlearn: 0.8653062\ttotal: 1m 30s\tremaining: 2m 54s\n204:\tlearn: 0.8631237\ttotal: 1m 30s\tremaining: 2m 54s\n205:\tlearn: 0.8597427\ttotal: 1m 30s\tremaining: 2m 54s\n206:\tlearn: 0.8559288\ttotal: 1m 31s\tremaining: 2m 53s\n207:\tlearn: 0.8516141\ttotal: 1m 31s\tremaining: 2m 53s\n208:\tlearn: 0.8512190\ttotal: 1m 32s\tremaining: 2m 52s\n209:\tlearn: 0.8498762\ttotal: 1m 32s\tremaining: 2m 52s\n210:\tlearn: 0.8468739\ttotal: 1m 33s\tremaining: 2m 51s\n211:\tlearn: 0.8452808\ttotal: 1m 33s\tremaining: 2m 51s\n212:\tlearn: 0.8436088\ttotal: 1m 34s\tremaining: 2m 50s\n213:\tlearn: 0.8428270\ttotal: 1m 34s\tremaining: 2m 50s\n214:\tlearn: 0.8421639\ttotal: 1m 34s\tremaining: 2m 49s\n215:\tlearn: 0.8404568\ttotal: 1m 35s\tremaining: 2m 49s\n216:\tlearn: 0.8367873\ttotal: 1m 35s\tremaining: 2m 49s\n217:\tlearn: 0.8348209\ttotal: 1m 36s\tremaining: 2m 48s\n218:\tlearn: 0.8331944\ttotal: 1m 36s\tremaining: 2m 48s\n219:\tlearn: 0.8324460\ttotal: 1m 37s\tremaining: 2m 47s\n220:\tlearn: 0.8316964\ttotal: 1m 37s\tremaining: 2m 47s\n221:\tlearn: 0.8297147\ttotal: 1m 37s\tremaining: 2m 46s\n222:\tlearn: 0.8262990\ttotal: 1m 38s\tremaining: 2m 46s\n223:\tlearn: 0.8256462\ttotal: 1m 38s\tremaining: 2m 45s\n224:\tlearn: 0.8247084\ttotal: 1m 39s\tremaining: 2m 45s\n225:\tlearn: 0.8206980\ttotal: 1m 39s\tremaining: 2m 45s\n226:\tlearn: 0.8192961\ttotal: 1m 40s\tremaining: 2m 44s\n227:\tlearn: 0.8158974\ttotal: 1m 40s\tremaining: 2m 44s\n228:\tlearn: 0.8144133\ttotal: 1m 41s\tremaining: 2m 43s\n229:\tlearn: 0.8133388\ttotal: 1m 41s\tremaining: 2m 43s\n230:\tlearn: 0.8116229\ttotal: 1m 41s\tremaining: 2m 42s\n231:\tlearn: 0.8097779\ttotal: 1m 42s\tremaining: 2m 42s\n232:\tlearn: 0.8085383\ttotal: 1m 42s\tremaining: 2m 41s\n233:\tlearn: 0.8073655\ttotal: 1m 43s\tremaining: 2m 41s\n234:\tlearn: 0.8023849\ttotal: 1m 43s\tremaining: 2m 41s\n235:\tlearn: 0.8018551\ttotal: 1m 44s\tremaining: 2m 40s\n236:\tlearn: 0.8003633\ttotal: 1m 44s\tremaining: 2m 40s\n237:\tlearn: 0.7990321\ttotal: 1m 45s\tremaining: 2m 39s\n238:\tlearn: 0.7962035\ttotal: 1m 45s\tremaining: 2m 39s\n239:\tlearn: 0.7957510\ttotal: 1m 45s\tremaining: 2m 38s\n240:\tlearn: 0.7944775\ttotal: 1m 46s\tremaining: 2m 38s\n241:\tlearn: 0.7938903\ttotal: 1m 46s\tremaining: 2m 37s\n242:\tlearn: 0.7930889\ttotal: 1m 47s\tremaining: 2m 37s\n243:\tlearn: 0.7917167\ttotal: 1m 47s\tremaining: 2m 37s\n244:\tlearn: 0.7901213\ttotal: 1m 48s\tremaining: 2m 36s\n245:\tlearn: 0.7891138\ttotal: 1m 48s\tremaining: 2m 36s\n246:\tlearn: 0.7881913\ttotal: 1m 48s\tremaining: 2m 35s\n247:\tlearn: 0.7877359\ttotal: 1m 49s\tremaining: 2m 35s\n248:\tlearn: 0.7860849\ttotal: 1m 49s\tremaining: 2m 34s\n249:\tlearn: 0.7839698\ttotal: 1m 50s\tremaining: 2m 34s\n250:\tlearn: 0.7819380\ttotal: 1m 50s\tremaining: 2m 33s\n251:\tlearn: 0.7812532\ttotal: 1m 51s\tremaining: 2m 33s\n252:\tlearn: 0.7797959\ttotal: 1m 51s\tremaining: 2m 32s\n253:\tlearn: 0.7773547\ttotal: 1m 51s\tremaining: 2m 32s\n254:\tlearn: 0.7768087\ttotal: 1m 52s\tremaining: 2m 32s\n255:\tlearn: 0.7747182\ttotal: 1m 52s\tremaining: 2m 31s\n256:\tlearn: 0.7726743\ttotal: 1m 53s\tremaining: 2m 31s\n257:\tlearn: 0.7708264\ttotal: 1m 53s\tremaining: 2m 30s\n258:\tlearn: 0.7699191\ttotal: 1m 54s\tremaining: 2m 30s\n259:\tlearn: 0.7694603\ttotal: 1m 54s\tremaining: 2m 29s\n260:\tlearn: 0.7688678\ttotal: 1m 55s\tremaining: 2m 29s\n261:\tlearn: 0.7669839\ttotal: 1m 55s\tremaining: 2m 28s\n262:\tlearn: 0.7668149\ttotal: 1m 55s\tremaining: 2m 28s\n263:\tlearn: 0.7663783\ttotal: 1m 56s\tremaining: 2m 28s\n264:\tlearn: 0.7656859\ttotal: 1m 56s\tremaining: 2m 27s\n265:\tlearn: 0.7654023\ttotal: 1m 57s\tremaining: 2m 27s\n266:\tlearn: 0.7641532\ttotal: 1m 57s\tremaining: 2m 26s\n267:\tlearn: 0.7632546\ttotal: 1m 58s\tremaining: 2m 26s\n268:\tlearn: 0.7613872\ttotal: 1m 58s\tremaining: 2m 25s\n269:\tlearn: 0.7597590\ttotal: 1m 58s\tremaining: 2m 25s\n270:\tlearn: 0.7587034\ttotal: 1m 59s\tremaining: 2m 24s\n271:\tlearn: 0.7567159\ttotal: 1m 59s\tremaining: 2m 24s\n272:\tlearn: 0.7559689\ttotal: 2m\tremaining: 2m 23s\n273:\tlearn: 0.7553787\ttotal: 2m\tremaining: 2m 23s\n274:\tlearn: 0.7547467\ttotal: 2m 1s\tremaining: 2m 23s\n275:\tlearn: 0.7543155\ttotal: 2m 1s\tremaining: 2m 22s\n276:\tlearn: 0.7538690\ttotal: 2m 1s\tremaining: 2m 22s\n277:\tlearn: 0.7525076\ttotal: 2m 2s\tremaining: 2m 21s\n278:\tlearn: 0.7489868\ttotal: 2m 2s\tremaining: 2m 21s\n279:\tlearn: 0.7479808\ttotal: 2m 3s\tremaining: 2m 20s\n280:\tlearn: 0.7446831\ttotal: 2m 3s\tremaining: 2m 20s\n281:\tlearn: 0.7435964\ttotal: 2m 4s\tremaining: 2m 20s\n282:\tlearn: 0.7430141\ttotal: 2m 4s\tremaining: 2m 19s\n283:\tlearn: 0.7425215\ttotal: 2m 5s\tremaining: 2m 19s\n284:\tlearn: 0.7414556\ttotal: 2m 5s\tremaining: 2m 18s\n285:\tlearn: 0.7397693\ttotal: 2m 5s\tremaining: 2m 18s\n286:\tlearn: 0.7388268\ttotal: 2m 6s\tremaining: 2m 17s\n287:\tlearn: 0.7385696\ttotal: 2m 6s\tremaining: 2m 17s\n288:\tlearn: 0.7379567\ttotal: 2m 7s\tremaining: 2m 16s\n289:\tlearn: 0.7349693\ttotal: 2m 7s\tremaining: 2m 16s\n290:\tlearn: 0.7346288\ttotal: 2m 8s\tremaining: 2m 15s\n291:\tlearn: 0.7290597\ttotal: 2m 8s\tremaining: 2m 15s\n292:\tlearn: 0.7286965\ttotal: 2m 8s\tremaining: 2m 15s\n293:\tlearn: 0.7283028\ttotal: 2m 9s\tremaining: 2m 14s\n294:\tlearn: 0.7280484\ttotal: 2m 9s\tremaining: 2m 14s\n295:\tlearn: 0.7275964\ttotal: 2m 10s\tremaining: 2m 13s\n296:\tlearn: 0.7269097\ttotal: 2m 10s\tremaining: 2m 13s\n297:\tlearn: 0.7248595\ttotal: 2m 11s\tremaining: 2m 12s\n298:\tlearn: 0.7217933\ttotal: 2m 11s\tremaining: 2m 12s\n299:\tlearn: 0.7213954\ttotal: 2m 12s\tremaining: 2m 12s\n300:\tlearn: 0.7208603\ttotal: 2m 12s\tremaining: 2m 11s\n301:\tlearn: 0.7200825\ttotal: 2m 12s\tremaining: 2m 11s\n302:\tlearn: 0.7191257\ttotal: 2m 13s\tremaining: 2m 10s\n303:\tlearn: 0.7186885\ttotal: 2m 13s\tremaining: 2m 10s\n304:\tlearn: 0.7171441\ttotal: 2m 14s\tremaining: 2m 9s\n305:\tlearn: 0.7156541\ttotal: 2m 14s\tremaining: 2m 9s\n306:\tlearn: 0.7139078\ttotal: 2m 15s\tremaining: 2m 8s\n307:\tlearn: 0.7126349\ttotal: 2m 15s\tremaining: 2m 8s\n308:\tlearn: 0.7124014\ttotal: 2m 15s\tremaining: 2m 8s\n309:\tlearn: 0.7121897\ttotal: 2m 16s\tremaining: 2m 7s\n310:\tlearn: 0.7116677\ttotal: 2m 16s\tremaining: 2m 7s\n311:\tlearn: 0.7106644\ttotal: 2m 17s\tremaining: 2m 6s\n312:\tlearn: 0.7100825\ttotal: 2m 17s\tremaining: 2m 6s\n313:\tlearn: 0.7097392\ttotal: 2m 18s\tremaining: 2m 5s\n314:\tlearn: 0.7077970\ttotal: 2m 18s\tremaining: 2m 5s\n315:\tlearn: 0.7076401\ttotal: 2m 18s\tremaining: 2m 4s\n316:\tlearn: 0.7057372\ttotal: 2m 19s\tremaining: 2m 4s\n317:\tlearn: 0.7044789\ttotal: 2m 19s\tremaining: 2m 4s\n318:\tlearn: 0.7038758\ttotal: 2m 20s\tremaining: 2m 3s\n319:\tlearn: 0.7036657\ttotal: 2m 20s\tremaining: 2m 3s\n320:\tlearn: 0.7034370\ttotal: 2m 21s\tremaining: 2m 2s\n321:\tlearn: 0.7027873\ttotal: 2m 21s\tremaining: 2m 2s\n322:\tlearn: 0.7021913\ttotal: 2m 22s\tremaining: 2m 1s\n323:\tlearn: 0.7014518\ttotal: 2m 22s\tremaining: 2m 1s\n324:\tlearn: 0.7002977\ttotal: 2m 22s\tremaining: 2m\n325:\tlearn: 0.6991141\ttotal: 2m 23s\tremaining: 2m\n326:\tlearn: 0.6987512\ttotal: 2m 23s\tremaining: 2m\n327:\tlearn: 0.6962360\ttotal: 2m 24s\tremaining: 1m 59s\n328:\tlearn: 0.6956267\ttotal: 2m 24s\tremaining: 1m 59s\n329:\tlearn: 0.6944336\ttotal: 2m 25s\tremaining: 1m 58s\n330:\tlearn: 0.6929377\ttotal: 2m 25s\tremaining: 1m 58s\n331:\tlearn: 0.6895985\ttotal: 2m 25s\tremaining: 1m 57s\n332:\tlearn: 0.6885829\ttotal: 2m 26s\tremaining: 1m 57s\n333:\tlearn: 0.6879398\ttotal: 2m 26s\tremaining: 1m 56s\n334:\tlearn: 0.6856389\ttotal: 2m 27s\tremaining: 1m 56s\n335:\tlearn: 0.6851490\ttotal: 2m 27s\tremaining: 1m 56s\n336:\tlearn: 0.6831415\ttotal: 2m 28s\tremaining: 1m 55s\n337:\tlearn: 0.6829671\ttotal: 2m 28s\tremaining: 1m 55s\n338:\tlearn: 0.6825334\ttotal: 2m 29s\tremaining: 1m 54s\n339:\tlearn: 0.6815487\ttotal: 2m 29s\tremaining: 1m 54s\n340:\tlearn: 0.6797419\ttotal: 2m 29s\tremaining: 1m 53s\n341:\tlearn: 0.6783870\ttotal: 2m 30s\tremaining: 1m 53s\n342:\tlearn: 0.6780322\ttotal: 2m 30s\tremaining: 1m 52s\n343:\tlearn: 0.6777361\ttotal: 2m 31s\tremaining: 1m 52s\n344:\tlearn: 0.6760512\ttotal: 2m 31s\tremaining: 1m 52s\n345:\tlearn: 0.6758395\ttotal: 2m 32s\tremaining: 1m 51s\n346:\tlearn: 0.6752634\ttotal: 2m 32s\tremaining: 1m 51s\n347:\tlearn: 0.6733888\ttotal: 2m 32s\tremaining: 1m 50s\n348:\tlearn: 0.6721856\ttotal: 2m 33s\tremaining: 1m 50s\n349:\tlearn: 0.6719223\ttotal: 2m 33s\tremaining: 1m 49s\n350:\tlearn: 0.6713470\ttotal: 2m 34s\tremaining: 1m 49s\n351:\tlearn: 0.6708982\ttotal: 2m 34s\tremaining: 1m 49s\n352:\tlearn: 0.6697653\ttotal: 2m 35s\tremaining: 1m 48s\n353:\tlearn: 0.6684627\ttotal: 2m 35s\tremaining: 1m 48s\n354:\tlearn: 0.6681163\ttotal: 2m 36s\tremaining: 1m 47s\n355:\tlearn: 0.6666124\ttotal: 2m 36s\tremaining: 1m 47s\n356:\tlearn: 0.6662345\ttotal: 2m 36s\tremaining: 1m 46s\n357:\tlearn: 0.6645883\ttotal: 2m 37s\tremaining: 1m 46s\n358:\tlearn: 0.6631252\ttotal: 2m 37s\tremaining: 1m 45s\n359:\tlearn: 0.6620252\ttotal: 2m 38s\tremaining: 1m 45s\n360:\tlearn: 0.6616376\ttotal: 2m 38s\tremaining: 1m 45s\n361:\tlearn: 0.6609717\ttotal: 2m 39s\tremaining: 1m 44s\n362:\tlearn: 0.6598092\ttotal: 2m 39s\tremaining: 1m 44s\n363:\tlearn: 0.6596489\ttotal: 2m 39s\tremaining: 1m 43s\n364:\tlearn: 0.6580222\ttotal: 2m 40s\tremaining: 1m 43s\n365:\tlearn: 0.6577879\ttotal: 2m 40s\tremaining: 1m 42s\n366:\tlearn: 0.6542988\ttotal: 2m 41s\tremaining: 1m 42s\n367:\tlearn: 0.6531174\ttotal: 2m 41s\tremaining: 1m 41s\n368:\tlearn: 0.6498897\ttotal: 2m 42s\tremaining: 1m 41s\n369:\tlearn: 0.6494650\ttotal: 2m 42s\tremaining: 1m 41s\n370:\tlearn: 0.6490993\ttotal: 2m 43s\tremaining: 1m 40s\n371:\tlearn: 0.6463519\ttotal: 2m 43s\tremaining: 1m 40s\n372:\tlearn: 0.6460148\ttotal: 2m 43s\tremaining: 1m 39s\n373:\tlearn: 0.6458869\ttotal: 2m 44s\tremaining: 1m 39s\n374:\tlearn: 0.6455282\ttotal: 2m 44s\tremaining: 1m 38s\n375:\tlearn: 0.6452453\ttotal: 2m 45s\tremaining: 1m 38s\n376:\tlearn: 0.6448324\ttotal: 2m 45s\tremaining: 1m 37s\n377:\tlearn: 0.6440917\ttotal: 2m 46s\tremaining: 1m 37s\n378:\tlearn: 0.6416000\ttotal: 2m 46s\tremaining: 1m 37s\n379:\tlearn: 0.6414463\ttotal: 2m 46s\tremaining: 1m 36s\n380:\tlearn: 0.6401301\ttotal: 2m 47s\tremaining: 1m 36s\n381:\tlearn: 0.6373269\ttotal: 2m 47s\tremaining: 1m 35s\n382:\tlearn: 0.6371901\ttotal: 2m 48s\tremaining: 1m 35s\n383:\tlearn: 0.6368420\ttotal: 2m 48s\tremaining: 1m 34s\n384:\tlearn: 0.6344820\ttotal: 2m 49s\tremaining: 1m 34s\n385:\tlearn: 0.6336380\ttotal: 2m 49s\tremaining: 1m 34s\n386:\tlearn: 0.6331839\ttotal: 2m 50s\tremaining: 1m 33s\n387:\tlearn: 0.6323515\ttotal: 2m 50s\tremaining: 1m 33s\n388:\tlearn: 0.6322201\ttotal: 2m 50s\tremaining: 1m 32s\n389:\tlearn: 0.6315428\ttotal: 2m 51s\tremaining: 1m 32s\n390:\tlearn: 0.6293757\ttotal: 2m 51s\tremaining: 1m 31s\n391:\tlearn: 0.6290241\ttotal: 2m 52s\tremaining: 1m 31s\n392:\tlearn: 0.6289112\ttotal: 2m 52s\tremaining: 1m 30s\n393:\tlearn: 0.6286801\ttotal: 2m 53s\tremaining: 1m 30s\n394:\tlearn: 0.6280916\ttotal: 2m 53s\tremaining: 1m 30s\n395:\tlearn: 0.6267436\ttotal: 2m 53s\tremaining: 1m 29s\n396:\tlearn: 0.6258703\ttotal: 2m 54s\tremaining: 1m 29s\n397:\tlearn: 0.6225544\ttotal: 2m 54s\tremaining: 1m 28s\n398:\tlearn: 0.6223312\ttotal: 2m 55s\tremaining: 1m 28s\n399:\tlearn: 0.6212946\ttotal: 2m 55s\tremaining: 1m 27s\n400:\tlearn: 0.6205279\ttotal: 2m 56s\tremaining: 1m 27s\n401:\tlearn: 0.6186285\ttotal: 2m 56s\tremaining: 1m 26s\n402:\tlearn: 0.6181367\ttotal: 2m 56s\tremaining: 1m 26s\n403:\tlearn: 0.6157607\ttotal: 2m 57s\tremaining: 1m 26s\n404:\tlearn: 0.6153138\ttotal: 2m 57s\tremaining: 1m 25s\n405:\tlearn: 0.6144343\ttotal: 2m 58s\tremaining: 1m 25s\n406:\tlearn: 0.6133361\ttotal: 2m 58s\tremaining: 1m 24s\n407:\tlearn: 0.6122956\ttotal: 2m 59s\tremaining: 1m 24s\n408:\tlearn: 0.6118300\ttotal: 2m 59s\tremaining: 1m 23s\n409:\tlearn: 0.6110234\ttotal: 3m\tremaining: 1m 23s\n410:\tlearn: 0.6108100\ttotal: 3m\tremaining: 1m 23s\n411:\tlearn: 0.6107124\ttotal: 3m\tremaining: 1m 22s\n412:\tlearn: 0.6105025\ttotal: 3m 1s\tremaining: 1m 22s\n413:\tlearn: 0.6102108\ttotal: 3m 1s\tremaining: 1m 21s\n414:\tlearn: 0.6098139\ttotal: 3m 2s\tremaining: 1m 21s\n415:\tlearn: 0.6085581\ttotal: 3m 2s\tremaining: 1m 20s\n416:\tlearn: 0.6078820\ttotal: 3m 3s\tremaining: 1m 20s\n417:\tlearn: 0.6077173\ttotal: 3m 3s\tremaining: 1m 19s\n418:\tlearn: 0.6071122\ttotal: 3m 3s\tremaining: 1m 19s\n419:\tlearn: 0.6053350\ttotal: 3m 4s\tremaining: 1m 19s\n420:\tlearn: 0.6030307\ttotal: 3m 4s\tremaining: 1m 18s\n421:\tlearn: 0.6024703\ttotal: 3m 5s\tremaining: 1m 18s\n422:\tlearn: 0.6013695\ttotal: 3m 5s\tremaining: 1m 17s\n423:\tlearn: 0.6009176\ttotal: 3m 6s\tremaining: 1m 17s\n424:\tlearn: 0.6002523\ttotal: 3m 6s\tremaining: 1m 16s\n425:\tlearn: 0.5982897\ttotal: 3m 7s\tremaining: 1m 16s\n426:\tlearn: 0.5977079\ttotal: 3m 7s\tremaining: 1m 15s\n427:\tlearn: 0.5974520\ttotal: 3m 7s\tremaining: 1m 15s\n428:\tlearn: 0.5971416\ttotal: 3m 8s\tremaining: 1m 15s\n429:\tlearn: 0.5965270\ttotal: 3m 8s\tremaining: 1m 14s\n430:\tlearn: 0.5958868\ttotal: 3m 9s\tremaining: 1m 14s\n431:\tlearn: 0.5953614\ttotal: 3m 9s\tremaining: 1m 13s\n432:\tlearn: 0.5950439\ttotal: 3m 10s\tremaining: 1m 13s\n433:\tlearn: 0.5947118\ttotal: 3m 10s\tremaining: 1m 12s\n434:\tlearn: 0.5939750\ttotal: 3m 10s\tremaining: 1m 12s\n435:\tlearn: 0.5935387\ttotal: 3m 11s\tremaining: 1m 11s\n436:\tlearn: 0.5931759\ttotal: 3m 11s\tremaining: 1m 11s\n437:\tlearn: 0.5929649\ttotal: 3m 12s\tremaining: 1m 11s\n438:\tlearn: 0.5908461\ttotal: 3m 12s\tremaining: 1m 10s\n439:\tlearn: 0.5897573\ttotal: 3m 13s\tremaining: 1m 10s\n440:\tlearn: 0.5894340\ttotal: 3m 13s\tremaining: 1m 9s\n441:\tlearn: 0.5893686\ttotal: 3m 13s\tremaining: 1m 9s\n442:\tlearn: 0.5863222\ttotal: 3m 14s\tremaining: 1m 8s\n443:\tlearn: 0.5860751\ttotal: 3m 14s\tremaining: 1m 8s\n444:\tlearn: 0.5843768\ttotal: 3m 15s\tremaining: 1m 8s\n445:\tlearn: 0.5827363\ttotal: 3m 15s\tremaining: 1m 7s\n446:\tlearn: 0.5824725\ttotal: 3m 16s\tremaining: 1m 7s\n447:\tlearn: 0.5808813\ttotal: 3m 16s\tremaining: 1m 6s\n448:\tlearn: 0.5801615\ttotal: 3m 17s\tremaining: 1m 6s\n449:\tlearn: 0.5797691\ttotal: 3m 17s\tremaining: 1m 5s\n450:\tlearn: 0.5767218\ttotal: 3m 17s\tremaining: 1m 5s\n451:\tlearn: 0.5754527\ttotal: 3m 18s\tremaining: 1m 4s\n452:\tlearn: 0.5747700\ttotal: 3m 18s\tremaining: 1m 4s\n453:\tlearn: 0.5744485\ttotal: 3m 19s\tremaining: 1m 4s\n454:\tlearn: 0.5727637\ttotal: 3m 19s\tremaining: 1m 3s\n455:\tlearn: 0.5695714\ttotal: 3m 20s\tremaining: 1m 3s\n456:\tlearn: 0.5689553\ttotal: 3m 20s\tremaining: 1m 2s\n457:\tlearn: 0.5680974\ttotal: 3m 21s\tremaining: 1m 2s\n458:\tlearn: 0.5671466\ttotal: 3m 21s\tremaining: 1m 1s\n459:\tlearn: 0.5662267\ttotal: 3m 21s\tremaining: 1m 1s\n460:\tlearn: 0.5656419\ttotal: 3m 22s\tremaining: 1m 1s\n461:\tlearn: 0.5652318\ttotal: 3m 22s\tremaining: 1m\n462:\tlearn: 0.5630966\ttotal: 3m 23s\tremaining: 1m\n463:\tlearn: 0.5627926\ttotal: 3m 23s\tremaining: 59.7s\n464:\tlearn: 0.5623809\ttotal: 3m 24s\tremaining: 59.3s\n465:\tlearn: 0.5620326\ttotal: 3m 24s\tremaining: 58.8s\n466:\tlearn: 0.5595741\ttotal: 3m 25s\tremaining: 58.4s\n467:\tlearn: 0.5592232\ttotal: 3m 25s\tremaining: 58s\n468:\tlearn: 0.5588955\ttotal: 3m 25s\tremaining: 57.5s\n469:\tlearn: 0.5577682\ttotal: 3m 26s\tremaining: 57.1s\n470:\tlearn: 0.5575819\ttotal: 3m 26s\tremaining: 56.6s\n471:\tlearn: 0.5563399\ttotal: 3m 27s\tremaining: 56.2s\n472:\tlearn: 0.5560949\ttotal: 3m 27s\tremaining: 55.8s\n473:\tlearn: 0.5560147\ttotal: 3m 28s\tremaining: 55.3s\n474:\tlearn: 0.5543372\ttotal: 3m 28s\tremaining: 54.9s\n475:\tlearn: 0.5542008\ttotal: 3m 28s\tremaining: 54.4s\n476:\tlearn: 0.5517610\ttotal: 3m 29s\tremaining: 54s\n477:\tlearn: 0.5516309\ttotal: 3m 29s\tremaining: 53.6s\n478:\tlearn: 0.5513483\ttotal: 3m 30s\tremaining: 53.1s\n479:\tlearn: 0.5510379\ttotal: 3m 30s\tremaining: 52.7s\n480:\tlearn: 0.5508451\ttotal: 3m 31s\tremaining: 52.2s\n481:\tlearn: 0.5507307\ttotal: 3m 31s\tremaining: 51.8s\n482:\tlearn: 0.5496066\ttotal: 3m 32s\tremaining: 51.4s\n483:\tlearn: 0.5487392\ttotal: 3m 32s\tremaining: 50.9s\n484:\tlearn: 0.5481147\ttotal: 3m 32s\tremaining: 50.5s\n485:\tlearn: 0.5468186\ttotal: 3m 33s\tremaining: 50s\n486:\tlearn: 0.5466660\ttotal: 3m 33s\tremaining: 49.6s\n487:\tlearn: 0.5447573\ttotal: 3m 34s\tremaining: 49.2s\n488:\tlearn: 0.5444228\ttotal: 3m 34s\tremaining: 48.7s\n489:\tlearn: 0.5431213\ttotal: 3m 35s\tremaining: 48.3s\n490:\tlearn: 0.5427738\ttotal: 3m 35s\tremaining: 47.9s\n491:\tlearn: 0.5424097\ttotal: 3m 35s\tremaining: 47.4s\n492:\tlearn: 0.5419886\ttotal: 3m 36s\tremaining: 47s\n493:\tlearn: 0.5398257\ttotal: 3m 36s\tremaining: 46.5s\n494:\tlearn: 0.5390493\ttotal: 3m 37s\tremaining: 46.1s\n495:\tlearn: 0.5387278\ttotal: 3m 37s\tremaining: 45.7s\n496:\tlearn: 0.5384775\ttotal: 3m 38s\tremaining: 45.2s\n497:\tlearn: 0.5356662\ttotal: 3m 38s\tremaining: 44.8s\n498:\tlearn: 0.5353493\ttotal: 3m 39s\tremaining: 44.3s\n499:\tlearn: 0.5350138\ttotal: 3m 39s\tremaining: 43.9s\n500:\tlearn: 0.5332892\ttotal: 3m 39s\tremaining: 43.5s\n501:\tlearn: 0.5329033\ttotal: 3m 40s\tremaining: 43s\n502:\tlearn: 0.5322730\ttotal: 3m 40s\tremaining: 42.6s\n503:\tlearn: 0.5292592\ttotal: 3m 41s\tremaining: 42.2s\n504:\tlearn: 0.5286109\ttotal: 3m 41s\tremaining: 41.7s\n505:\tlearn: 0.5282494\ttotal: 3m 42s\tremaining: 41.3s\n506:\tlearn: 0.5280984\ttotal: 3m 42s\tremaining: 40.8s\n507:\tlearn: 0.5277483\ttotal: 3m 43s\tremaining: 40.4s\n508:\tlearn: 0.5275878\ttotal: 3m 43s\tremaining: 40s\n509:\tlearn: 0.5271896\ttotal: 3m 43s\tremaining: 39.5s\n510:\tlearn: 0.5266026\ttotal: 3m 44s\tremaining: 39.1s\n511:\tlearn: 0.5264599\ttotal: 3m 44s\tremaining: 38.6s\n512:\tlearn: 0.5247758\ttotal: 3m 45s\tremaining: 38.2s\n513:\tlearn: 0.5243873\ttotal: 3m 45s\tremaining: 37.8s\n514:\tlearn: 0.5242404\ttotal: 3m 46s\tremaining: 37.3s\n515:\tlearn: 0.5233459\ttotal: 3m 46s\tremaining: 36.9s\n516:\tlearn: 0.5218855\ttotal: 3m 47s\tremaining: 36.4s\n517:\tlearn: 0.5213516\ttotal: 3m 47s\tremaining: 36s\n518:\tlearn: 0.5210402\ttotal: 3m 47s\tremaining: 35.6s\n519:\tlearn: 0.5190321\ttotal: 3m 48s\tremaining: 35.1s\n520:\tlearn: 0.5188505\ttotal: 3m 48s\tremaining: 34.7s\n521:\tlearn: 0.5184522\ttotal: 3m 49s\tremaining: 34.2s\n522:\tlearn: 0.5182969\ttotal: 3m 49s\tremaining: 33.8s\n523:\tlearn: 0.5178158\ttotal: 3m 50s\tremaining: 33.4s\n524:\tlearn: 0.5177319\ttotal: 3m 50s\tremaining: 32.9s\n525:\tlearn: 0.5175212\ttotal: 3m 50s\tremaining: 32.5s\n526:\tlearn: 0.5172347\ttotal: 3m 51s\tremaining: 32s\n527:\tlearn: 0.5170876\ttotal: 3m 51s\tremaining: 31.6s\n528:\tlearn: 0.5157739\ttotal: 3m 52s\tremaining: 31.2s\n529:\tlearn: 0.5153567\ttotal: 3m 52s\tremaining: 30.7s\n530:\tlearn: 0.5150478\ttotal: 3m 53s\tremaining: 30.3s\n531:\tlearn: 0.5147143\ttotal: 3m 53s\tremaining: 29.8s\n532:\tlearn: 0.5139528\ttotal: 3m 53s\tremaining: 29.4s\n533:\tlearn: 0.5136070\ttotal: 3m 54s\tremaining: 29s\n534:\tlearn: 0.5126680\ttotal: 3m 54s\tremaining: 28.5s\n535:\tlearn: 0.5121740\ttotal: 3m 55s\tremaining: 28.1s\n536:\tlearn: 0.5105392\ttotal: 3m 55s\tremaining: 27.7s\n537:\tlearn: 0.5104190\ttotal: 3m 56s\tremaining: 27.2s\n538:\tlearn: 0.5095679\ttotal: 3m 56s\tremaining: 26.8s\n539:\tlearn: 0.5090277\ttotal: 3m 57s\tremaining: 26.3s\n540:\tlearn: 0.5083081\ttotal: 3m 57s\tremaining: 25.9s\n541:\tlearn: 0.5081680\ttotal: 3m 57s\tremaining: 25.5s\n542:\tlearn: 0.5079451\ttotal: 3m 58s\tremaining: 25s\n543:\tlearn: 0.5077281\ttotal: 3m 58s\tremaining: 24.6s\n544:\tlearn: 0.5075093\ttotal: 3m 59s\tremaining: 24.1s\n545:\tlearn: 0.5074093\ttotal: 3m 59s\tremaining: 23.7s\n546:\tlearn: 0.5069966\ttotal: 4m\tremaining: 23.3s\n547:\tlearn: 0.5067545\ttotal: 4m\tremaining: 22.8s\n548:\tlearn: 0.5064030\ttotal: 4m\tremaining: 22.4s\n549:\tlearn: 0.5061962\ttotal: 4m 1s\tremaining: 21.9s\n550:\tlearn: 0.5058941\ttotal: 4m 1s\tremaining: 21.5s\n551:\tlearn: 0.5051926\ttotal: 4m 2s\tremaining: 21.1s\n552:\tlearn: 0.5045819\ttotal: 4m 2s\tremaining: 20.6s\n553:\tlearn: 0.5044483\ttotal: 4m 3s\tremaining: 20.2s\n554:\tlearn: 0.5043401\ttotal: 4m 3s\tremaining: 19.7s\n555:\tlearn: 0.5038708\ttotal: 4m 3s\tremaining: 19.3s\n556:\tlearn: 0.5036197\ttotal: 4m 4s\tremaining: 18.9s\n557:\tlearn: 0.5030727\ttotal: 4m 4s\tremaining: 18.4s\n558:\tlearn: 0.5030224\ttotal: 4m 5s\tremaining: 18s\n559:\tlearn: 0.5023129\ttotal: 4m 5s\tremaining: 17.5s\n560:\tlearn: 0.5022169\ttotal: 4m 6s\tremaining: 17.1s\n561:\tlearn: 0.5020717\ttotal: 4m 6s\tremaining: 16.7s\n562:\tlearn: 0.5019861\ttotal: 4m 6s\tremaining: 16.2s\n563:\tlearn: 0.5017087\ttotal: 4m 7s\tremaining: 15.8s\n564:\tlearn: 0.5011240\ttotal: 4m 7s\tremaining: 15.3s\n565:\tlearn: 0.5010004\ttotal: 4m 8s\tremaining: 14.9s\n566:\tlearn: 0.4988408\ttotal: 4m 8s\tremaining: 14.5s\n567:\tlearn: 0.4978103\ttotal: 4m 9s\tremaining: 14s\n568:\tlearn: 0.4975089\ttotal: 4m 9s\tremaining: 13.6s\n569:\tlearn: 0.4969930\ttotal: 4m 10s\tremaining: 13.2s\n570:\tlearn: 0.4967353\ttotal: 4m 10s\tremaining: 12.7s\n571:\tlearn: 0.4963493\ttotal: 4m 10s\tremaining: 12.3s\n572:\tlearn: 0.4947020\ttotal: 4m 11s\tremaining: 11.8s\n573:\tlearn: 0.4942830\ttotal: 4m 11s\tremaining: 11.4s\n574:\tlearn: 0.4942424\ttotal: 4m 12s\tremaining: 11s\n575:\tlearn: 0.4936856\ttotal: 4m 12s\tremaining: 10.5s\n576:\tlearn: 0.4924922\ttotal: 4m 13s\tremaining: 10.1s\n577:\tlearn: 0.4923306\ttotal: 4m 13s\tremaining: 9.65s\n578:\tlearn: 0.4920871\ttotal: 4m 13s\tremaining: 9.21s\n579:\tlearn: 0.4919820\ttotal: 4m 14s\tremaining: 8.77s\n580:\tlearn: 0.4917708\ttotal: 4m 14s\tremaining: 8.33s\n581:\tlearn: 0.4916665\ttotal: 4m 15s\tremaining: 7.89s\n582:\tlearn: 0.4897544\ttotal: 4m 15s\tremaining: 7.46s\n583:\tlearn: 0.4895780\ttotal: 4m 16s\tremaining: 7.02s\n584:\tlearn: 0.4890537\ttotal: 4m 16s\tremaining: 6.58s\n585:\tlearn: 0.4885538\ttotal: 4m 16s\tremaining: 6.14s\n586:\tlearn: 0.4880758\ttotal: 4m 17s\tremaining: 5.7s\n587:\tlearn: 0.4879315\ttotal: 4m 17s\tremaining: 5.26s\n588:\tlearn: 0.4874437\ttotal: 4m 18s\tremaining: 4.82s\n589:\tlearn: 0.4869407\ttotal: 4m 18s\tremaining: 4.38s\n590:\tlearn: 0.4866977\ttotal: 4m 19s\tremaining: 3.95s\n591:\tlearn: 0.4865869\ttotal: 4m 19s\tremaining: 3.51s\n592:\tlearn: 0.4856356\ttotal: 4m 20s\tremaining: 3.07s\n593:\tlearn: 0.4855119\ttotal: 4m 20s\tremaining: 2.63s\n594:\tlearn: 0.4852091\ttotal: 4m 20s\tremaining: 2.19s\n595:\tlearn: 0.4841858\ttotal: 4m 21s\tremaining: 1.75s\n596:\tlearn: 0.4839616\ttotal: 4m 21s\tremaining: 1.31s\n597:\tlearn: 0.4828201\ttotal: 4m 22s\tremaining: 877ms\n598:\tlearn: 0.4827324\ttotal: 4m 22s\tremaining: 438ms\n599:\tlearn: 0.4821207\ttotal: 4m 23s\tremaining: 0us\ncat_fit_done\nmodel_ready\n0:\tlearn: 2.5877066\ttotal: 342ms\tremaining: 3m 24s\n1:\tlearn: 2.4717951\ttotal: 678ms\tremaining: 3m 22s\n2:\tlearn: 2.3705206\ttotal: 1.02s\tremaining: 3m 22s\n3:\tlearn: 2.2894679\ttotal: 1.36s\tremaining: 3m 22s\n4:\tlearn: 2.1955917\ttotal: 1.7s\tremaining: 3m 21s\n5:\tlearn: 2.1282962\ttotal: 2.04s\tremaining: 3m 21s\n6:\tlearn: 2.0692263\ttotal: 2.37s\tremaining: 3m 21s\n7:\tlearn: 2.0125143\ttotal: 2.71s\tremaining: 3m 20s\n8:\tlearn: 1.9628714\ttotal: 3.05s\tremaining: 3m 20s\n9:\tlearn: 1.9149322\ttotal: 3.39s\tremaining: 3m 19s\n10:\tlearn: 1.8851222\ttotal: 3.72s\tremaining: 3m 19s\n11:\tlearn: 1.8425039\ttotal: 4.06s\tremaining: 3m 18s\n12:\tlearn: 1.8140134\ttotal: 4.39s\tremaining: 3m 18s\n13:\tlearn: 1.7773232\ttotal: 4.73s\tremaining: 3m 18s\n14:\tlearn: 1.7481295\ttotal: 5.08s\tremaining: 3m 18s\n15:\tlearn: 1.7181291\ttotal: 5.43s\tremaining: 3m 18s\n16:\tlearn: 1.6894530\ttotal: 5.76s\tremaining: 3m 17s\n17:\tlearn: 1.6638137\ttotal: 6.11s\tremaining: 3m 17s\n18:\tlearn: 1.6397188\ttotal: 6.45s\tremaining: 3m 17s\n19:\tlearn: 1.6206227\ttotal: 6.79s\tremaining: 3m 16s\n20:\tlearn: 1.5935964\ttotal: 7.12s\tremaining: 3m 16s\n21:\tlearn: 1.5744677\ttotal: 7.46s\tremaining: 3m 16s\n22:\tlearn: 1.5622167\ttotal: 7.8s\tremaining: 3m 15s\n23:\tlearn: 1.5435584\ttotal: 8.14s\tremaining: 3m 15s\n24:\tlearn: 1.5291523\ttotal: 8.48s\tremaining: 3m 15s\n25:\tlearn: 1.5128292\ttotal: 8.81s\tremaining: 3m 14s\n26:\tlearn: 1.4937690\ttotal: 9.16s\tremaining: 3m 14s\n27:\tlearn: 1.4743591\ttotal: 9.5s\tremaining: 3m 14s\n28:\tlearn: 1.4568150\ttotal: 9.85s\tremaining: 3m 13s\n29:\tlearn: 1.4338069\ttotal: 10.2s\tremaining: 3m 13s\n30:\tlearn: 1.4126801\ttotal: 10.5s\tremaining: 3m 13s\n31:\tlearn: 1.3937868\ttotal: 10.9s\tremaining: 3m 13s\n32:\tlearn: 1.3848646\ttotal: 11.2s\tremaining: 3m 12s\n33:\tlearn: 1.3705298\ttotal: 11.6s\tremaining: 3m 12s\n34:\tlearn: 1.3619159\ttotal: 11.9s\tremaining: 3m 11s\n35:\tlearn: 1.3489001\ttotal: 12.2s\tremaining: 3m 11s\n36:\tlearn: 1.3375003\ttotal: 12.6s\tremaining: 3m 11s\n37:\tlearn: 1.3291297\ttotal: 12.9s\tremaining: 3m 10s\n38:\tlearn: 1.3223655\ttotal: 13.2s\tremaining: 3m 10s\n39:\tlearn: 1.3062885\ttotal: 13.6s\tremaining: 3m 10s\n40:\tlearn: 1.3013006\ttotal: 13.9s\tremaining: 3m 9s\n41:\tlearn: 1.2977082\ttotal: 14.2s\tremaining: 3m 9s\n42:\tlearn: 1.2832738\ttotal: 14.6s\tremaining: 3m 8s\n43:\tlearn: 1.2719826\ttotal: 14.9s\tremaining: 3m 8s\n44:\tlearn: 1.2608540\ttotal: 15.3s\tremaining: 3m 8s\n45:\tlearn: 1.2532845\ttotal: 15.6s\tremaining: 3m 7s\n46:\tlearn: 1.2472703\ttotal: 15.9s\tremaining: 3m 7s\n47:\tlearn: 1.2365172\ttotal: 16.3s\tremaining: 3m 7s\n48:\tlearn: 1.2255196\ttotal: 16.6s\tremaining: 3m 6s\n49:\tlearn: 1.2140657\ttotal: 16.9s\tremaining: 3m 6s\n50:\tlearn: 1.2080299\ttotal: 17.3s\tremaining: 3m 6s\n51:\tlearn: 1.2013312\ttotal: 17.6s\tremaining: 3m 5s\n52:\tlearn: 1.1951649\ttotal: 18s\tremaining: 3m 5s\n53:\tlearn: 1.1862779\ttotal: 18.3s\tremaining: 3m 4s\n54:\tlearn: 1.1826953\ttotal: 18.6s\tremaining: 3m 4s\n55:\tlearn: 1.1754396\ttotal: 19s\tremaining: 3m 4s\n56:\tlearn: 1.1714323\ttotal: 19.3s\tremaining: 3m 3s\n57:\tlearn: 1.1524369\ttotal: 19.6s\tremaining: 3m 3s\n58:\tlearn: 1.1469970\ttotal: 20s\tremaining: 3m 3s\n59:\tlearn: 1.1358850\ttotal: 20.3s\tremaining: 3m 2s\n60:\tlearn: 1.1287273\ttotal: 20.7s\tremaining: 3m 2s\n61:\tlearn: 1.1164266\ttotal: 21s\tremaining: 3m 2s\n62:\tlearn: 1.1084241\ttotal: 21.3s\tremaining: 3m 1s\n63:\tlearn: 1.1066319\ttotal: 21.7s\tremaining: 3m 1s\n64:\tlearn: 1.0962127\ttotal: 22s\tremaining: 3m 1s\n65:\tlearn: 1.0788009\ttotal: 22.3s\tremaining: 3m\n66:\tlearn: 1.0646386\ttotal: 22.7s\tremaining: 3m\n67:\tlearn: 1.0563443\ttotal: 23s\tremaining: 3m\n68:\tlearn: 1.0482812\ttotal: 23.4s\tremaining: 2m 59s\n69:\tlearn: 1.0441417\ttotal: 23.7s\tremaining: 2m 59s\n70:\tlearn: 1.0401487\ttotal: 24s\tremaining: 2m 58s\n71:\tlearn: 1.0341492\ttotal: 24.4s\tremaining: 2m 58s\n72:\tlearn: 1.0289630\ttotal: 24.7s\tremaining: 2m 58s\n73:\tlearn: 1.0222194\ttotal: 25s\tremaining: 2m 57s\n74:\tlearn: 1.0146405\ttotal: 25.4s\tremaining: 2m 57s\n75:\tlearn: 1.0039150\ttotal: 25.7s\tremaining: 2m 57s\n76:\tlearn: 0.9916350\ttotal: 26.1s\tremaining: 2m 57s\n77:\tlearn: 0.9868688\ttotal: 26.4s\tremaining: 2m 56s\n78:\tlearn: 0.9787645\ttotal: 26.7s\tremaining: 2m 56s\n79:\tlearn: 0.9736273\ttotal: 27.1s\tremaining: 2m 56s\n80:\tlearn: 0.9659879\ttotal: 27.4s\tremaining: 2m 55s\n81:\tlearn: 0.9594028\ttotal: 27.8s\tremaining: 2m 55s\n82:\tlearn: 0.9574293\ttotal: 28.1s\tremaining: 2m 54s\n83:\tlearn: 0.9491352\ttotal: 28.4s\tremaining: 2m 54s\n84:\tlearn: 0.9374232\ttotal: 28.8s\tremaining: 2m 54s\n85:\tlearn: 0.9269852\ttotal: 29.1s\tremaining: 2m 53s\n86:\tlearn: 0.9157010\ttotal: 29.5s\tremaining: 2m 53s\n87:\tlearn: 0.9067211\ttotal: 29.8s\tremaining: 2m 53s\n88:\tlearn: 0.8975771\ttotal: 30.2s\tremaining: 2m 53s\n89:\tlearn: 0.8960562\ttotal: 30.5s\tremaining: 2m 52s\n90:\tlearn: 0.8875019\ttotal: 30.8s\tremaining: 2m 52s\n91:\tlearn: 0.8831590\ttotal: 31.2s\tremaining: 2m 52s\n92:\tlearn: 0.8768656\ttotal: 31.5s\tremaining: 2m 51s\n93:\tlearn: 0.8669918\ttotal: 31.9s\tremaining: 2m 51s\n94:\tlearn: 0.8566527\ttotal: 32.2s\tremaining: 2m 51s\n95:\tlearn: 0.8424746\ttotal: 32.6s\tremaining: 2m 50s\n96:\tlearn: 0.8398237\ttotal: 32.9s\tremaining: 2m 50s\n97:\tlearn: 0.8343834\ttotal: 33.2s\tremaining: 2m 50s\n98:\tlearn: 0.8252850\ttotal: 33.6s\tremaining: 2m 49s\n99:\tlearn: 0.8190571\ttotal: 33.9s\tremaining: 2m 49s\n100:\tlearn: 0.8096555\ttotal: 34.3s\tremaining: 2m 49s\n101:\tlearn: 0.8047003\ttotal: 34.6s\tremaining: 2m 48s\n102:\tlearn: 0.7963887\ttotal: 34.9s\tremaining: 2m 48s\n103:\tlearn: 0.7943405\ttotal: 35.3s\tremaining: 2m 48s\n104:\tlearn: 0.7883786\ttotal: 35.6s\tremaining: 2m 47s\n105:\tlearn: 0.7835959\ttotal: 36s\tremaining: 2m 47s\n106:\tlearn: 0.7745637\ttotal: 36.3s\tremaining: 2m 47s\n107:\tlearn: 0.7694140\ttotal: 36.6s\tremaining: 2m 46s\n108:\tlearn: 0.7630332\ttotal: 37s\tremaining: 2m 46s\n109:\tlearn: 0.7589820\ttotal: 37.3s\tremaining: 2m 46s\n110:\tlearn: 0.7448109\ttotal: 37.7s\tremaining: 2m 45s\n111:\tlearn: 0.7433010\ttotal: 38s\tremaining: 2m 45s\n112:\tlearn: 0.7371488\ttotal: 38.4s\tremaining: 2m 45s\n113:\tlearn: 0.7332356\ttotal: 38.7s\tremaining: 2m 44s\n114:\tlearn: 0.7321385\ttotal: 39s\tremaining: 2m 44s\n115:\tlearn: 0.7293441\ttotal: 39.4s\tremaining: 2m 44s\n116:\tlearn: 0.7246143\ttotal: 39.7s\tremaining: 2m 43s\n117:\tlearn: 0.7148138\ttotal: 40s\tremaining: 2m 43s\n118:\tlearn: 0.7129876\ttotal: 40.4s\tremaining: 2m 43s\n119:\tlearn: 0.7105777\ttotal: 40.7s\tremaining: 2m 42s\n120:\tlearn: 0.7063274\ttotal: 41.1s\tremaining: 2m 42s\n121:\tlearn: 0.6992862\ttotal: 41.4s\tremaining: 2m 42s\n122:\tlearn: 0.6950459\ttotal: 41.7s\tremaining: 2m 41s\n123:\tlearn: 0.6903368\ttotal: 42.1s\tremaining: 2m 41s\n124:\tlearn: 0.6879188\ttotal: 42.4s\tremaining: 2m 41s\n125:\tlearn: 0.6866041\ttotal: 42.8s\tremaining: 2m 40s\n126:\tlearn: 0.6836689\ttotal: 43.1s\tremaining: 2m 40s\n127:\tlearn: 0.6806606\ttotal: 43.4s\tremaining: 2m 40s\n128:\tlearn: 0.6755790\ttotal: 43.8s\tremaining: 2m 39s\n129:\tlearn: 0.6723235\ttotal: 44.1s\tremaining: 2m 39s\n130:\tlearn: 0.6673458\ttotal: 44.5s\tremaining: 2m 39s\n131:\tlearn: 0.6628059\ttotal: 44.8s\tremaining: 2m 38s\n132:\tlearn: 0.6598427\ttotal: 45.1s\tremaining: 2m 38s\n133:\tlearn: 0.6552084\ttotal: 45.5s\tremaining: 2m 38s\n134:\tlearn: 0.6499191\ttotal: 45.9s\tremaining: 2m 37s\n135:\tlearn: 0.6463071\ttotal: 46.2s\tremaining: 2m 37s\n136:\tlearn: 0.6410194\ttotal: 46.6s\tremaining: 2m 37s\n137:\tlearn: 0.6369666\ttotal: 46.9s\tremaining: 2m 37s\n138:\tlearn: 0.6295432\ttotal: 47.3s\tremaining: 2m 36s\n139:\tlearn: 0.6217230\ttotal: 47.6s\tremaining: 2m 36s\n140:\tlearn: 0.6129611\ttotal: 48s\tremaining: 2m 36s\n141:\tlearn: 0.6099699\ttotal: 48.3s\tremaining: 2m 35s\n142:\tlearn: 0.6089147\ttotal: 48.6s\tremaining: 2m 35s\n143:\tlearn: 0.6039385\ttotal: 49s\tremaining: 2m 35s\n144:\tlearn: 0.5993435\ttotal: 49.3s\tremaining: 2m 34s\n145:\tlearn: 0.5963038\ttotal: 49.7s\tremaining: 2m 34s\n146:\tlearn: 0.5919626\ttotal: 50s\tremaining: 2m 34s\n147:\tlearn: 0.5884452\ttotal: 50.3s\tremaining: 2m 33s\n148:\tlearn: 0.5856232\ttotal: 50.7s\tremaining: 2m 33s\n149:\tlearn: 0.5842705\ttotal: 51s\tremaining: 2m 33s\n150:\tlearn: 0.5802592\ttotal: 51.4s\tremaining: 2m 32s\n151:\tlearn: 0.5783975\ttotal: 51.7s\tremaining: 2m 32s\n152:\tlearn: 0.5767147\ttotal: 52s\tremaining: 2m 32s\n153:\tlearn: 0.5718783\ttotal: 52.4s\tremaining: 2m 31s\n154:\tlearn: 0.5699622\ttotal: 52.7s\tremaining: 2m 31s\n155:\tlearn: 0.5679797\ttotal: 53.1s\tremaining: 2m 31s\n156:\tlearn: 0.5662202\ttotal: 53.4s\tremaining: 2m 30s\n157:\tlearn: 0.5620849\ttotal: 53.7s\tremaining: 2m 30s\n158:\tlearn: 0.5585225\ttotal: 54.1s\tremaining: 2m 30s\n159:\tlearn: 0.5548000\ttotal: 54.4s\tremaining: 2m 29s\n160:\tlearn: 0.5527153\ttotal: 54.8s\tremaining: 2m 29s\n161:\tlearn: 0.5478965\ttotal: 55.1s\tremaining: 2m 29s\n162:\tlearn: 0.5460056\ttotal: 55.5s\tremaining: 2m 28s\n163:\tlearn: 0.5452113\ttotal: 55.8s\tremaining: 2m 28s\n164:\tlearn: 0.5376203\ttotal: 56.1s\tremaining: 2m 28s\n165:\tlearn: 0.5356966\ttotal: 56.5s\tremaining: 2m 27s\n166:\tlearn: 0.5334510\ttotal: 56.8s\tremaining: 2m 27s\n167:\tlearn: 0.5248284\ttotal: 57.2s\tremaining: 2m 27s\n168:\tlearn: 0.5241990\ttotal: 57.5s\tremaining: 2m 26s\n169:\tlearn: 0.5235840\ttotal: 57.9s\tremaining: 2m 26s\n170:\tlearn: 0.5229048\ttotal: 58.2s\tremaining: 2m 25s\n171:\tlearn: 0.5203510\ttotal: 58.5s\tremaining: 2m 25s\n172:\tlearn: 0.5187068\ttotal: 58.9s\tremaining: 2m 25s\n173:\tlearn: 0.5162021\ttotal: 59.2s\tremaining: 2m 24s\n174:\tlearn: 0.5120596\ttotal: 59.6s\tremaining: 2m 24s\n175:\tlearn: 0.5104085\ttotal: 59.9s\tremaining: 2m 24s\n176:\tlearn: 0.5078386\ttotal: 1m\tremaining: 2m 23s\n177:\tlearn: 0.5059437\ttotal: 1m\tremaining: 2m 23s\n178:\tlearn: 0.5043516\ttotal: 1m\tremaining: 2m 23s\n179:\tlearn: 0.5013341\ttotal: 1m 1s\tremaining: 2m 22s\n180:\tlearn: 0.4987762\ttotal: 1m 1s\tremaining: 2m 22s\n181:\tlearn: 0.4966286\ttotal: 1m 1s\tremaining: 2m 22s\n182:\tlearn: 0.4957007\ttotal: 1m 2s\tremaining: 2m 21s\n183:\tlearn: 0.4936858\ttotal: 1m 2s\tremaining: 2m 21s\n184:\tlearn: 0.4912653\ttotal: 1m 2s\tremaining: 2m 21s\n185:\tlearn: 0.4896443\ttotal: 1m 3s\tremaining: 2m 20s\n186:\tlearn: 0.4887678\ttotal: 1m 3s\tremaining: 2m 20s\n187:\tlearn: 0.4855342\ttotal: 1m 3s\tremaining: 2m 20s\n188:\tlearn: 0.4812512\ttotal: 1m 4s\tremaining: 2m 19s\n189:\tlearn: 0.4804960\ttotal: 1m 4s\tremaining: 2m 19s\n190:\tlearn: 0.4785455\ttotal: 1m 4s\tremaining: 2m 19s\n191:\tlearn: 0.4774644\ttotal: 1m 5s\tremaining: 2m 18s\n192:\tlearn: 0.4754321\ttotal: 1m 5s\tremaining: 2m 18s\n193:\tlearn: 0.4748009\ttotal: 1m 6s\tremaining: 2m 18s\n194:\tlearn: 0.4746450\ttotal: 1m 6s\tremaining: 2m 17s\n195:\tlearn: 0.4733800\ttotal: 1m 6s\tremaining: 2m 17s\n196:\tlearn: 0.4704304\ttotal: 1m 7s\tremaining: 2m 17s\n197:\tlearn: 0.4695862\ttotal: 1m 7s\tremaining: 2m 16s\n198:\tlearn: 0.4684702\ttotal: 1m 7s\tremaining: 2m 16s\n199:\tlearn: 0.4656462\ttotal: 1m 8s\tremaining: 2m 16s\n200:\tlearn: 0.4642516\ttotal: 1m 8s\tremaining: 2m 15s\n201:\tlearn: 0.4630007\ttotal: 1m 8s\tremaining: 2m 15s\n202:\tlearn: 0.4616799\ttotal: 1m 9s\tremaining: 2m 15s\n203:\tlearn: 0.4590109\ttotal: 1m 9s\tremaining: 2m 14s\n204:\tlearn: 0.4573225\ttotal: 1m 9s\tremaining: 2m 14s\n205:\tlearn: 0.4565689\ttotal: 1m 10s\tremaining: 2m 14s\n206:\tlearn: 0.4536339\ttotal: 1m 10s\tremaining: 2m 13s\n207:\tlearn: 0.4488799\ttotal: 1m 10s\tremaining: 2m 13s\n208:\tlearn: 0.4465931\ttotal: 1m 11s\tremaining: 2m 13s\n209:\tlearn: 0.4447606\ttotal: 1m 11s\tremaining: 2m 12s\n210:\tlearn: 0.4443300\ttotal: 1m 11s\tremaining: 2m 12s\n211:\tlearn: 0.4438229\ttotal: 1m 12s\tremaining: 2m 12s\n212:\tlearn: 0.4421538\ttotal: 1m 12s\tremaining: 2m 11s\n213:\tlearn: 0.4382856\ttotal: 1m 12s\tremaining: 2m 11s\n214:\tlearn: 0.4356760\ttotal: 1m 13s\tremaining: 2m 11s\n215:\tlearn: 0.4342792\ttotal: 1m 13s\tremaining: 2m 10s\n216:\tlearn: 0.4331097\ttotal: 1m 13s\tremaining: 2m 10s\n217:\tlearn: 0.4322300\ttotal: 1m 14s\tremaining: 2m 10s\n218:\tlearn: 0.4300470\ttotal: 1m 14s\tremaining: 2m 9s\n219:\tlearn: 0.4293619\ttotal: 1m 14s\tremaining: 2m 9s\n220:\tlearn: 0.4285090\ttotal: 1m 15s\tremaining: 2m 9s\n221:\tlearn: 0.4276532\ttotal: 1m 15s\tremaining: 2m 8s\n222:\tlearn: 0.4233540\ttotal: 1m 15s\tremaining: 2m 8s\n223:\tlearn: 0.4230111\ttotal: 1m 16s\tremaining: 2m 8s\n224:\tlearn: 0.4223735\ttotal: 1m 16s\tremaining: 2m 7s\n225:\tlearn: 0.4209785\ttotal: 1m 16s\tremaining: 2m 7s\n226:\tlearn: 0.4184554\ttotal: 1m 17s\tremaining: 2m 7s\n227:\tlearn: 0.4170765\ttotal: 1m 17s\tremaining: 2m 6s\n228:\tlearn: 0.4165969\ttotal: 1m 17s\tremaining: 2m 6s\n229:\tlearn: 0.4145506\ttotal: 1m 18s\tremaining: 2m 6s\n230:\tlearn: 0.4118964\ttotal: 1m 18s\tremaining: 2m 5s\n231:\tlearn: 0.4099515\ttotal: 1m 19s\tremaining: 2m 5s\n232:\tlearn: 0.4082375\ttotal: 1m 19s\tremaining: 2m 5s\n233:\tlearn: 0.4076987\ttotal: 1m 19s\tremaining: 2m 4s\n234:\tlearn: 0.4059311\ttotal: 1m 20s\tremaining: 2m 4s\n235:\tlearn: 0.4054953\ttotal: 1m 20s\tremaining: 2m 3s\n236:\tlearn: 0.4032960\ttotal: 1m 20s\tremaining: 2m 3s\n237:\tlearn: 0.4023374\ttotal: 1m 21s\tremaining: 2m 3s\n238:\tlearn: 0.4019921\ttotal: 1m 21s\tremaining: 2m 2s\n239:\tlearn: 0.4015808\ttotal: 1m 21s\tremaining: 2m 2s\n240:\tlearn: 0.3996424\ttotal: 1m 22s\tremaining: 2m 2s\n241:\tlearn: 0.3990136\ttotal: 1m 22s\tremaining: 2m 1s\n242:\tlearn: 0.3976601\ttotal: 1m 22s\tremaining: 2m 1s\n243:\tlearn: 0.3969886\ttotal: 1m 23s\tremaining: 2m 1s\n244:\tlearn: 0.3959313\ttotal: 1m 23s\tremaining: 2m\n245:\tlearn: 0.3932711\ttotal: 1m 23s\tremaining: 2m\n246:\tlearn: 0.3931317\ttotal: 1m 24s\tremaining: 2m\n247:\tlearn: 0.3920737\ttotal: 1m 24s\tremaining: 1m 59s\n248:\tlearn: 0.3883568\ttotal: 1m 24s\tremaining: 1m 59s\n249:\tlearn: 0.3871624\ttotal: 1m 25s\tremaining: 1m 59s\n250:\tlearn: 0.3865658\ttotal: 1m 25s\tremaining: 1m 58s\n251:\tlearn: 0.3858821\ttotal: 1m 25s\tremaining: 1m 58s\n252:\tlearn: 0.3848413\ttotal: 1m 26s\tremaining: 1m 58s\n253:\tlearn: 0.3841962\ttotal: 1m 26s\tremaining: 1m 57s\n254:\tlearn: 0.3838649\ttotal: 1m 26s\tremaining: 1m 57s\n255:\tlearn: 0.3823770\ttotal: 1m 27s\tremaining: 1m 57s\n256:\tlearn: 0.3779269\ttotal: 1m 27s\tremaining: 1m 56s\n257:\tlearn: 0.3771263\ttotal: 1m 27s\tremaining: 1m 56s\n258:\tlearn: 0.3768350\ttotal: 1m 28s\tremaining: 1m 56s\n259:\tlearn: 0.3765855\ttotal: 1m 28s\tremaining: 1m 55s\n260:\tlearn: 0.3760045\ttotal: 1m 28s\tremaining: 1m 55s\n261:\tlearn: 0.3755442\ttotal: 1m 29s\tremaining: 1m 55s\n262:\tlearn: 0.3751012\ttotal: 1m 29s\tremaining: 1m 54s\n263:\tlearn: 0.3749362\ttotal: 1m 29s\tremaining: 1m 54s\n264:\tlearn: 0.3745404\ttotal: 1m 30s\tremaining: 1m 54s\n265:\tlearn: 0.3730620\ttotal: 1m 30s\tremaining: 1m 53s\n266:\tlearn: 0.3729957\ttotal: 1m 30s\tremaining: 1m 53s\n267:\tlearn: 0.3726195\ttotal: 1m 31s\tremaining: 1m 53s\n268:\tlearn: 0.3716921\ttotal: 1m 31s\tremaining: 1m 52s\n269:\tlearn: 0.3707728\ttotal: 1m 31s\tremaining: 1m 52s\n270:\tlearn: 0.3705367\ttotal: 1m 32s\tremaining: 1m 52s\n271:\tlearn: 0.3701789\ttotal: 1m 32s\tremaining: 1m 51s\n272:\tlearn: 0.3698948\ttotal: 1m 32s\tremaining: 1m 51s\n273:\tlearn: 0.3692342\ttotal: 1m 33s\tremaining: 1m 51s\n274:\tlearn: 0.3665455\ttotal: 1m 33s\tremaining: 1m 50s\n275:\tlearn: 0.3654920\ttotal: 1m 33s\tremaining: 1m 50s\n276:\tlearn: 0.3647928\ttotal: 1m 34s\tremaining: 1m 50s\n277:\tlearn: 0.3636337\ttotal: 1m 34s\tremaining: 1m 49s\n278:\tlearn: 0.3625008\ttotal: 1m 35s\tremaining: 1m 49s\n279:\tlearn: 0.3608557\ttotal: 1m 35s\tremaining: 1m 49s\n280:\tlearn: 0.3601839\ttotal: 1m 35s\tremaining: 1m 48s\n281:\tlearn: 0.3589356\ttotal: 1m 36s\tremaining: 1m 48s\n282:\tlearn: 0.3568701\ttotal: 1m 36s\tremaining: 1m 48s\n283:\tlearn: 0.3543915\ttotal: 1m 36s\tremaining: 1m 47s\n284:\tlearn: 0.3537973\ttotal: 1m 37s\tremaining: 1m 47s\n285:\tlearn: 0.3531961\ttotal: 1m 37s\tremaining: 1m 46s\n286:\tlearn: 0.3517735\ttotal: 1m 37s\tremaining: 1m 46s\n287:\tlearn: 0.3509297\ttotal: 1m 38s\tremaining: 1m 46s\n288:\tlearn: 0.3502900\ttotal: 1m 38s\tremaining: 1m 45s\n289:\tlearn: 0.3486287\ttotal: 1m 38s\tremaining: 1m 45s\n290:\tlearn: 0.3475973\ttotal: 1m 39s\tremaining: 1m 45s\n291:\tlearn: 0.3467412\ttotal: 1m 39s\tremaining: 1m 44s\n292:\tlearn: 0.3456607\ttotal: 1m 39s\tremaining: 1m 44s\n293:\tlearn: 0.3449609\ttotal: 1m 40s\tremaining: 1m 44s\n294:\tlearn: 0.3426316\ttotal: 1m 40s\tremaining: 1m 43s\n295:\tlearn: 0.3419392\ttotal: 1m 40s\tremaining: 1m 43s\n296:\tlearn: 0.3416119\ttotal: 1m 41s\tremaining: 1m 43s\n297:\tlearn: 0.3399319\ttotal: 1m 41s\tremaining: 1m 42s\n298:\tlearn: 0.3394529\ttotal: 1m 41s\tremaining: 1m 42s\n299:\tlearn: 0.3392335\ttotal: 1m 42s\tremaining: 1m 42s\n300:\tlearn: 0.3387007\ttotal: 1m 42s\tremaining: 1m 41s\n301:\tlearn: 0.3383601\ttotal: 1m 42s\tremaining: 1m 41s\n302:\tlearn: 0.3368012\ttotal: 1m 43s\tremaining: 1m 41s\n303:\tlearn: 0.3358030\ttotal: 1m 43s\tremaining: 1m 40s\n304:\tlearn: 0.3356210\ttotal: 1m 43s\tremaining: 1m 40s\n305:\tlearn: 0.3354756\ttotal: 1m 44s\tremaining: 1m 40s\n306:\tlearn: 0.3353178\ttotal: 1m 44s\tremaining: 1m 39s\n307:\tlearn: 0.3331745\ttotal: 1m 44s\tremaining: 1m 39s\n308:\tlearn: 0.3328256\ttotal: 1m 45s\tremaining: 1m 39s\n309:\tlearn: 0.3324151\ttotal: 1m 45s\tremaining: 1m 38s\n310:\tlearn: 0.3322904\ttotal: 1m 45s\tremaining: 1m 38s\n311:\tlearn: 0.3320246\ttotal: 1m 46s\tremaining: 1m 38s\n312:\tlearn: 0.3318612\ttotal: 1m 46s\tremaining: 1m 37s\n313:\tlearn: 0.3316200\ttotal: 1m 46s\tremaining: 1m 37s\n314:\tlearn: 0.3310065\ttotal: 1m 47s\tremaining: 1m 37s\n315:\tlearn: 0.3302743\ttotal: 1m 47s\tremaining: 1m 36s\n316:\tlearn: 0.3300535\ttotal: 1m 47s\tremaining: 1m 36s\n317:\tlearn: 0.3296312\ttotal: 1m 48s\tremaining: 1m 36s\n318:\tlearn: 0.3294384\ttotal: 1m 48s\tremaining: 1m 35s\n319:\tlearn: 0.3291296\ttotal: 1m 48s\tremaining: 1m 35s\n320:\tlearn: 0.3289361\ttotal: 1m 49s\tremaining: 1m 35s\n321:\tlearn: 0.3284562\ttotal: 1m 49s\tremaining: 1m 34s\n322:\tlearn: 0.3279645\ttotal: 1m 50s\tremaining: 1m 34s\n323:\tlearn: 0.3275912\ttotal: 1m 50s\tremaining: 1m 33s\n324:\tlearn: 0.3273903\ttotal: 1m 50s\tremaining: 1m 33s\n325:\tlearn: 0.3263357\ttotal: 1m 51s\tremaining: 1m 33s\n326:\tlearn: 0.3260856\ttotal: 1m 51s\tremaining: 1m 32s\n327:\tlearn: 0.3258365\ttotal: 1m 51s\tremaining: 1m 32s\n328:\tlearn: 0.3255080\ttotal: 1m 52s\tremaining: 1m 32s\n329:\tlearn: 0.3253222\ttotal: 1m 52s\tremaining: 1m 31s\n330:\tlearn: 0.3251919\ttotal: 1m 52s\tremaining: 1m 31s\n331:\tlearn: 0.3239415\ttotal: 1m 53s\tremaining: 1m 31s\n332:\tlearn: 0.3235286\ttotal: 1m 53s\tremaining: 1m 30s\n333:\tlearn: 0.3229405\ttotal: 1m 53s\tremaining: 1m 30s\n334:\tlearn: 0.3223730\ttotal: 1m 54s\tremaining: 1m 30s\n335:\tlearn: 0.3221501\ttotal: 1m 54s\tremaining: 1m 29s\n336:\tlearn: 0.3216277\ttotal: 1m 54s\tremaining: 1m 29s\n337:\tlearn: 0.3214997\ttotal: 1m 55s\tremaining: 1m 29s\n338:\tlearn: 0.3214141\ttotal: 1m 55s\tremaining: 1m 28s\n339:\tlearn: 0.3203385\ttotal: 1m 55s\tremaining: 1m 28s\n340:\tlearn: 0.3200526\ttotal: 1m 56s\tremaining: 1m 28s\n341:\tlearn: 0.3199849\ttotal: 1m 56s\tremaining: 1m 27s\n342:\tlearn: 0.3193140\ttotal: 1m 56s\tremaining: 1m 27s\n343:\tlearn: 0.3185074\ttotal: 1m 57s\tremaining: 1m 27s\n344:\tlearn: 0.3181795\ttotal: 1m 57s\tremaining: 1m 26s\n345:\tlearn: 0.3168663\ttotal: 1m 57s\tremaining: 1m 26s\n346:\tlearn: 0.3166223\ttotal: 1m 58s\tremaining: 1m 26s\n347:\tlearn: 0.3162275\ttotal: 1m 58s\tremaining: 1m 25s\n348:\tlearn: 0.3153039\ttotal: 1m 58s\tremaining: 1m 25s\n349:\tlearn: 0.3151156\ttotal: 1m 59s\tremaining: 1m 25s\n350:\tlearn: 0.3144512\ttotal: 1m 59s\tremaining: 1m 24s\n351:\tlearn: 0.3140223\ttotal: 1m 59s\tremaining: 1m 24s\n352:\tlearn: 0.3138731\ttotal: 2m\tremaining: 1m 24s\n353:\tlearn: 0.3134761\ttotal: 2m\tremaining: 1m 23s\n354:\tlearn: 0.3119267\ttotal: 2m\tremaining: 1m 23s\n355:\tlearn: 0.3118118\ttotal: 2m 1s\tremaining: 1m 23s\n356:\tlearn: 0.3116599\ttotal: 2m 1s\tremaining: 1m 22s\n357:\tlearn: 0.3107591\ttotal: 2m 1s\tremaining: 1m 22s\n358:\tlearn: 0.3099524\ttotal: 2m 2s\tremaining: 1m 22s\n359:\tlearn: 0.3097797\ttotal: 2m 2s\tremaining: 1m 21s\n360:\tlearn: 0.3094187\ttotal: 2m 2s\tremaining: 1m 21s\n361:\tlearn: 0.3092543\ttotal: 2m 3s\tremaining: 1m 21s\n362:\tlearn: 0.3088113\ttotal: 2m 3s\tremaining: 1m 20s\n363:\tlearn: 0.3076982\ttotal: 2m 3s\tremaining: 1m 20s\n364:\tlearn: 0.3067353\ttotal: 2m 4s\tremaining: 1m 19s\n365:\tlearn: 0.3062831\ttotal: 2m 4s\tremaining: 1m 19s\n366:\tlearn: 0.3060633\ttotal: 2m 4s\tremaining: 1m 19s\n367:\tlearn: 0.3057617\ttotal: 2m 5s\tremaining: 1m 18s\n368:\tlearn: 0.3043506\ttotal: 2m 5s\tremaining: 1m 18s\n369:\tlearn: 0.3042140\ttotal: 2m 5s\tremaining: 1m 18s\n370:\tlearn: 0.3038894\ttotal: 2m 6s\tremaining: 1m 17s\n371:\tlearn: 0.3037813\ttotal: 2m 6s\tremaining: 1m 17s\n372:\tlearn: 0.3036820\ttotal: 2m 6s\tremaining: 1m 17s\n373:\tlearn: 0.3033992\ttotal: 2m 7s\tremaining: 1m 16s\n374:\tlearn: 0.3030582\ttotal: 2m 7s\tremaining: 1m 16s\n375:\tlearn: 0.3028575\ttotal: 2m 7s\tremaining: 1m 16s\n376:\tlearn: 0.3018699\ttotal: 2m 8s\tremaining: 1m 15s\n377:\tlearn: 0.3014871\ttotal: 2m 8s\tremaining: 1m 15s\n378:\tlearn: 0.3008763\ttotal: 2m 8s\tremaining: 1m 15s\n379:\tlearn: 0.2992644\ttotal: 2m 9s\tremaining: 1m 14s\n380:\tlearn: 0.2984934\ttotal: 2m 9s\tremaining: 1m 14s\n381:\tlearn: 0.2984251\ttotal: 2m 10s\tremaining: 1m 14s\n382:\tlearn: 0.2979603\ttotal: 2m 10s\tremaining: 1m 13s\n383:\tlearn: 0.2969437\ttotal: 2m 10s\tremaining: 1m 13s\n384:\tlearn: 0.2967763\ttotal: 2m 11s\tremaining: 1m 13s\n385:\tlearn: 0.2964481\ttotal: 2m 11s\tremaining: 1m 12s\n386:\tlearn: 0.2962170\ttotal: 2m 11s\tremaining: 1m 12s\n387:\tlearn: 0.2958443\ttotal: 2m 12s\tremaining: 1m 12s\n388:\tlearn: 0.2956557\ttotal: 2m 12s\tremaining: 1m 11s\n389:\tlearn: 0.2951517\ttotal: 2m 12s\tremaining: 1m 11s\n390:\tlearn: 0.2950385\ttotal: 2m 13s\tremaining: 1m 11s\n391:\tlearn: 0.2949785\ttotal: 2m 13s\tremaining: 1m 10s\n392:\tlearn: 0.2948569\ttotal: 2m 13s\tremaining: 1m 10s\n393:\tlearn: 0.2947359\ttotal: 2m 14s\tremaining: 1m 10s\n394:\tlearn: 0.2945526\ttotal: 2m 14s\tremaining: 1m 9s\n395:\tlearn: 0.2943329\ttotal: 2m 14s\tremaining: 1m 9s\n396:\tlearn: 0.2938091\ttotal: 2m 15s\tremaining: 1m 9s\n397:\tlearn: 0.2936471\ttotal: 2m 15s\tremaining: 1m 8s\n398:\tlearn: 0.2934174\ttotal: 2m 15s\tremaining: 1m 8s\n399:\tlearn: 0.2930571\ttotal: 2m 16s\tremaining: 1m 8s\n400:\tlearn: 0.2922468\ttotal: 2m 16s\tremaining: 1m 7s\n401:\tlearn: 0.2918107\ttotal: 2m 16s\tremaining: 1m 7s\n402:\tlearn: 0.2912985\ttotal: 2m 17s\tremaining: 1m 7s\n403:\tlearn: 0.2909467\ttotal: 2m 17s\tremaining: 1m 6s\n404:\tlearn: 0.2907357\ttotal: 2m 17s\tremaining: 1m 6s\n405:\tlearn: 0.2906944\ttotal: 2m 18s\tremaining: 1m 5s\n406:\tlearn: 0.2905360\ttotal: 2m 18s\tremaining: 1m 5s\n407:\tlearn: 0.2901643\ttotal: 2m 18s\tremaining: 1m 5s\n408:\tlearn: 0.2901165\ttotal: 2m 19s\tremaining: 1m 4s\n409:\tlearn: 0.2898255\ttotal: 2m 19s\tremaining: 1m 4s\n410:\tlearn: 0.2895169\ttotal: 2m 19s\tremaining: 1m 4s\n411:\tlearn: 0.2891093\ttotal: 2m 20s\tremaining: 1m 3s\n412:\tlearn: 0.2889489\ttotal: 2m 20s\tremaining: 1m 3s\n413:\tlearn: 0.2881700\ttotal: 2m 20s\tremaining: 1m 3s\n414:\tlearn: 0.2877573\ttotal: 2m 21s\tremaining: 1m 2s\n415:\tlearn: 0.2875353\ttotal: 2m 21s\tremaining: 1m 2s\n416:\tlearn: 0.2867551\ttotal: 2m 21s\tremaining: 1m 2s\n417:\tlearn: 0.2866440\ttotal: 2m 22s\tremaining: 1m 1s\n418:\tlearn: 0.2847312\ttotal: 2m 22s\tremaining: 1m 1s\n419:\tlearn: 0.2846935\ttotal: 2m 22s\tremaining: 1m 1s\n420:\tlearn: 0.2845450\ttotal: 2m 23s\tremaining: 1m\n421:\tlearn: 0.2843183\ttotal: 2m 23s\tremaining: 1m\n422:\tlearn: 0.2842533\ttotal: 2m 23s\tremaining: 1m\n423:\tlearn: 0.2837051\ttotal: 2m 24s\tremaining: 59.9s\n424:\tlearn: 0.2829785\ttotal: 2m 24s\tremaining: 59.5s\n425:\tlearn: 0.2824022\ttotal: 2m 24s\tremaining: 59.2s\n426:\tlearn: 0.2820403\ttotal: 2m 25s\tremaining: 58.9s\n427:\tlearn: 0.2816902\ttotal: 2m 25s\tremaining: 58.5s\n428:\tlearn: 0.2807158\ttotal: 2m 25s\tremaining: 58.2s\n429:\tlearn: 0.2800801\ttotal: 2m 26s\tremaining: 57.9s\n430:\tlearn: 0.2791751\ttotal: 2m 26s\tremaining: 57.5s\n431:\tlearn: 0.2789072\ttotal: 2m 27s\tremaining: 57.2s\n432:\tlearn: 0.2781028\ttotal: 2m 27s\tremaining: 56.8s\n433:\tlearn: 0.2779608\ttotal: 2m 27s\tremaining: 56.5s\n434:\tlearn: 0.2772086\ttotal: 2m 28s\tremaining: 56.2s\n435:\tlearn: 0.2768465\ttotal: 2m 28s\tremaining: 55.8s\n436:\tlearn: 0.2763942\ttotal: 2m 28s\tremaining: 55.5s\n437:\tlearn: 0.2760927\ttotal: 2m 29s\tremaining: 55.1s\n438:\tlearn: 0.2758138\ttotal: 2m 29s\tremaining: 54.8s\n439:\tlearn: 0.2756150\ttotal: 2m 29s\tremaining: 54.5s\n440:\tlearn: 0.2748688\ttotal: 2m 30s\tremaining: 54.1s\n441:\tlearn: 0.2744711\ttotal: 2m 30s\tremaining: 53.8s\n442:\tlearn: 0.2742213\ttotal: 2m 30s\tremaining: 53.4s\n443:\tlearn: 0.2740854\ttotal: 2m 31s\tremaining: 53.1s\n444:\tlearn: 0.2739306\ttotal: 2m 31s\tremaining: 52.8s\n445:\tlearn: 0.2737307\ttotal: 2m 31s\tremaining: 52.4s\n446:\tlearn: 0.2736687\ttotal: 2m 32s\tremaining: 52.1s\n447:\tlearn: 0.2736171\ttotal: 2m 32s\tremaining: 51.7s\n448:\tlearn: 0.2735208\ttotal: 2m 32s\tremaining: 51.4s\n449:\tlearn: 0.2721246\ttotal: 2m 33s\tremaining: 51s\n450:\tlearn: 0.2706901\ttotal: 2m 33s\tremaining: 50.7s\n451:\tlearn: 0.2706246\ttotal: 2m 33s\tremaining: 50.4s\n452:\tlearn: 0.2705224\ttotal: 2m 34s\tremaining: 50s\n453:\tlearn: 0.2704541\ttotal: 2m 34s\tremaining: 49.7s\n454:\tlearn: 0.2703909\ttotal: 2m 34s\tremaining: 49.3s\n455:\tlearn: 0.2703169\ttotal: 2m 35s\tremaining: 49s\n456:\tlearn: 0.2699808\ttotal: 2m 35s\tremaining: 48.7s\n457:\tlearn: 0.2696901\ttotal: 2m 35s\tremaining: 48.3s\n458:\tlearn: 0.2696543\ttotal: 2m 36s\tremaining: 48s\n459:\tlearn: 0.2693301\ttotal: 2m 36s\tremaining: 47.6s\n460:\tlearn: 0.2690193\ttotal: 2m 36s\tremaining: 47.3s\n461:\tlearn: 0.2688725\ttotal: 2m 37s\tremaining: 47s\n462:\tlearn: 0.2686929\ttotal: 2m 37s\tremaining: 46.6s\n463:\tlearn: 0.2684803\ttotal: 2m 37s\tremaining: 46.3s\n464:\tlearn: 0.2680791\ttotal: 2m 38s\tremaining: 45.9s\n465:\tlearn: 0.2679463\ttotal: 2m 38s\tremaining: 45.6s\n466:\tlearn: 0.2676751\ttotal: 2m 38s\tremaining: 45.3s\n467:\tlearn: 0.2674720\ttotal: 2m 39s\tremaining: 44.9s\n468:\tlearn: 0.2674214\ttotal: 2m 39s\tremaining: 44.6s\n469:\tlearn: 0.2661499\ttotal: 2m 39s\tremaining: 44.2s\n470:\tlearn: 0.2660690\ttotal: 2m 40s\tremaining: 43.9s\n471:\tlearn: 0.2653791\ttotal: 2m 40s\tremaining: 43.6s\n472:\tlearn: 0.2651490\ttotal: 2m 40s\tremaining: 43.2s\n473:\tlearn: 0.2647158\ttotal: 2m 41s\tremaining: 42.9s\n474:\tlearn: 0.2642457\ttotal: 2m 41s\tremaining: 42.5s\n475:\tlearn: 0.2640120\ttotal: 2m 42s\tremaining: 42.2s\n476:\tlearn: 0.2633742\ttotal: 2m 42s\tremaining: 41.9s\n477:\tlearn: 0.2632776\ttotal: 2m 42s\tremaining: 41.5s\n478:\tlearn: 0.2629225\ttotal: 2m 43s\tremaining: 41.2s\n479:\tlearn: 0.2628754\ttotal: 2m 43s\tremaining: 40.8s\n480:\tlearn: 0.2623330\ttotal: 2m 43s\tremaining: 40.5s\n481:\tlearn: 0.2619852\ttotal: 2m 44s\tremaining: 40.2s\n482:\tlearn: 0.2616249\ttotal: 2m 44s\tremaining: 39.8s\n483:\tlearn: 0.2612004\ttotal: 2m 44s\tremaining: 39.5s\n484:\tlearn: 0.2610609\ttotal: 2m 45s\tremaining: 39.1s\n485:\tlearn: 0.2606178\ttotal: 2m 45s\tremaining: 38.8s\n486:\tlearn: 0.2605875\ttotal: 2m 45s\tremaining: 38.5s\n487:\tlearn: 0.2604535\ttotal: 2m 46s\tremaining: 38.1s\n488:\tlearn: 0.2603746\ttotal: 2m 46s\tremaining: 37.8s\n489:\tlearn: 0.2602998\ttotal: 2m 46s\tremaining: 37.4s\n490:\tlearn: 0.2601254\ttotal: 2m 47s\tremaining: 37.1s\n491:\tlearn: 0.2589842\ttotal: 2m 47s\tremaining: 36.8s\n492:\tlearn: 0.2581834\ttotal: 2m 47s\tremaining: 36.4s\n493:\tlearn: 0.2580680\ttotal: 2m 48s\tremaining: 36.1s\n494:\tlearn: 0.2577100\ttotal: 2m 48s\tremaining: 35.7s\n495:\tlearn: 0.2572241\ttotal: 2m 48s\tremaining: 35.4s\n496:\tlearn: 0.2570774\ttotal: 2m 49s\tremaining: 35.1s\n497:\tlearn: 0.2565714\ttotal: 2m 49s\tremaining: 34.7s\n498:\tlearn: 0.2564881\ttotal: 2m 49s\tremaining: 34.4s\n499:\tlearn: 0.2564624\ttotal: 2m 50s\tremaining: 34s\n500:\tlearn: 0.2563762\ttotal: 2m 50s\tremaining: 33.7s\n501:\tlearn: 0.2561266\ttotal: 2m 50s\tremaining: 33.4s\n502:\tlearn: 0.2560650\ttotal: 2m 51s\tremaining: 33s\n503:\tlearn: 0.2559549\ttotal: 2m 51s\tremaining: 32.7s\n504:\tlearn: 0.2558416\ttotal: 2m 51s\tremaining: 32.3s\n505:\tlearn: 0.2556330\ttotal: 2m 52s\tremaining: 32s\n506:\tlearn: 0.2555789\ttotal: 2m 52s\tremaining: 31.7s\n507:\tlearn: 0.2552804\ttotal: 2m 52s\tremaining: 31.3s\n508:\tlearn: 0.2545678\ttotal: 2m 53s\tremaining: 31s\n509:\tlearn: 0.2544617\ttotal: 2m 53s\tremaining: 30.6s\n510:\tlearn: 0.2543465\ttotal: 2m 53s\tremaining: 30.3s\n511:\tlearn: 0.2541722\ttotal: 2m 54s\tremaining: 30s\n512:\tlearn: 0.2539709\ttotal: 2m 54s\tremaining: 29.6s\n513:\tlearn: 0.2534211\ttotal: 2m 54s\tremaining: 29.3s\n514:\tlearn: 0.2526287\ttotal: 2m 55s\tremaining: 28.9s\n515:\tlearn: 0.2525353\ttotal: 2m 55s\tremaining: 28.6s\n516:\tlearn: 0.2524251\ttotal: 2m 55s\tremaining: 28.3s\n517:\tlearn: 0.2514224\ttotal: 2m 56s\tremaining: 27.9s\n518:\tlearn: 0.2509250\ttotal: 2m 56s\tremaining: 27.6s\n519:\tlearn: 0.2508295\ttotal: 2m 57s\tremaining: 27.2s\n520:\tlearn: 0.2505263\ttotal: 2m 57s\tremaining: 26.9s\n521:\tlearn: 0.2504166\ttotal: 2m 57s\tremaining: 26.6s\n522:\tlearn: 0.2503401\ttotal: 2m 58s\tremaining: 26.2s\n523:\tlearn: 0.2497399\ttotal: 2m 58s\tremaining: 25.9s\n524:\tlearn: 0.2496173\ttotal: 2m 58s\tremaining: 25.5s\n525:\tlearn: 0.2495607\ttotal: 2m 59s\tremaining: 25.2s\n526:\tlearn: 0.2489261\ttotal: 2m 59s\tremaining: 24.8s\n527:\tlearn: 0.2487511\ttotal: 2m 59s\tremaining: 24.5s\n528:\tlearn: 0.2487099\ttotal: 3m\tremaining: 24.2s\n529:\tlearn: 0.2474592\ttotal: 3m\tremaining: 23.8s\n530:\tlearn: 0.2472309\ttotal: 3m\tremaining: 23.5s\n531:\tlearn: 0.2471540\ttotal: 3m 1s\tremaining: 23.1s\n532:\tlearn: 0.2470429\ttotal: 3m 1s\tremaining: 22.8s\n533:\tlearn: 0.2469994\ttotal: 3m 1s\tremaining: 22.5s\n534:\tlearn: 0.2468117\ttotal: 3m 2s\tremaining: 22.1s\n535:\tlearn: 0.2466241\ttotal: 3m 2s\tremaining: 21.8s\n536:\tlearn: 0.2465350\ttotal: 3m 2s\tremaining: 21.4s\n537:\tlearn: 0.2464782\ttotal: 3m 3s\tremaining: 21.1s\n538:\tlearn: 0.2463850\ttotal: 3m 3s\tremaining: 20.8s\n539:\tlearn: 0.2463009\ttotal: 3m 3s\tremaining: 20.4s\n540:\tlearn: 0.2457586\ttotal: 3m 4s\tremaining: 20.1s\n541:\tlearn: 0.2456500\ttotal: 3m 4s\tremaining: 19.7s\n542:\tlearn: 0.2455036\ttotal: 3m 4s\tremaining: 19.4s\n543:\tlearn: 0.2454475\ttotal: 3m 5s\tremaining: 19.1s\n544:\tlearn: 0.2453331\ttotal: 3m 5s\tremaining: 18.7s\n545:\tlearn: 0.2451445\ttotal: 3m 5s\tremaining: 18.4s\n546:\tlearn: 0.2449373\ttotal: 3m 6s\tremaining: 18s\n547:\tlearn: 0.2448774\ttotal: 3m 6s\tremaining: 17.7s\n548:\tlearn: 0.2445301\ttotal: 3m 6s\tremaining: 17.4s\n549:\tlearn: 0.2444958\ttotal: 3m 7s\tremaining: 17s\n550:\tlearn: 0.2431556\ttotal: 3m 7s\tremaining: 16.7s\n551:\tlearn: 0.2423584\ttotal: 3m 7s\tremaining: 16.3s\n552:\tlearn: 0.2419252\ttotal: 3m 8s\tremaining: 16s\n553:\tlearn: 0.2417401\ttotal: 3m 8s\tremaining: 15.7s\n554:\tlearn: 0.2414062\ttotal: 3m 8s\tremaining: 15.3s\n555:\tlearn: 0.2410805\ttotal: 3m 9s\tremaining: 15s\n556:\tlearn: 0.2410419\ttotal: 3m 9s\tremaining: 14.6s\n557:\tlearn: 0.2401356\ttotal: 3m 9s\tremaining: 14.3s\n558:\tlearn: 0.2399002\ttotal: 3m 10s\tremaining: 14s\n559:\tlearn: 0.2398288\ttotal: 3m 10s\tremaining: 13.6s\n560:\tlearn: 0.2397481\ttotal: 3m 10s\tremaining: 13.3s\n561:\tlearn: 0.2392452\ttotal: 3m 11s\tremaining: 12.9s\n562:\tlearn: 0.2391453\ttotal: 3m 11s\tremaining: 12.6s\n563:\tlearn: 0.2390118\ttotal: 3m 11s\tremaining: 12.3s\n564:\tlearn: 0.2389408\ttotal: 3m 12s\tremaining: 11.9s\n565:\tlearn: 0.2388568\ttotal: 3m 12s\tremaining: 11.6s\n566:\tlearn: 0.2388273\ttotal: 3m 12s\tremaining: 11.2s\n567:\tlearn: 0.2387732\ttotal: 3m 13s\tremaining: 10.9s\n568:\tlearn: 0.2387345\ttotal: 3m 13s\tremaining: 10.5s\n569:\tlearn: 0.2386864\ttotal: 3m 13s\tremaining: 10.2s\n570:\tlearn: 0.2384570\ttotal: 3m 14s\tremaining: 9.87s\n571:\tlearn: 0.2380197\ttotal: 3m 14s\tremaining: 9.53s\n572:\tlearn: 0.2378763\ttotal: 3m 14s\tremaining: 9.19s\n573:\tlearn: 0.2364382\ttotal: 3m 15s\tremaining: 8.85s\n574:\tlearn: 0.2363943\ttotal: 3m 15s\tremaining: 8.51s\n575:\tlearn: 0.2362675\ttotal: 3m 16s\tremaining: 8.17s\n576:\tlearn: 0.2359889\ttotal: 3m 16s\tremaining: 7.83s\n577:\tlearn: 0.2355615\ttotal: 3m 16s\tremaining: 7.49s\n578:\tlearn: 0.2355291\ttotal: 3m 17s\tremaining: 7.15s\n579:\tlearn: 0.2353476\ttotal: 3m 17s\tremaining: 6.81s\n580:\tlearn: 0.2351517\ttotal: 3m 17s\tremaining: 6.46s\n581:\tlearn: 0.2348748\ttotal: 3m 18s\tremaining: 6.13s\n582:\tlearn: 0.2348537\ttotal: 3m 18s\tremaining: 5.79s\n583:\tlearn: 0.2347044\ttotal: 3m 18s\tremaining: 5.44s\n584:\tlearn: 0.2344743\ttotal: 3m 19s\tremaining: 5.1s\n585:\tlearn: 0.2344235\ttotal: 3m 19s\tremaining: 4.76s\n586:\tlearn: 0.2342565\ttotal: 3m 19s\tremaining: 4.42s\n587:\tlearn: 0.2342257\ttotal: 3m 20s\tremaining: 4.08s\n588:\tlearn: 0.2340128\ttotal: 3m 20s\tremaining: 3.74s\n589:\tlearn: 0.2339783\ttotal: 3m 20s\tremaining: 3.4s\n590:\tlearn: 0.2339399\ttotal: 3m 21s\tremaining: 3.06s\n591:\tlearn: 0.2336428\ttotal: 3m 21s\tremaining: 2.72s\n592:\tlearn: 0.2334410\ttotal: 3m 21s\tremaining: 2.38s\n593:\tlearn: 0.2331312\ttotal: 3m 22s\tremaining: 2.04s\n594:\tlearn: 0.2330960\ttotal: 3m 22s\tremaining: 1.7s\n595:\tlearn: 0.2329758\ttotal: 3m 22s\tremaining: 1.36s\n596:\tlearn: 0.2324513\ttotal: 3m 23s\tremaining: 1.02s\n597:\tlearn: 0.2322635\ttotal: 3m 23s\tremaining: 681ms\n598:\tlearn: 0.2321695\ttotal: 3m 23s\tremaining: 340ms\n599:\tlearn: 0.2321254\ttotal: 3m 24s\tremaining: 0us\ncat_fit_done\n","output_type":"stream"}]},{"cell_type":"code","source":"# concat train and val\n\n# total_feature_full = np.concatenate((total_feature, total_feature_val), axis=0)\n# target_full = np.concatenate((target, target_val), axis=0)\n# model_xgb = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1)\n# model_xgb.fit(total_feature, target)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:01:45.266444Z","iopub.status.idle":"2024-05-15T15:01:45.266814Z","shell.execute_reply.started":"2024-05-15T15:01:45.266636Z","shell.execute_reply":"2024-05-15T15:01:45.266651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"\n\n# print(test_loader)\n\n# model.eval()\n\n# test_loader = DataLoader(test_dataset,\n#                           shuffle=True,\n#                           batch_size=batch_size,\n#                           num_workers=2)\n\ntest_x_origin = pd.read_json('{}data/test_data.json'.format(path))\ntest_x_origin['img_filepath'] = test_x_origin['img_filepath'].apply(lambda x: '{}data/'.format(path) + x)\n# test_prediction = []\n\n# with torch.no_grad():\n#   # iterate over the DataLoader for training data\n#   for i, data in enumerate(test_loader,0):\n#     input_feature = data[0].to(device)\n#     input_image = data[1].to(device)\n#     # Now, let's see what the network thinks these examples are\n#     prediction = model(input_image, input_feature)\n#     for i in prediction:\n#         test_prediction.append(i.item())\nfor cat in test_x.keys():\n    test_x[cat]['prediction'] = train_x[cat]['model'].predict(test_x[cat]['total_feature'].cpu().detach().numpy())\n# test_prediction = model_xgb.predict(total_feature_test)\n\n# reconstruct the test_prediction according to order\ntest_prediction = []\nfor i in test_x_origin['img_filepath']:\n    for cat in test_x.keys():\n        if i in test_x[cat]['df'][:, 0]:     \n            test_prediction.append(test_x[cat]['prediction'][np.where(test_x[cat]['df'][:, 0] == i)][0])\n            break\n\n# print(len(test_prediction))\n# convert test_ids to a dataframe\nsubmission = pd.DataFrame({'Pid': test_x_origin['Pid']})\nsubmission['label'] = test_prediction\nprint(submission)\nprint(submission.shape)\nsubmission.to_csv('/kaggle/working/predictions.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:41:56.115758Z","iopub.execute_input":"2024-05-15T15:41:56.116112Z","iopub.status.idle":"2024-05-15T15:41:57.564328Z","shell.execute_reply.started":"2024-05-15T15:41:56.116084Z","shell.execute_reply":"2024-05-15T15:41:57.563410Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"          Pid     label\n0       56783  8.022300\n1       75638  7.635104\n2       82051  6.768583\n3      381878  7.627807\n4      382850  5.985416\n...       ...       ...\n4995  1066395  6.796783\n4996   494492  7.364872\n4997   494495  4.815458\n4998   737606  6.391252\n4999   494555  6.069927\n\n[5000 rows x 2 columns]\n(5000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}